2021-05-12 00:22:16.982959: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
2021-05-12 00:22:24,480 - INFO - allennlp.common.params - udify_replace = ['dataset_reader.token_indexers', 'model.text_field_embedder', 'model.encoder', 'model.decoders.xpos', 'model.decoders.deps.encoder', 'model.decoders.upos.encoder', 'model.decoders.feats.encoder', 'model.decoders.lemmas.encoder', 'trainer.learning_rate_scheduler', 'trainer.optimizer']
2021-05-12 00:22:24,483 - INFO - allennlp.common.params - vocabulary.non_padded_namespaces = ['upos', 'xpos', 'feats', 'lemmas', '*tags', '*labels']
2021-05-12 00:22:24,565 - INFO - allennlp.common.params - include_in_archive = None
2021-05-12 00:22:24,567 - INFO - allennlp.common.params - random_seed = 13370
2021-05-12 00:22:24,567 - INFO - allennlp.common.params - numpy_seed = 1337
2021-05-12 00:22:24,567 - INFO - allennlp.common.params - pytorch_seed = 133
2021-05-12 00:22:24,571 - INFO - allennlp.common.checks - Pytorch version: 1.7.1
2021-05-12 00:22:24,572 - INFO - allennlp.common.params - type = default
2021-05-12 00:22:24,573 - INFO - allennlp.common.params - dataset_reader.type = udify_universal_dependencies
2021-05-12 00:22:24,573 - INFO - allennlp.common.params - dataset_reader.token_indexers.bert.type = udify-bert-pretrained
2021-05-12 00:22:24,573 - INFO - allennlp.common.params - dataset_reader.token_indexers.bert.pretrained_model = config/archive/bert-base-multilingual-cased/vocab.txt
2021-05-12 00:22:24,574 - INFO - allennlp.common.params - dataset_reader.token_indexers.bert.use_starting_offsets = True
2021-05-12 00:22:24,574 - INFO - allennlp.common.params - dataset_reader.token_indexers.bert.do_lowercase = False
2021-05-12 00:22:24,574 - INFO - allennlp.common.params - dataset_reader.token_indexers.bert.never_lowercase = None
2021-05-12 00:22:24,574 - INFO - allennlp.common.params - dataset_reader.token_indexers.bert.max_pieces = 512
2021-05-12 00:22:24,574 - INFO - allennlp.common.params - dataset_reader.token_indexers.bert.truncate_long_sequences = False
Calling BertTokenizer.from_pretrained() with the path to a single file or url is deprecated
2021-05-12 00:22:24,799 - INFO - allennlp.common.params - dataset_reader.token_indexers.tokens.type = single_id
2021-05-12 00:22:24,799 - INFO - allennlp.common.params - dataset_reader.token_indexers.tokens.namespace = tokens
2021-05-12 00:22:24,800 - INFO - allennlp.common.params - dataset_reader.token_indexers.tokens.lowercase_tokens = True
2021-05-12 00:22:24,800 - INFO - allennlp.common.params - dataset_reader.token_indexers.tokens.start_tokens = None
2021-05-12 00:22:24,800 - INFO - allennlp.common.params - dataset_reader.token_indexers.tokens.end_tokens = None
2021-05-12 00:22:24,800 - INFO - allennlp.common.params - dataset_reader.token_indexers.tokens.feature_name = text
2021-05-12 00:22:24,800 - INFO - allennlp.common.params - dataset_reader.token_indexers.tokens.default_value = THIS IS A REALLY UNLIKELY VALUE THAT HAS TO BE A STRING
2021-05-12 00:22:24,800 - INFO - allennlp.common.params - dataset_reader.token_indexers.tokens.token_min_padding_length = 0
2021-05-12 00:22:24,800 - INFO - allennlp.common.params - dataset_reader.lazy = False
2021-05-12 00:22:24,800 - INFO - allennlp.common.params - train_data_path = data/ud-treebanks-v2.3/UD_English-EWT/en_ewt-ud-train.conllu
2021-05-12 00:22:24,801 - INFO - allennlp.common.params - datasets_for_vocab_creation = None
2021-05-12 00:22:24,801 - INFO - allennlp.common.params - validation_dataset_reader = None
2021-05-12 00:22:24,801 - INFO - allennlp.common.params - validation_data_path = data/ud-treebanks-v2.3/UD_English-EWT/en_ewt-ud-dev.conllu
2021-05-12 00:22:24,801 - INFO - allennlp.common.params - validation_data_loader = None
2021-05-12 00:22:24,801 - INFO - allennlp.common.params - test_data_path = data/ud-treebanks-v2.3/UD_English-EWT/en_ewt-ud-test.conllu
2021-05-12 00:22:24,801 - INFO - allennlp.common.params - evaluate_on_test = True
2021-05-12 00:22:24,801 - INFO - allennlp.common.params - batch_weight_key = 
2021-05-12 00:22:24,802 - INFO - allennlp.training.util - Reading training data from data/ud-treebanks-v2.3/UD_English-EWT/en_ewt-ud-train.conllu
reading instances: 0it [00:00, ?it/s]
2021-05-12 00:22:24,804 - INFO - udify.dataset_readers.universal_dependencies - Reading UD instances from conllu dataset at: data/ud-treebanks-v2.3/UD_English-EWT/en_ewt-ud-train.conllu
2021-05-12 00:22:24,807 - WARNING - allennlp.data.fields.sequence_label_field - Your label namespace was 'feats'. We recommend you use a namespace ending with 'labels' or 'tags', so we don't add UNK and PAD tokens by default to your vocabulary.  See documentation for `non_padded_namespaces` parameter in Vocabulary.
2021-05-12 00:22:24,807 - WARNING - allennlp.data.fields.sequence_label_field - Your label namespace was 'lemmas'. We recommend you use a namespace ending with 'labels' or 'tags', so we don't add UNK and PAD tokens by default to your vocabulary.  See documentation for `non_padded_namespaces` parameter in Vocabulary.
reading instances: 1070it [00:02, 534.89it/s]
reading instances: 2713it [00:04, 703.38it/s]
reading instances: 4120it [00:06, 702.53it/s]
reading instances: 5880it [00:08, 772.40it/s]
reading instances: 7425it [00:11, 650.32it/s]
reading instances: 8995it [00:13, 691.02it/s]
reading instances: 10423it [00:15, 692.25it/s]
reading instances: 12074it [00:17, 732.11it/s]
reading instances: 12543it [00:17, 705.88it/s]
2021-05-12 00:22:42,572 - INFO - allennlp.training.util - Reading validation data from data/ud-treebanks-v2.3/UD_English-EWT/en_ewt-ud-dev.conllu
reading instances: 0it [00:00, ?it/s]
2021-05-12 00:22:42,575 - INFO - udify.dataset_readers.universal_dependencies - Reading UD instances from conllu dataset at: data/ud-treebanks-v2.3/UD_English-EWT/en_ewt-ud-dev.conllu
reading instances: 1101it [00:02, 550.41it/s]
reading instances: 2002it [00:02, 712.77it/s]
2021-05-12 00:22:45,383 - INFO - allennlp.training.util - Reading test data from data/ud-treebanks-v2.3/UD_English-EWT/en_ewt-ud-test.conllu
reading instances: 0it [00:00, ?it/s]
2021-05-12 00:22:45,384 - INFO - udify.dataset_readers.universal_dependencies - Reading UD instances from conllu dataset at: data/ud-treebanks-v2.3/UD_English-EWT/en_ewt-ud-test.conllu
reading instances: 1744it [00:02, 871.86it/s]
reading instances: 2077it [00:02, 903.51it/s]
2021-05-12 00:22:47,682 - INFO - allennlp.common.params - vocabulary.type = from_files
2021-05-12 00:22:47,683 - INFO - allennlp.common.params - vocabulary.directory = data/concat-exp-mix/vocab/concat-exp-mix/vocabulary/
2021-05-12 00:22:47,683 - INFO - allennlp.common.params - vocabulary.padding_token = @@PADDING@@
2021-05-12 00:22:47,683 - INFO - allennlp.common.params - vocabulary.oov_token = @@UNKNOWN@@
2021-05-12 00:22:47,683 - INFO - allennlp.data.vocabulary - Loading token dictionary from data/concat-exp-mix/vocab/concat-exp-mix/vocabulary/.
2021-05-12 00:22:47,685 - INFO - filelock - Lock 22396678273680 acquired on data/concat-exp-mix/vocab/concat-exp-mix/vocabulary/.lock
2021-05-12 00:22:49,142 - INFO - filelock - Lock 22396678273680 released on data/concat-exp-mix/vocab/concat-exp-mix/vocabulary/.lock
2021-05-12 00:22:49,142 - INFO - allennlp.common.params - model.type = udify_model
2021-05-12 00:22:49,143 - INFO - allennlp.common.params - model.tasks = ['deps']
2021-05-12 00:22:49,143 - INFO - allennlp.common.params - model.text_field_embedder.type = udify_embedder
2021-05-12 00:22:49,143 - INFO - allennlp.common.params - model.text_field_embedder.allow_unmatched_keys = True
2021-05-12 00:22:49,144 - INFO - allennlp.common.params - model.text_field_embedder.dropout = 0.5
2021-05-12 00:22:49,144 - INFO - allennlp.common.params - model.text_field_embedder.output_dim = None
2021-05-12 00:22:49,144 - INFO - allennlp.common.params - model.text_field_embedder.sum_embeddings = None
2021-05-12 00:22:49,144 - INFO - allennlp.common.params - model.text_field_embedder.token_embedders.bert.type = udify-bert-pretrained
2021-05-12 00:22:49,144 - INFO - allennlp.common.params - model.text_field_embedder.token_embedders.bert.pretrained_model = bert-base-multilingual-cased
2021-05-12 00:22:49,144 - INFO - allennlp.common.params - model.text_field_embedder.token_embedders.bert.requires_grad = True
2021-05-12 00:22:49,144 - INFO - allennlp.common.params - model.text_field_embedder.token_embedders.bert.dropout = 0.15
2021-05-12 00:22:49,144 - INFO - allennlp.common.params - model.text_field_embedder.token_embedders.bert.layer_dropout = 0.1
2021-05-12 00:22:49,144 - INFO - allennlp.common.params - model.text_field_embedder.token_embedders.bert.combine_layers = all
2021-05-12 00:22:56,396 - INFO - allennlp.common.params - model.encoder.type = pass_through
2021-05-12 00:22:56,397 - INFO - allennlp.common.params - model.encoder.input_dim = 768
2021-05-12 00:22:56,398 - INFO - allennlp.common.params - model.decoders.feats.type = udify_tag_decoder
2021-05-12 00:22:56,398 - INFO - allennlp.common.params - model.decoders.feats.task = feats
2021-05-12 00:22:56,398 - INFO - allennlp.common.params - model.decoders.feats.encoder.type = pass_through
2021-05-12 00:22:56,399 - INFO - allennlp.common.params - model.decoders.feats.encoder.input_dim = 768
2021-05-12 00:22:56,399 - INFO - allennlp.common.params - model.decoders.feats.label_smoothing = 0.03
2021-05-12 00:22:56,399 - INFO - allennlp.common.params - model.decoders.feats.dropout = 0.5
2021-05-12 00:22:56,399 - INFO - allennlp.common.params - model.decoders.feats.adaptive = True
2021-05-12 00:22:56,399 - INFO - allennlp.common.params - model.decoders.feats.features = None
2021-05-12 00:22:56,399 - INFO - allennlp.common.params - model.decoders.feats.initializer = <allennlp.nn.initializers.InitializerApplicator object at 0x145ec1431df0>
2021-05-12 00:22:56,399 - INFO - allennlp.common.params - model.decoders.feats.regularizer = None
2021-05-12 00:22:56,414 - INFO - allennlp.nn.initializers - Initializing parameters
2021-05-12 00:22:56,415 - INFO - allennlp.nn.initializers - Done initializing parameters; the following parameters are using their default initialization from their code
2021-05-12 00:22:56,415 - INFO - allennlp.nn.initializers -    task_output.head.weight
2021-05-12 00:22:56,415 - INFO - allennlp.nn.initializers -    task_output.tail.0.0.weight
2021-05-12 00:22:56,415 - INFO - allennlp.nn.initializers -    task_output.tail.0.1.weight
2021-05-12 00:22:56,415 - INFO - allennlp.nn.initializers -    task_output.tail.1.0.weight
2021-05-12 00:22:56,415 - INFO - allennlp.nn.initializers -    task_output.tail.1.1.weight
2021-05-12 00:22:56,415 - INFO - allennlp.common.params - model.decoders.upos.type = udify_tag_decoder
2021-05-12 00:22:56,415 - INFO - allennlp.common.params - model.decoders.upos.task = upos
2021-05-12 00:22:56,416 - INFO - allennlp.common.params - model.decoders.upos.encoder.type = pass_through
2021-05-12 00:22:56,416 - INFO - allennlp.common.params - model.decoders.upos.encoder.input_dim = 768
2021-05-12 00:22:56,416 - INFO - allennlp.common.params - model.decoders.upos.label_smoothing = 0.03
2021-05-12 00:22:56,416 - INFO - allennlp.common.params - model.decoders.upos.dropout = 0.5
2021-05-12 00:22:56,416 - INFO - allennlp.common.params - model.decoders.upos.adaptive = False
2021-05-12 00:22:56,416 - INFO - allennlp.common.params - model.decoders.upos.features = None
2021-05-12 00:22:56,416 - INFO - allennlp.common.params - model.decoders.upos.initializer = <allennlp.nn.initializers.InitializerApplicator object at 0x145ec1431df0>
2021-05-12 00:22:56,416 - INFO - allennlp.common.params - model.decoders.upos.regularizer = None
2021-05-12 00:22:56,417 - INFO - allennlp.nn.initializers - Initializing parameters
2021-05-12 00:22:56,417 - INFO - allennlp.nn.initializers - Done initializing parameters; the following parameters are using their default initialization from their code
2021-05-12 00:22:56,417 - INFO - allennlp.nn.initializers -    task_output._module.bias
2021-05-12 00:22:56,417 - INFO - allennlp.nn.initializers -    task_output._module.weight
2021-05-12 00:22:56,417 - INFO - allennlp.common.params - model.decoders.deps.type = udify_dependency_decoder
2021-05-12 00:22:56,418 - INFO - allennlp.common.params - model.decoders.deps.encoder.type = pass_through
2021-05-12 00:22:56,418 - INFO - allennlp.common.params - model.decoders.deps.encoder.input_dim = 768
2021-05-12 00:22:56,418 - INFO - allennlp.common.params - model.decoders.deps.tag_representation_dim = 256
2021-05-12 00:22:56,418 - INFO - allennlp.common.params - model.decoders.deps.arc_representation_dim = 768
2021-05-12 00:22:56,418 - INFO - allennlp.common.params - model.decoders.deps.pos_embed_dim = None
2021-05-12 00:22:56,419 - INFO - allennlp.common.params - model.decoders.deps.tag_feedforward = None
2021-05-12 00:22:56,419 - INFO - allennlp.common.params - model.decoders.deps.arc_feedforward = None
2021-05-12 00:22:56,419 - INFO - allennlp.common.params - model.decoders.deps.use_mst_decoding_for_validation = True
2021-05-12 00:22:56,419 - INFO - allennlp.common.params - model.decoders.deps.dropout = 0.5
2021-05-12 00:22:56,419 - INFO - allennlp.common.params - model.decoders.deps.initializer = <allennlp.nn.initializers.InitializerApplicator object at 0x145ec1431850>
2021-05-12 00:22:56,419 - INFO - allennlp.common.params - model.decoders.deps.regularizer = None
2021-05-12 00:22:56,530 - INFO - udify.models.dependency_decoder - Found POS tags corresponding to the following punctuation : {}. Ignoring words with these POS tags for evaluation.
2021-05-12 00:22:56,530 - INFO - allennlp.nn.initializers - Initializing parameters
2021-05-12 00:22:56,531 - INFO - allennlp.nn.initializers - Done initializing parameters; the following parameters are using their default initialization from their code
2021-05-12 00:22:56,531 - INFO - allennlp.nn.initializers -    _head_sentinel
2021-05-12 00:22:56,531 - INFO - allennlp.nn.initializers -    arc_attention._bias
2021-05-12 00:22:56,531 - INFO - allennlp.nn.initializers -    arc_attention._weight_matrix
2021-05-12 00:22:56,531 - INFO - allennlp.nn.initializers -    child_arc_feedforward._linear_layers.0.bias
2021-05-12 00:22:56,531 - INFO - allennlp.nn.initializers -    child_arc_feedforward._linear_layers.0.weight
2021-05-12 00:22:56,531 - INFO - allennlp.nn.initializers -    child_tag_feedforward._linear_layers.0.bias
2021-05-12 00:22:56,531 - INFO - allennlp.nn.initializers -    child_tag_feedforward._linear_layers.0.weight
2021-05-12 00:22:56,531 - INFO - allennlp.nn.initializers -    head_arc_feedforward._linear_layers.0.bias
2021-05-12 00:22:56,531 - INFO - allennlp.nn.initializers -    head_arc_feedforward._linear_layers.0.weight
2021-05-12 00:22:56,531 - INFO - allennlp.nn.initializers -    head_tag_feedforward._linear_layers.0.bias
2021-05-12 00:22:56,531 - INFO - allennlp.nn.initializers -    head_tag_feedforward._linear_layers.0.weight
2021-05-12 00:22:56,532 - INFO - allennlp.nn.initializers -    tag_bilinear.bias
2021-05-12 00:22:56,532 - INFO - allennlp.nn.initializers -    tag_bilinear.weight
2021-05-12 00:22:56,532 - INFO - allennlp.common.params - model.decoders.lemmas.type = udify_tag_decoder
2021-05-12 00:22:56,532 - INFO - allennlp.common.params - model.decoders.lemmas.task = lemmas
2021-05-12 00:22:56,532 - INFO - allennlp.common.params - model.decoders.lemmas.encoder.type = pass_through
2021-05-12 00:22:56,533 - INFO - allennlp.common.params - model.decoders.lemmas.encoder.input_dim = 768
2021-05-12 00:22:56,533 - INFO - allennlp.common.params - model.decoders.lemmas.label_smoothing = 0.03
2021-05-12 00:22:56,533 - INFO - allennlp.common.params - model.decoders.lemmas.dropout = 0.5
2021-05-12 00:22:56,533 - INFO - allennlp.common.params - model.decoders.lemmas.adaptive = True
2021-05-12 00:22:56,533 - INFO - allennlp.common.params - model.decoders.lemmas.features = None
2021-05-12 00:22:56,533 - INFO - allennlp.common.params - model.decoders.lemmas.initializer = <allennlp.nn.initializers.InitializerApplicator object at 0x145ec1431df0>
2021-05-12 00:22:56,533 - INFO - allennlp.common.params - model.decoders.lemmas.regularizer = None
2021-05-12 00:22:56,620 - INFO - allennlp.nn.initializers - Initializing parameters
2021-05-12 00:22:56,620 - INFO - allennlp.nn.initializers - Done initializing parameters; the following parameters are using their default initialization from their code
2021-05-12 00:22:56,620 - INFO - allennlp.nn.initializers -    task_output.head.weight
2021-05-12 00:22:56,620 - INFO - allennlp.nn.initializers -    task_output.tail.0.0.weight
2021-05-12 00:22:56,620 - INFO - allennlp.nn.initializers -    task_output.tail.0.1.weight
2021-05-12 00:22:56,620 - INFO - allennlp.nn.initializers -    task_output.tail.1.0.weight
2021-05-12 00:22:56,621 - INFO - allennlp.nn.initializers -    task_output.tail.1.1.weight
2021-05-12 00:22:56,621 - INFO - allennlp.common.params - model.pretrained_model = bert-base-multilingual-cased
2021-05-12 00:22:56,621 - INFO - allennlp.common.params - model.post_encoder_embedder = None
2021-05-12 00:22:56,621 - INFO - allennlp.common.params - model.dropout = 0.5
2021-05-12 00:22:56,621 - INFO - allennlp.common.params - model.word_dropout = 0.2
2021-05-12 00:22:56,621 - INFO - allennlp.common.params - model.mix_embedding = 12
2021-05-12 00:22:56,621 - INFO - allennlp.common.params - model.layer_dropout = 0.1
2021-05-12 00:22:56,621 - INFO - allennlp.common.params - model.initializer = <allennlp.nn.initializers.InitializerApplicator object at 0x145ec14394f0>
2021-05-12 00:22:56,621 - INFO - allennlp.common.params - model.regularizer = None
2021-05-12 00:22:57,141 - INFO - allennlp.nn.initializers - Initializing parameters
2021-05-12 00:22:57,144 - INFO - allennlp.nn.initializers - Done initializing parameters; the following parameters are using their default initialization from their code
2021-05-12 00:22:57,144 - INFO - allennlp.nn.initializers -    decoders.deps._head_sentinel
2021-05-12 00:22:57,144 - INFO - allennlp.nn.initializers -    decoders.deps.arc_attention._bias
2021-05-12 00:22:57,144 - INFO - allennlp.nn.initializers -    decoders.deps.arc_attention._weight_matrix
2021-05-12 00:22:57,144 - INFO - allennlp.nn.initializers -    decoders.deps.child_arc_feedforward._linear_layers.0.bias
2021-05-12 00:22:57,144 - INFO - allennlp.nn.initializers -    decoders.deps.child_arc_feedforward._linear_layers.0.weight
2021-05-12 00:22:57,144 - INFO - allennlp.nn.initializers -    decoders.deps.child_tag_feedforward._linear_layers.0.bias
2021-05-12 00:22:57,144 - INFO - allennlp.nn.initializers -    decoders.deps.child_tag_feedforward._linear_layers.0.weight
2021-05-12 00:22:57,144 - INFO - allennlp.nn.initializers -    decoders.deps.head_arc_feedforward._linear_layers.0.bias
2021-05-12 00:22:57,144 - INFO - allennlp.nn.initializers -    decoders.deps.head_arc_feedforward._linear_layers.0.weight
2021-05-12 00:22:57,144 - INFO - allennlp.nn.initializers -    decoders.deps.head_tag_feedforward._linear_layers.0.bias
2021-05-12 00:22:57,144 - INFO - allennlp.nn.initializers -    decoders.deps.head_tag_feedforward._linear_layers.0.weight
2021-05-12 00:22:57,144 - INFO - allennlp.nn.initializers -    decoders.deps.tag_bilinear.bias
2021-05-12 00:22:57,145 - INFO - allennlp.nn.initializers -    decoders.deps.tag_bilinear.weight
2021-05-12 00:22:57,145 - INFO - allennlp.nn.initializers -    decoders.feats.task_output.head.weight
2021-05-12 00:22:57,145 - INFO - allennlp.nn.initializers -    decoders.feats.task_output.tail.0.0.weight
2021-05-12 00:22:57,145 - INFO - allennlp.nn.initializers -    decoders.feats.task_output.tail.0.1.weight
2021-05-12 00:22:57,145 - INFO - allennlp.nn.initializers -    decoders.feats.task_output.tail.1.0.weight
2021-05-12 00:22:57,145 - INFO - allennlp.nn.initializers -    decoders.feats.task_output.tail.1.1.weight
2021-05-12 00:22:57,145 - INFO - allennlp.nn.initializers -    decoders.lemmas.task_output.head.weight
2021-05-12 00:22:57,145 - INFO - allennlp.nn.initializers -    decoders.lemmas.task_output.tail.0.0.weight
2021-05-12 00:22:57,145 - INFO - allennlp.nn.initializers -    decoders.lemmas.task_output.tail.0.1.weight
2021-05-12 00:22:57,145 - INFO - allennlp.nn.initializers -    decoders.lemmas.task_output.tail.1.0.weight
2021-05-12 00:22:57,145 - INFO - allennlp.nn.initializers -    decoders.lemmas.task_output.tail.1.1.weight
2021-05-12 00:22:57,145 - INFO - allennlp.nn.initializers -    decoders.upos.task_output._module.bias
2021-05-12 00:22:57,145 - INFO - allennlp.nn.initializers -    decoders.upos.task_output._module.weight
2021-05-12 00:22:57,145 - INFO - allennlp.nn.initializers -    scalar_mix.deps.gamma
2021-05-12 00:22:57,145 - INFO - allennlp.nn.initializers -    scalar_mix.deps.scalar_parameters.0
2021-05-12 00:22:57,145 - INFO - allennlp.nn.initializers -    scalar_mix.deps.scalar_parameters.1
2021-05-12 00:22:57,145 - INFO - allennlp.nn.initializers -    scalar_mix.deps.scalar_parameters.10
2021-05-12 00:22:57,145 - INFO - allennlp.nn.initializers -    scalar_mix.deps.scalar_parameters.11
2021-05-12 00:22:57,146 - INFO - allennlp.nn.initializers -    scalar_mix.deps.scalar_parameters.2
2021-05-12 00:22:57,146 - INFO - allennlp.nn.initializers -    scalar_mix.deps.scalar_parameters.3
2021-05-12 00:22:57,146 - INFO - allennlp.nn.initializers -    scalar_mix.deps.scalar_parameters.4
2021-05-12 00:22:57,146 - INFO - allennlp.nn.initializers -    scalar_mix.deps.scalar_parameters.5
2021-05-12 00:22:57,146 - INFO - allennlp.nn.initializers -    scalar_mix.deps.scalar_parameters.6
2021-05-12 00:22:57,146 - INFO - allennlp.nn.initializers -    scalar_mix.deps.scalar_parameters.7
2021-05-12 00:22:57,146 - INFO - allennlp.nn.initializers -    scalar_mix.deps.scalar_parameters.8
2021-05-12 00:22:57,146 - INFO - allennlp.nn.initializers -    scalar_mix.deps.scalar_parameters.9
2021-05-12 00:22:57,146 - INFO - allennlp.nn.initializers -    scalar_mix.feats.gamma
2021-05-12 00:22:57,146 - INFO - allennlp.nn.initializers -    scalar_mix.feats.scalar_parameters.0
2021-05-12 00:22:57,146 - INFO - allennlp.nn.initializers -    scalar_mix.feats.scalar_parameters.1
2021-05-12 00:22:57,146 - INFO - allennlp.nn.initializers -    scalar_mix.feats.scalar_parameters.10
2021-05-12 00:22:57,146 - INFO - allennlp.nn.initializers -    scalar_mix.feats.scalar_parameters.11
2021-05-12 00:22:57,146 - INFO - allennlp.nn.initializers -    scalar_mix.feats.scalar_parameters.2
2021-05-12 00:22:57,146 - INFO - allennlp.nn.initializers -    scalar_mix.feats.scalar_parameters.3
2021-05-12 00:22:57,146 - INFO - allennlp.nn.initializers -    scalar_mix.feats.scalar_parameters.4
2021-05-12 00:22:57,146 - INFO - allennlp.nn.initializers -    scalar_mix.feats.scalar_parameters.5
2021-05-12 00:22:57,146 - INFO - allennlp.nn.initializers -    scalar_mix.feats.scalar_parameters.6
2021-05-12 00:22:57,147 - INFO - allennlp.nn.initializers -    scalar_mix.feats.scalar_parameters.7
2021-05-12 00:22:57,147 - INFO - allennlp.nn.initializers -    scalar_mix.feats.scalar_parameters.8
2021-05-12 00:22:57,147 - INFO - allennlp.nn.initializers -    scalar_mix.feats.scalar_parameters.9
2021-05-12 00:22:57,147 - INFO - allennlp.nn.initializers -    scalar_mix.lemmas.gamma
2021-05-12 00:22:57,147 - INFO - allennlp.nn.initializers -    scalar_mix.lemmas.scalar_parameters.0
2021-05-12 00:22:57,147 - INFO - allennlp.nn.initializers -    scalar_mix.lemmas.scalar_parameters.1
2021-05-12 00:22:57,147 - INFO - allennlp.nn.initializers -    scalar_mix.lemmas.scalar_parameters.10
2021-05-12 00:22:57,147 - INFO - allennlp.nn.initializers -    scalar_mix.lemmas.scalar_parameters.11
2021-05-12 00:22:57,147 - INFO - allennlp.nn.initializers -    scalar_mix.lemmas.scalar_parameters.2
2021-05-12 00:22:57,147 - INFO - allennlp.nn.initializers -    scalar_mix.lemmas.scalar_parameters.3
2021-05-12 00:22:57,147 - INFO - allennlp.nn.initializers -    scalar_mix.lemmas.scalar_parameters.4
2021-05-12 00:22:57,147 - INFO - allennlp.nn.initializers -    scalar_mix.lemmas.scalar_parameters.5
2021-05-12 00:22:57,147 - INFO - allennlp.nn.initializers -    scalar_mix.lemmas.scalar_parameters.6
2021-05-12 00:22:57,147 - INFO - allennlp.nn.initializers -    scalar_mix.lemmas.scalar_parameters.7
2021-05-12 00:22:57,147 - INFO - allennlp.nn.initializers -    scalar_mix.lemmas.scalar_parameters.8
2021-05-12 00:22:57,147 - INFO - allennlp.nn.initializers -    scalar_mix.lemmas.scalar_parameters.9
2021-05-12 00:22:57,147 - INFO - allennlp.nn.initializers -    scalar_mix.upos.gamma
2021-05-12 00:22:57,147 - INFO - allennlp.nn.initializers -    scalar_mix.upos.scalar_parameters.0
2021-05-12 00:22:57,148 - INFO - allennlp.nn.initializers -    scalar_mix.upos.scalar_parameters.1
2021-05-12 00:22:57,148 - INFO - allennlp.nn.initializers -    scalar_mix.upos.scalar_parameters.10
2021-05-12 00:22:57,148 - INFO - allennlp.nn.initializers -    scalar_mix.upos.scalar_parameters.11
2021-05-12 00:22:57,148 - INFO - allennlp.nn.initializers -    scalar_mix.upos.scalar_parameters.2
2021-05-12 00:22:57,148 - INFO - allennlp.nn.initializers -    scalar_mix.upos.scalar_parameters.3
2021-05-12 00:22:57,148 - INFO - allennlp.nn.initializers -    scalar_mix.upos.scalar_parameters.4
2021-05-12 00:22:57,148 - INFO - allennlp.nn.initializers -    scalar_mix.upos.scalar_parameters.5
2021-05-12 00:22:57,148 - INFO - allennlp.nn.initializers -    scalar_mix.upos.scalar_parameters.6
2021-05-12 00:22:57,148 - INFO - allennlp.nn.initializers -    scalar_mix.upos.scalar_parameters.7
2021-05-12 00:22:57,148 - INFO - allennlp.nn.initializers -    scalar_mix.upos.scalar_parameters.8
2021-05-12 00:22:57,148 - INFO - allennlp.nn.initializers -    scalar_mix.upos.scalar_parameters.9
2021-05-12 00:22:57,148 - INFO - allennlp.nn.initializers -    text_field_embedder.token_embedder_bert.bert_model.embeddings.LayerNorm.bias
2021-05-12 00:22:57,148 - INFO - allennlp.nn.initializers -    text_field_embedder.token_embedder_bert.bert_model.embeddings.LayerNorm.weight
2021-05-12 00:22:57,148 - INFO - allennlp.nn.initializers -    text_field_embedder.token_embedder_bert.bert_model.embeddings.position_embeddings.weight
2021-05-12 00:22:57,148 - INFO - allennlp.nn.initializers -    text_field_embedder.token_embedder_bert.bert_model.embeddings.token_type_embeddings.weight
2021-05-12 00:22:57,148 - INFO - allennlp.nn.initializers -    text_field_embedder.token_embedder_bert.bert_model.embeddings.word_embeddings.weight
2021-05-12 00:22:57,148 - INFO - allennlp.nn.initializers -    text_field_embedder.token_embedder_bert.bert_model.encoder.layer.0.attention.output.LayerNorm.bias
2021-05-12 00:22:57,148 - INFO - allennlp.nn.initializers -    text_field_embedder.token_embedder_bert.bert_model.encoder.layer.0.attention.output.LayerNorm.weight
2021-05-12 00:22:57,149 - INFO - allennlp.nn.initializers -    text_field_embedder.token_embedder_bert.bert_model.encoder.layer.0.attention.output.dense.bias
2021-05-12 00:22:57,149 - INFO - allennlp.nn.initializers -    text_field_embedder.token_embedder_bert.bert_model.encoder.layer.0.attention.output.dense.weight
2021-05-12 00:22:57,149 - INFO - allennlp.nn.initializers -    text_field_embedder.token_embedder_bert.bert_model.encoder.layer.0.attention.self.key.bias
2021-05-12 00:22:57,149 - INFO - allennlp.nn.initializers -    text_field_embedder.token_embedder_bert.bert_model.encoder.layer.0.attention.self.key.weight
2021-05-12 00:22:57,149 - INFO - allennlp.nn.initializers -    text_field_embedder.token_embedder_bert.bert_model.encoder.layer.0.attention.self.query.bias
2021-05-12 00:22:57,149 - INFO - allennlp.nn.initializers -    text_field_embedder.token_embedder_bert.bert_model.encoder.layer.0.attention.self.query.weight
2021-05-12 00:22:57,149 - INFO - allennlp.nn.initializers -    text_field_embedder.token_embedder_bert.bert_model.encoder.layer.0.attention.self.value.bias
2021-05-12 00:22:57,149 - INFO - allennlp.nn.initializers -    text_field_embedder.token_embedder_bert.bert_model.encoder.layer.0.attention.self.value.weight
2021-05-12 00:22:57,149 - INFO - allennlp.nn.initializers -    text_field_embedder.token_embedder_bert.bert_model.encoder.layer.0.intermediate.dense.bias
2021-05-12 00:22:57,149 - INFO - allennlp.nn.initializers -    text_field_embedder.token_embedder_bert.bert_model.encoder.layer.0.intermediate.dense.weight
2021-05-12 00:22:57,149 - INFO - allennlp.nn.initializers -    text_field_embedder.token_embedder_bert.bert_model.encoder.layer.0.output.LayerNorm.bias
2021-05-12 00:22:57,149 - INFO - allennlp.nn.initializers -    text_field_embedder.token_embedder_bert.bert_model.encoder.layer.0.output.LayerNorm.weight
2021-05-12 00:22:57,149 - INFO - allennlp.nn.initializers -    text_field_embedder.token_embedder_bert.bert_model.encoder.layer.0.output.dense.bias
2021-05-12 00:22:57,149 - INFO - allennlp.nn.initializers -    text_field_embedder.token_embedder_bert.bert_model.encoder.layer.0.output.dense.weight
2021-05-12 00:22:57,149 - INFO - allennlp.nn.initializers -    text_field_embedder.token_embedder_bert.bert_model.encoder.layer.1.attention.output.LayerNorm.bias
2021-05-12 00:22:57,149 - INFO - allennlp.nn.initializers -    text_field_embedder.token_embedder_bert.bert_model.encoder.layer.1.attention.output.LayerNorm.weight
2021-05-12 00:22:57,149 - INFO - allennlp.nn.initializers -    text_field_embedder.token_embedder_bert.bert_model.encoder.layer.1.attention.output.dense.bias
2021-05-12 00:22:57,149 - INFO - allennlp.nn.initializers -    text_field_embedder.token_embedder_bert.bert_model.encoder.layer.1.attention.output.dense.weight
2021-05-12 00:22:57,150 - INFO - allennlp.nn.initializers -    text_field_embedder.token_embedder_bert.bert_model.encoder.layer.1.attention.self.key.bias
2021-05-12 00:22:57,150 - INFO - allennlp.nn.initializers -    text_field_embedder.token_embedder_bert.bert_model.encoder.layer.1.attention.self.key.weight
2021-05-12 00:22:57,150 - INFO - allennlp.nn.initializers -    text_field_embedder.token_embedder_bert.bert_model.encoder.layer.1.attention.self.query.bias
2021-05-12 00:22:57,150 - INFO - allennlp.nn.initializers -    text_field_embedder.token_embedder_bert.bert_model.encoder.layer.1.attention.self.query.weight
2021-05-12 00:22:57,150 - INFO - allennlp.nn.initializers -    text_field_embedder.token_embedder_bert.bert_model.encoder.layer.1.attention.self.value.bias
2021-05-12 00:22:57,150 - INFO - allennlp.nn.initializers -    text_field_embedder.token_embedder_bert.bert_model.encoder.layer.1.attention.self.value.weight
2021-05-12 00:22:57,150 - INFO - allennlp.nn.initializers -    text_field_embedder.token_embedder_bert.bert_model.encoder.layer.1.intermediate.dense.bias
2021-05-12 00:22:57,150 - INFO - allennlp.nn.initializers -    text_field_embedder.token_embedder_bert.bert_model.encoder.layer.1.intermediate.dense.weight
2021-05-12 00:22:57,150 - INFO - allennlp.nn.initializers -    text_field_embedder.token_embedder_bert.bert_model.encoder.layer.1.output.LayerNorm.bias
2021-05-12 00:22:57,150 - INFO - allennlp.nn.initializers -    text_field_embedder.token_embedder_bert.bert_model.encoder.layer.1.output.LayerNorm.weight
2021-05-12 00:22:57,150 - INFO - allennlp.nn.initializers -    text_field_embedder.token_embedder_bert.bert_model.encoder.layer.1.output.dense.bias
2021-05-12 00:22:57,150 - INFO - allennlp.nn.initializers -    text_field_embedder.token_embedder_bert.bert_model.encoder.layer.1.output.dense.weight
2021-05-12 00:22:57,150 - INFO - allennlp.nn.initializers -    text_field_embedder.token_embedder_bert.bert_model.encoder.layer.10.attention.output.LayerNorm.bias
2021-05-12 00:22:57,150 - INFO - allennlp.nn.initializers -    text_field_embedder.token_embedder_bert.bert_model.encoder.layer.10.attention.output.LayerNorm.weight
2021-05-12 00:22:57,150 - INFO - allennlp.nn.initializers -    text_field_embedder.token_embedder_bert.bert_model.encoder.layer.10.attention.output.dense.bias
2021-05-12 00:22:57,150 - INFO - allennlp.nn.initializers -    text_field_embedder.token_embedder_bert.bert_model.encoder.layer.10.attention.output.dense.weight
2021-05-12 00:22:57,150 - INFO - allennlp.nn.initializers -    text_field_embedder.token_embedder_bert.bert_model.encoder.layer.10.attention.self.key.bias
2021-05-12 00:22:57,151 - INFO - allennlp.nn.initializers -    text_field_embedder.token_embedder_bert.bert_model.encoder.layer.10.attention.self.key.weight
2021-05-12 00:22:57,151 - INFO - allennlp.nn.initializers -    text_field_embedder.token_embedder_bert.bert_model.encoder.layer.10.attention.self.query.bias
2021-05-12 00:22:57,151 - INFO - allennlp.nn.initializers -    text_field_embedder.token_embedder_bert.bert_model.encoder.layer.10.attention.self.query.weight
2021-05-12 00:22:57,151 - INFO - allennlp.nn.initializers -    text_field_embedder.token_embedder_bert.bert_model.encoder.layer.10.attention.self.value.bias
2021-05-12 00:22:57,151 - INFO - allennlp.nn.initializers -    text_field_embedder.token_embedder_bert.bert_model.encoder.layer.10.attention.self.value.weight
2021-05-12 00:22:57,151 - INFO - allennlp.nn.initializers -    text_field_embedder.token_embedder_bert.bert_model.encoder.layer.10.intermediate.dense.bias
2021-05-12 00:22:57,151 - INFO - allennlp.nn.initializers -    text_field_embedder.token_embedder_bert.bert_model.encoder.layer.10.intermediate.dense.weight
2021-05-12 00:22:57,151 - INFO - allennlp.nn.initializers -    text_field_embedder.token_embedder_bert.bert_model.encoder.layer.10.output.LayerNorm.bias
2021-05-12 00:22:57,151 - INFO - allennlp.nn.initializers -    text_field_embedder.token_embedder_bert.bert_model.encoder.layer.10.output.LayerNorm.weight
2021-05-12 00:22:57,151 - INFO - allennlp.nn.initializers -    text_field_embedder.token_embedder_bert.bert_model.encoder.layer.10.output.dense.bias
2021-05-12 00:22:57,151 - INFO - allennlp.nn.initializers -    text_field_embedder.token_embedder_bert.bert_model.encoder.layer.10.output.dense.weight
2021-05-12 00:22:57,151 - INFO - allennlp.nn.initializers -    text_field_embedder.token_embedder_bert.bert_model.encoder.layer.11.attention.output.LayerNorm.bias
2021-05-12 00:22:57,151 - INFO - allennlp.nn.initializers -    text_field_embedder.token_embedder_bert.bert_model.encoder.layer.11.attention.output.LayerNorm.weight
2021-05-12 00:22:57,151 - INFO - allennlp.nn.initializers -    text_field_embedder.token_embedder_bert.bert_model.encoder.layer.11.attention.output.dense.bias
2021-05-12 00:22:57,151 - INFO - allennlp.nn.initializers -    text_field_embedder.token_embedder_bert.bert_model.encoder.layer.11.attention.output.dense.weight
2021-05-12 00:22:57,151 - INFO - allennlp.nn.initializers -    text_field_embedder.token_embedder_bert.bert_model.encoder.layer.11.attention.self.key.bias
2021-05-12 00:22:57,151 - INFO - allennlp.nn.initializers -    text_field_embedder.token_embedder_bert.bert_model.encoder.layer.11.attention.self.key.weight
2021-05-12 00:22:57,151 - INFO - allennlp.nn.initializers -    text_field_embedder.token_embedder_bert.bert_model.encoder.layer.11.attention.self.query.bias
2021-05-12 00:22:57,152 - INFO - allennlp.nn.initializers -    text_field_embedder.token_embedder_bert.bert_model.encoder.layer.11.attention.self.query.weight
2021-05-12 00:22:57,152 - INFO - allennlp.nn.initializers -    text_field_embedder.token_embedder_bert.bert_model.encoder.layer.11.attention.self.value.bias
2021-05-12 00:22:57,152 - INFO - allennlp.nn.initializers -    text_field_embedder.token_embedder_bert.bert_model.encoder.layer.11.attention.self.value.weight
2021-05-12 00:22:57,152 - INFO - allennlp.nn.initializers -    text_field_embedder.token_embedder_bert.bert_model.encoder.layer.11.intermediate.dense.bias
2021-05-12 00:22:57,152 - INFO - allennlp.nn.initializers -    text_field_embedder.token_embedder_bert.bert_model.encoder.layer.11.intermediate.dense.weight
2021-05-12 00:22:57,152 - INFO - allennlp.nn.initializers -    text_field_embedder.token_embedder_bert.bert_model.encoder.layer.11.output.LayerNorm.bias
2021-05-12 00:22:57,152 - INFO - allennlp.nn.initializers -    text_field_embedder.token_embedder_bert.bert_model.encoder.layer.11.output.LayerNorm.weight
2021-05-12 00:22:57,152 - INFO - allennlp.nn.initializers -    text_field_embedder.token_embedder_bert.bert_model.encoder.layer.11.output.dense.bias
2021-05-12 00:22:57,152 - INFO - allennlp.nn.initializers -    text_field_embedder.token_embedder_bert.bert_model.encoder.layer.11.output.dense.weight
2021-05-12 00:22:57,152 - INFO - allennlp.nn.initializers -    text_field_embedder.token_embedder_bert.bert_model.encoder.layer.2.attention.output.LayerNorm.bias
2021-05-12 00:22:57,152 - INFO - allennlp.nn.initializers -    text_field_embedder.token_embedder_bert.bert_model.encoder.layer.2.attention.output.LayerNorm.weight
2021-05-12 00:22:57,152 - INFO - allennlp.nn.initializers -    text_field_embedder.token_embedder_bert.bert_model.encoder.layer.2.attention.output.dense.bias
2021-05-12 00:22:57,152 - INFO - allennlp.nn.initializers -    text_field_embedder.token_embedder_bert.bert_model.encoder.layer.2.attention.output.dense.weight
2021-05-12 00:22:57,152 - INFO - allennlp.nn.initializers -    text_field_embedder.token_embedder_bert.bert_model.encoder.layer.2.attention.self.key.bias
2021-05-12 00:22:57,152 - INFO - allennlp.nn.initializers -    text_field_embedder.token_embedder_bert.bert_model.encoder.layer.2.attention.self.key.weight
2021-05-12 00:22:57,152 - INFO - allennlp.nn.initializers -    text_field_embedder.token_embedder_bert.bert_model.encoder.layer.2.attention.self.query.bias
2021-05-12 00:22:57,152 - INFO - allennlp.nn.initializers -    text_field_embedder.token_embedder_bert.bert_model.encoder.layer.2.attention.self.query.weight
2021-05-12 00:22:57,152 - INFO - allennlp.nn.initializers -    text_field_embedder.token_embedder_bert.bert_model.encoder.layer.2.attention.self.value.bias
2021-05-12 00:22:57,153 - INFO - allennlp.nn.initializers -    text_field_embedder.token_embedder_bert.bert_model.encoder.layer.2.attention.self.value.weight
2021-05-12 00:22:57,153 - INFO - allennlp.nn.initializers -    text_field_embedder.token_embedder_bert.bert_model.encoder.layer.2.intermediate.dense.bias
2021-05-12 00:22:57,153 - INFO - allennlp.nn.initializers -    text_field_embedder.token_embedder_bert.bert_model.encoder.layer.2.intermediate.dense.weight
2021-05-12 00:22:57,153 - INFO - allennlp.nn.initializers -    text_field_embedder.token_embedder_bert.bert_model.encoder.layer.2.output.LayerNorm.bias
2021-05-12 00:22:57,153 - INFO - allennlp.nn.initializers -    text_field_embedder.token_embedder_bert.bert_model.encoder.layer.2.output.LayerNorm.weight
2021-05-12 00:22:57,153 - INFO - allennlp.nn.initializers -    text_field_embedder.token_embedder_bert.bert_model.encoder.layer.2.output.dense.bias
2021-05-12 00:22:57,153 - INFO - allennlp.nn.initializers -    text_field_embedder.token_embedder_bert.bert_model.encoder.layer.2.output.dense.weight
2021-05-12 00:22:57,153 - INFO - allennlp.nn.initializers -    text_field_embedder.token_embedder_bert.bert_model.encoder.layer.3.attention.output.LayerNorm.bias
2021-05-12 00:22:57,153 - INFO - allennlp.nn.initializers -    text_field_embedder.token_embedder_bert.bert_model.encoder.layer.3.attention.output.LayerNorm.weight
2021-05-12 00:22:57,153 - INFO - allennlp.nn.initializers -    text_field_embedder.token_embedder_bert.bert_model.encoder.layer.3.attention.output.dense.bias
2021-05-12 00:22:57,153 - INFO - allennlp.nn.initializers -    text_field_embedder.token_embedder_bert.bert_model.encoder.layer.3.attention.output.dense.weight
2021-05-12 00:22:57,153 - INFO - allennlp.nn.initializers -    text_field_embedder.token_embedder_bert.bert_model.encoder.layer.3.attention.self.key.bias
2021-05-12 00:22:57,153 - INFO - allennlp.nn.initializers -    text_field_embedder.token_embedder_bert.bert_model.encoder.layer.3.attention.self.key.weight
2021-05-12 00:22:57,153 - INFO - allennlp.nn.initializers -    text_field_embedder.token_embedder_bert.bert_model.encoder.layer.3.attention.self.query.bias
2021-05-12 00:22:57,153 - INFO - allennlp.nn.initializers -    text_field_embedder.token_embedder_bert.bert_model.encoder.layer.3.attention.self.query.weight
2021-05-12 00:22:57,153 - INFO - allennlp.nn.initializers -    text_field_embedder.token_embedder_bert.bert_model.encoder.layer.3.attention.self.value.bias
2021-05-12 00:22:57,153 - INFO - allennlp.nn.initializers -    text_field_embedder.token_embedder_bert.bert_model.encoder.layer.3.attention.self.value.weight
2021-05-12 00:22:57,153 - INFO - allennlp.nn.initializers -    text_field_embedder.token_embedder_bert.bert_model.encoder.layer.3.intermediate.dense.bias
2021-05-12 00:22:57,154 - INFO - allennlp.nn.initializers -    text_field_embedder.token_embedder_bert.bert_model.encoder.layer.3.intermediate.dense.weight
2021-05-12 00:22:57,154 - INFO - allennlp.nn.initializers -    text_field_embedder.token_embedder_bert.bert_model.encoder.layer.3.output.LayerNorm.bias
2021-05-12 00:22:57,154 - INFO - allennlp.nn.initializers -    text_field_embedder.token_embedder_bert.bert_model.encoder.layer.3.output.LayerNorm.weight
2021-05-12 00:22:57,154 - INFO - allennlp.nn.initializers -    text_field_embedder.token_embedder_bert.bert_model.encoder.layer.3.output.dense.bias
2021-05-12 00:22:57,154 - INFO - allennlp.nn.initializers -    text_field_embedder.token_embedder_bert.bert_model.encoder.layer.3.output.dense.weight
2021-05-12 00:22:57,154 - INFO - allennlp.nn.initializers -    text_field_embedder.token_embedder_bert.bert_model.encoder.layer.4.attention.output.LayerNorm.bias
2021-05-12 00:22:57,154 - INFO - allennlp.nn.initializers -    text_field_embedder.token_embedder_bert.bert_model.encoder.layer.4.attention.output.LayerNorm.weight
2021-05-12 00:22:57,154 - INFO - allennlp.nn.initializers -    text_field_embedder.token_embedder_bert.bert_model.encoder.layer.4.attention.output.dense.bias
2021-05-12 00:22:57,154 - INFO - allennlp.nn.initializers -    text_field_embedder.token_embedder_bert.bert_model.encoder.layer.4.attention.output.dense.weight
2021-05-12 00:22:57,154 - INFO - allennlp.nn.initializers -    text_field_embedder.token_embedder_bert.bert_model.encoder.layer.4.attention.self.key.bias
2021-05-12 00:22:57,154 - INFO - allennlp.nn.initializers -    text_field_embedder.token_embedder_bert.bert_model.encoder.layer.4.attention.self.key.weight
2021-05-12 00:22:57,154 - INFO - allennlp.nn.initializers -    text_field_embedder.token_embedder_bert.bert_model.encoder.layer.4.attention.self.query.bias
2021-05-12 00:22:57,154 - INFO - allennlp.nn.initializers -    text_field_embedder.token_embedder_bert.bert_model.encoder.layer.4.attention.self.query.weight
2021-05-12 00:22:57,154 - INFO - allennlp.nn.initializers -    text_field_embedder.token_embedder_bert.bert_model.encoder.layer.4.attention.self.value.bias
2021-05-12 00:22:57,154 - INFO - allennlp.nn.initializers -    text_field_embedder.token_embedder_bert.bert_model.encoder.layer.4.attention.self.value.weight
2021-05-12 00:22:57,154 - INFO - allennlp.nn.initializers -    text_field_embedder.token_embedder_bert.bert_model.encoder.layer.4.intermediate.dense.bias
2021-05-12 00:22:57,154 - INFO - allennlp.nn.initializers -    text_field_embedder.token_embedder_bert.bert_model.encoder.layer.4.intermediate.dense.weight
2021-05-12 00:22:57,154 - INFO - allennlp.nn.initializers -    text_field_embedder.token_embedder_bert.bert_model.encoder.layer.4.output.LayerNorm.bias
2021-05-12 00:22:57,155 - INFO - allennlp.nn.initializers -    text_field_embedder.token_embedder_bert.bert_model.encoder.layer.4.output.LayerNorm.weight
2021-05-12 00:22:57,155 - INFO - allennlp.nn.initializers -    text_field_embedder.token_embedder_bert.bert_model.encoder.layer.4.output.dense.bias
2021-05-12 00:22:57,155 - INFO - allennlp.nn.initializers -    text_field_embedder.token_embedder_bert.bert_model.encoder.layer.4.output.dense.weight
2021-05-12 00:22:57,155 - INFO - allennlp.nn.initializers -    text_field_embedder.token_embedder_bert.bert_model.encoder.layer.5.attention.output.LayerNorm.bias
2021-05-12 00:22:57,155 - INFO - allennlp.nn.initializers -    text_field_embedder.token_embedder_bert.bert_model.encoder.layer.5.attention.output.LayerNorm.weight
2021-05-12 00:22:57,155 - INFO - allennlp.nn.initializers -    text_field_embedder.token_embedder_bert.bert_model.encoder.layer.5.attention.output.dense.bias
2021-05-12 00:22:57,155 - INFO - allennlp.nn.initializers -    text_field_embedder.token_embedder_bert.bert_model.encoder.layer.5.attention.output.dense.weight
2021-05-12 00:22:57,155 - INFO - allennlp.nn.initializers -    text_field_embedder.token_embedder_bert.bert_model.encoder.layer.5.attention.self.key.bias
2021-05-12 00:22:57,155 - INFO - allennlp.nn.initializers -    text_field_embedder.token_embedder_bert.bert_model.encoder.layer.5.attention.self.key.weight
2021-05-12 00:22:57,155 - INFO - allennlp.nn.initializers -    text_field_embedder.token_embedder_bert.bert_model.encoder.layer.5.attention.self.query.bias
2021-05-12 00:22:57,155 - INFO - allennlp.nn.initializers -    text_field_embedder.token_embedder_bert.bert_model.encoder.layer.5.attention.self.query.weight
2021-05-12 00:22:57,155 - INFO - allennlp.nn.initializers -    text_field_embedder.token_embedder_bert.bert_model.encoder.layer.5.attention.self.value.bias
2021-05-12 00:22:57,155 - INFO - allennlp.nn.initializers -    text_field_embedder.token_embedder_bert.bert_model.encoder.layer.5.attention.self.value.weight
2021-05-12 00:22:57,155 - INFO - allennlp.nn.initializers -    text_field_embedder.token_embedder_bert.bert_model.encoder.layer.5.intermediate.dense.bias
2021-05-12 00:22:57,155 - INFO - allennlp.nn.initializers -    text_field_embedder.token_embedder_bert.bert_model.encoder.layer.5.intermediate.dense.weight
2021-05-12 00:22:57,155 - INFO - allennlp.nn.initializers -    text_field_embedder.token_embedder_bert.bert_model.encoder.layer.5.output.LayerNorm.bias
2021-05-12 00:22:57,155 - INFO - allennlp.nn.initializers -    text_field_embedder.token_embedder_bert.bert_model.encoder.layer.5.output.LayerNorm.weight
2021-05-12 00:22:57,155 - INFO - allennlp.nn.initializers -    text_field_embedder.token_embedder_bert.bert_model.encoder.layer.5.output.dense.bias
2021-05-12 00:22:57,156 - INFO - allennlp.nn.initializers -    text_field_embedder.token_embedder_bert.bert_model.encoder.layer.5.output.dense.weight
2021-05-12 00:22:57,156 - INFO - allennlp.nn.initializers -    text_field_embedder.token_embedder_bert.bert_model.encoder.layer.6.attention.output.LayerNorm.bias
2021-05-12 00:22:57,156 - INFO - allennlp.nn.initializers -    text_field_embedder.token_embedder_bert.bert_model.encoder.layer.6.attention.output.LayerNorm.weight
2021-05-12 00:22:57,156 - INFO - allennlp.nn.initializers -    text_field_embedder.token_embedder_bert.bert_model.encoder.layer.6.attention.output.dense.bias
2021-05-12 00:22:57,156 - INFO - allennlp.nn.initializers -    text_field_embedder.token_embedder_bert.bert_model.encoder.layer.6.attention.output.dense.weight
2021-05-12 00:22:57,156 - INFO - allennlp.nn.initializers -    text_field_embedder.token_embedder_bert.bert_model.encoder.layer.6.attention.self.key.bias
2021-05-12 00:22:57,156 - INFO - allennlp.nn.initializers -    text_field_embedder.token_embedder_bert.bert_model.encoder.layer.6.attention.self.key.weight
2021-05-12 00:22:57,156 - INFO - allennlp.nn.initializers -    text_field_embedder.token_embedder_bert.bert_model.encoder.layer.6.attention.self.query.bias
2021-05-12 00:22:57,156 - INFO - allennlp.nn.initializers -    text_field_embedder.token_embedder_bert.bert_model.encoder.layer.6.attention.self.query.weight
2021-05-12 00:22:57,156 - INFO - allennlp.nn.initializers -    text_field_embedder.token_embedder_bert.bert_model.encoder.layer.6.attention.self.value.bias
2021-05-12 00:22:57,156 - INFO - allennlp.nn.initializers -    text_field_embedder.token_embedder_bert.bert_model.encoder.layer.6.attention.self.value.weight
2021-05-12 00:22:57,156 - INFO - allennlp.nn.initializers -    text_field_embedder.token_embedder_bert.bert_model.encoder.layer.6.intermediate.dense.bias
2021-05-12 00:22:57,156 - INFO - allennlp.nn.initializers -    text_field_embedder.token_embedder_bert.bert_model.encoder.layer.6.intermediate.dense.weight
2021-05-12 00:22:57,156 - INFO - allennlp.nn.initializers -    text_field_embedder.token_embedder_bert.bert_model.encoder.layer.6.output.LayerNorm.bias
2021-05-12 00:22:57,156 - INFO - allennlp.nn.initializers -    text_field_embedder.token_embedder_bert.bert_model.encoder.layer.6.output.LayerNorm.weight
2021-05-12 00:22:57,156 - INFO - allennlp.nn.initializers -    text_field_embedder.token_embedder_bert.bert_model.encoder.layer.6.output.dense.bias
2021-05-12 00:22:57,156 - INFO - allennlp.nn.initializers -    text_field_embedder.token_embedder_bert.bert_model.encoder.layer.6.output.dense.weight
2021-05-12 00:22:57,156 - INFO - allennlp.nn.initializers -    text_field_embedder.token_embedder_bert.bert_model.encoder.layer.7.attention.output.LayerNorm.bias
2021-05-12 00:22:57,157 - INFO - allennlp.nn.initializers -    text_field_embedder.token_embedder_bert.bert_model.encoder.layer.7.attention.output.LayerNorm.weight
2021-05-12 00:22:57,157 - INFO - allennlp.nn.initializers -    text_field_embedder.token_embedder_bert.bert_model.encoder.layer.7.attention.output.dense.bias
2021-05-12 00:22:57,157 - INFO - allennlp.nn.initializers -    text_field_embedder.token_embedder_bert.bert_model.encoder.layer.7.attention.output.dense.weight
2021-05-12 00:22:57,157 - INFO - allennlp.nn.initializers -    text_field_embedder.token_embedder_bert.bert_model.encoder.layer.7.attention.self.key.bias
2021-05-12 00:22:57,157 - INFO - allennlp.nn.initializers -    text_field_embedder.token_embedder_bert.bert_model.encoder.layer.7.attention.self.key.weight
2021-05-12 00:22:57,157 - INFO - allennlp.nn.initializers -    text_field_embedder.token_embedder_bert.bert_model.encoder.layer.7.attention.self.query.bias
2021-05-12 00:22:57,157 - INFO - allennlp.nn.initializers -    text_field_embedder.token_embedder_bert.bert_model.encoder.layer.7.attention.self.query.weight
2021-05-12 00:22:57,157 - INFO - allennlp.nn.initializers -    text_field_embedder.token_embedder_bert.bert_model.encoder.layer.7.attention.self.value.bias
2021-05-12 00:22:57,157 - INFO - allennlp.nn.initializers -    text_field_embedder.token_embedder_bert.bert_model.encoder.layer.7.attention.self.value.weight
2021-05-12 00:22:57,157 - INFO - allennlp.nn.initializers -    text_field_embedder.token_embedder_bert.bert_model.encoder.layer.7.intermediate.dense.bias
2021-05-12 00:22:57,157 - INFO - allennlp.nn.initializers -    text_field_embedder.token_embedder_bert.bert_model.encoder.layer.7.intermediate.dense.weight
2021-05-12 00:22:57,157 - INFO - allennlp.nn.initializers -    text_field_embedder.token_embedder_bert.bert_model.encoder.layer.7.output.LayerNorm.bias
2021-05-12 00:22:57,157 - INFO - allennlp.nn.initializers -    text_field_embedder.token_embedder_bert.bert_model.encoder.layer.7.output.LayerNorm.weight
2021-05-12 00:22:57,157 - INFO - allennlp.nn.initializers -    text_field_embedder.token_embedder_bert.bert_model.encoder.layer.7.output.dense.bias
2021-05-12 00:22:57,157 - INFO - allennlp.nn.initializers -    text_field_embedder.token_embedder_bert.bert_model.encoder.layer.7.output.dense.weight
2021-05-12 00:22:57,157 - INFO - allennlp.nn.initializers -    text_field_embedder.token_embedder_bert.bert_model.encoder.layer.8.attention.output.LayerNorm.bias
2021-05-12 00:22:57,157 - INFO - allennlp.nn.initializers -    text_field_embedder.token_embedder_bert.bert_model.encoder.layer.8.attention.output.LayerNorm.weight
2021-05-12 00:22:57,158 - INFO - allennlp.nn.initializers -    text_field_embedder.token_embedder_bert.bert_model.encoder.layer.8.attention.output.dense.bias
2021-05-12 00:22:57,158 - INFO - allennlp.nn.initializers -    text_field_embedder.token_embedder_bert.bert_model.encoder.layer.8.attention.output.dense.weight
2021-05-12 00:22:57,158 - INFO - allennlp.nn.initializers -    text_field_embedder.token_embedder_bert.bert_model.encoder.layer.8.attention.self.key.bias
2021-05-12 00:22:57,158 - INFO - allennlp.nn.initializers -    text_field_embedder.token_embedder_bert.bert_model.encoder.layer.8.attention.self.key.weight
2021-05-12 00:22:57,158 - INFO - allennlp.nn.initializers -    text_field_embedder.token_embedder_bert.bert_model.encoder.layer.8.attention.self.query.bias
2021-05-12 00:22:57,158 - INFO - allennlp.nn.initializers -    text_field_embedder.token_embedder_bert.bert_model.encoder.layer.8.attention.self.query.weight
2021-05-12 00:22:57,158 - INFO - allennlp.nn.initializers -    text_field_embedder.token_embedder_bert.bert_model.encoder.layer.8.attention.self.value.bias
2021-05-12 00:22:57,158 - INFO - allennlp.nn.initializers -    text_field_embedder.token_embedder_bert.bert_model.encoder.layer.8.attention.self.value.weight
2021-05-12 00:22:57,158 - INFO - allennlp.nn.initializers -    text_field_embedder.token_embedder_bert.bert_model.encoder.layer.8.intermediate.dense.bias
2021-05-12 00:22:57,158 - INFO - allennlp.nn.initializers -    text_field_embedder.token_embedder_bert.bert_model.encoder.layer.8.intermediate.dense.weight
2021-05-12 00:22:57,158 - INFO - allennlp.nn.initializers -    text_field_embedder.token_embedder_bert.bert_model.encoder.layer.8.output.LayerNorm.bias
2021-05-12 00:22:57,158 - INFO - allennlp.nn.initializers -    text_field_embedder.token_embedder_bert.bert_model.encoder.layer.8.output.LayerNorm.weight
2021-05-12 00:22:57,158 - INFO - allennlp.nn.initializers -    text_field_embedder.token_embedder_bert.bert_model.encoder.layer.8.output.dense.bias
2021-05-12 00:22:57,158 - INFO - allennlp.nn.initializers -    text_field_embedder.token_embedder_bert.bert_model.encoder.layer.8.output.dense.weight
2021-05-12 00:22:57,158 - INFO - allennlp.nn.initializers -    text_field_embedder.token_embedder_bert.bert_model.encoder.layer.9.attention.output.LayerNorm.bias
2021-05-12 00:22:57,158 - INFO - allennlp.nn.initializers -    text_field_embedder.token_embedder_bert.bert_model.encoder.layer.9.attention.output.LayerNorm.weight
2021-05-12 00:22:57,158 - INFO - allennlp.nn.initializers -    text_field_embedder.token_embedder_bert.bert_model.encoder.layer.9.attention.output.dense.bias
2021-05-12 00:22:57,158 - INFO - allennlp.nn.initializers -    text_field_embedder.token_embedder_bert.bert_model.encoder.layer.9.attention.output.dense.weight
2021-05-12 00:22:57,159 - INFO - allennlp.nn.initializers -    text_field_embedder.token_embedder_bert.bert_model.encoder.layer.9.attention.self.key.bias
2021-05-12 00:22:57,159 - INFO - allennlp.nn.initializers -    text_field_embedder.token_embedder_bert.bert_model.encoder.layer.9.attention.self.key.weight
2021-05-12 00:22:57,159 - INFO - allennlp.nn.initializers -    text_field_embedder.token_embedder_bert.bert_model.encoder.layer.9.attention.self.query.bias
2021-05-12 00:22:57,159 - INFO - allennlp.nn.initializers -    text_field_embedder.token_embedder_bert.bert_model.encoder.layer.9.attention.self.query.weight
2021-05-12 00:22:57,159 - INFO - allennlp.nn.initializers -    text_field_embedder.token_embedder_bert.bert_model.encoder.layer.9.attention.self.value.bias
2021-05-12 00:22:57,159 - INFO - allennlp.nn.initializers -    text_field_embedder.token_embedder_bert.bert_model.encoder.layer.9.attention.self.value.weight
2021-05-12 00:22:57,159 - INFO - allennlp.nn.initializers -    text_field_embedder.token_embedder_bert.bert_model.encoder.layer.9.intermediate.dense.bias
2021-05-12 00:22:57,159 - INFO - allennlp.nn.initializers -    text_field_embedder.token_embedder_bert.bert_model.encoder.layer.9.intermediate.dense.weight
2021-05-12 00:22:57,159 - INFO - allennlp.nn.initializers -    text_field_embedder.token_embedder_bert.bert_model.encoder.layer.9.output.LayerNorm.bias
2021-05-12 00:22:57,159 - INFO - allennlp.nn.initializers -    text_field_embedder.token_embedder_bert.bert_model.encoder.layer.9.output.LayerNorm.weight
2021-05-12 00:22:57,159 - INFO - allennlp.nn.initializers -    text_field_embedder.token_embedder_bert.bert_model.encoder.layer.9.output.dense.bias
2021-05-12 00:22:57,159 - INFO - allennlp.nn.initializers -    text_field_embedder.token_embedder_bert.bert_model.encoder.layer.9.output.dense.weight
2021-05-12 00:22:57,159 - INFO - allennlp.nn.initializers -    text_field_embedder.token_embedder_bert.bert_model.pooler.dense.bias
2021-05-12 00:22:57,159 - INFO - allennlp.nn.initializers -    text_field_embedder.token_embedder_bert.bert_model.pooler.dense.weight
2021-05-12 00:22:57,165 - INFO - udify.models.udify_model - Total number of parameters: 198563643
2021-05-12 00:22:57,165 - INFO - udify.models.udify_model - Total number of trainable parameters: 198563643
2021-05-12 00:22:57,168 - INFO - filelock - Lock 22396712760848 acquired on logs/bert_finetune_en/2021.05.12_00.22.24/vocabulary/.lock
2021-05-12 00:22:59,530 - INFO - filelock - Lock 22396712760848 released on logs/bert_finetune_en/2021.05.12_00.22.24/vocabulary/.lock
2021-05-12 00:22:59,530 - INFO - allennlp.common.params - data_loader.type = pytorch_dataloader
2021-05-12 00:22:59,531 - INFO - allennlp.common.params - data_loader.batch_size = 1
2021-05-12 00:22:59,531 - INFO - allennlp.common.params - data_loader.shuffle = False
2021-05-12 00:22:59,532 - INFO - allennlp.common.params - data_loader.sampler = None
2021-05-12 00:22:59,532 - INFO - allennlp.common.params - data_loader.num_workers = 0
2021-05-12 00:22:59,532 - INFO - allennlp.common.params - data_loader.pin_memory = False
2021-05-12 00:22:59,533 - INFO - allennlp.common.params - data_loader.drop_last = False
2021-05-12 00:22:59,533 - INFO - allennlp.common.params - data_loader.timeout = 0
2021-05-12 00:22:59,533 - INFO - allennlp.common.params - data_loader.worker_init_fn = None
2021-05-12 00:22:59,533 - INFO - allennlp.common.params - data_loader.multiprocessing_context = None
2021-05-12 00:22:59,533 - INFO - allennlp.common.params - data_loader.batches_per_epoch = None
2021-05-12 00:22:59,534 - INFO - allennlp.common.params - data_loader.batch_sampler.type = bucket
2021-05-12 00:22:59,534 - INFO - allennlp.common.params - data_loader.batch_sampler.batch_size = 16
2021-05-12 00:22:59,534 - INFO - allennlp.common.params - data_loader.batch_sampler.sorting_keys = None
2021-05-12 00:22:59,535 - INFO - allennlp.common.params - data_loader.batch_sampler.padding_noise = 0.1
2021-05-12 00:22:59,535 - INFO - allennlp.common.params - data_loader.batch_sampler.drop_last = False
2021-05-12 00:22:59,536 - INFO - allennlp.common.params - data_loader.type = pytorch_dataloader
2021-05-12 00:22:59,537 - INFO - allennlp.common.params - data_loader.batch_size = 1
2021-05-12 00:22:59,537 - INFO - allennlp.common.params - data_loader.shuffle = False
2021-05-12 00:22:59,537 - INFO - allennlp.common.params - data_loader.sampler = None
2021-05-12 00:22:59,538 - INFO - allennlp.common.params - data_loader.num_workers = 0
2021-05-12 00:22:59,538 - INFO - allennlp.common.params - data_loader.pin_memory = False
2021-05-12 00:22:59,538 - INFO - allennlp.common.params - data_loader.drop_last = False
2021-05-12 00:22:59,538 - INFO - allennlp.common.params - data_loader.timeout = 0
2021-05-12 00:22:59,538 - INFO - allennlp.common.params - data_loader.worker_init_fn = None
2021-05-12 00:22:59,538 - INFO - allennlp.common.params - data_loader.multiprocessing_context = None
2021-05-12 00:22:59,539 - INFO - allennlp.common.params - data_loader.batches_per_epoch = None
2021-05-12 00:22:59,539 - INFO - allennlp.common.params - data_loader.batch_sampler.type = bucket
2021-05-12 00:22:59,539 - INFO - allennlp.common.params - data_loader.batch_sampler.batch_size = 16
2021-05-12 00:22:59,539 - INFO - allennlp.common.params - data_loader.batch_sampler.sorting_keys = None
2021-05-12 00:22:59,540 - INFO - allennlp.common.params - data_loader.batch_sampler.padding_noise = 0.1
2021-05-12 00:22:59,540 - INFO - allennlp.common.params - data_loader.batch_sampler.drop_last = False
2021-05-12 00:22:59,540 - INFO - allennlp.common.params - data_loader.type = pytorch_dataloader
2021-05-12 00:22:59,541 - INFO - allennlp.common.params - data_loader.batch_size = 1
2021-05-12 00:22:59,541 - INFO - allennlp.common.params - data_loader.shuffle = False
2021-05-12 00:22:59,541 - INFO - allennlp.common.params - data_loader.sampler = None
2021-05-12 00:22:59,541 - INFO - allennlp.common.params - data_loader.num_workers = 0
2021-05-12 00:22:59,541 - INFO - allennlp.common.params - data_loader.pin_memory = False
2021-05-12 00:22:59,542 - INFO - allennlp.common.params - data_loader.drop_last = False
2021-05-12 00:22:59,542 - INFO - allennlp.common.params - data_loader.timeout = 0
2021-05-12 00:22:59,542 - INFO - allennlp.common.params - data_loader.worker_init_fn = None
2021-05-12 00:22:59,542 - INFO - allennlp.common.params - data_loader.multiprocessing_context = None
2021-05-12 00:22:59,542 - INFO - allennlp.common.params - data_loader.batches_per_epoch = None
2021-05-12 00:22:59,542 - INFO - allennlp.common.params - data_loader.batch_sampler.type = bucket
2021-05-12 00:22:59,543 - INFO - allennlp.common.params - data_loader.batch_sampler.batch_size = 16
2021-05-12 00:22:59,543 - INFO - allennlp.common.params - data_loader.batch_sampler.sorting_keys = None
2021-05-12 00:22:59,543 - INFO - allennlp.common.params - data_loader.batch_sampler.padding_noise = 0.1
2021-05-12 00:22:59,543 - INFO - allennlp.common.params - data_loader.batch_sampler.drop_last = False
2021-05-12 00:22:59,544 - INFO - allennlp.common.params - trainer.type = gradient_descent
2021-05-12 00:22:59,544 - INFO - allennlp.common.params - trainer.patience = 40
2021-05-12 00:22:59,545 - INFO - allennlp.common.params - trainer.validation_metric = +.run/.sum
2021-05-12 00:22:59,545 - INFO - allennlp.common.params - trainer.num_epochs = 5
2021-05-12 00:22:59,545 - INFO - allennlp.common.params - trainer.cuda_device = 0
2021-05-12 00:22:59,545 - INFO - allennlp.common.params - trainer.grad_norm = 5
2021-05-12 00:22:59,545 - INFO - allennlp.common.params - trainer.grad_clipping = 10
2021-05-12 00:22:59,545 - INFO - allennlp.common.params - trainer.distributed = False
2021-05-12 00:22:59,545 - INFO - allennlp.common.params - trainer.world_size = 1
2021-05-12 00:22:59,546 - INFO - allennlp.common.params - trainer.num_gradient_accumulation_steps = 1
2021-05-12 00:22:59,546 - INFO - allennlp.common.params - trainer.use_amp = False
2021-05-12 00:22:59,546 - INFO - allennlp.common.params - trainer.no_grad = None
2021-05-12 00:22:59,546 - INFO - allennlp.common.params - trainer.momentum_scheduler = None
2021-05-12 00:22:59,547 - INFO - allennlp.common.params - trainer.tensorboard_writer = <allennlp.common.lazy.Lazy object at 0x145ec150cac0>
2021-05-12 00:22:59,547 - INFO - allennlp.common.params - trainer.moving_average = None
2021-05-12 00:22:59,547 - INFO - allennlp.common.params - trainer.checkpointer = <allennlp.common.lazy.Lazy object at 0x145ec150cbb0>
2021-05-12 00:22:59,547 - INFO - allennlp.common.params - trainer.batch_callbacks = None
2021-05-12 00:22:59,547 - INFO - allennlp.common.params - trainer.epoch_callbacks = None
2021-05-12 00:22:59,547 - INFO - allennlp.common.params - trainer.end_callbacks = None
2021-05-12 00:22:59,547 - INFO - allennlp.common.params - trainer.trainer_callbacks = None
2021-05-12 00:23:03,433 - INFO - allennlp.common.params - trainer.optimizer.type = adamw
2021-05-12 00:23:03,434 - INFO - allennlp.common.params - trainer.optimizer.lr = 0.001
2021-05-12 00:23:03,434 - INFO - allennlp.common.params - trainer.optimizer.betas = [0.9, 0.99]
2021-05-12 00:23:03,434 - INFO - allennlp.common.params - trainer.optimizer.eps = 1e-08
2021-05-12 00:23:03,434 - INFO - allennlp.common.params - trainer.optimizer.weight_decay = 0.01
2021-05-12 00:23:03,434 - INFO - allennlp.common.params - trainer.optimizer.amsgrad = False
2021-05-12 00:23:03,441 - INFO - allennlp.training.optimizers - Done constructing parameter groups.
2021-05-12 00:23:03,441 - INFO - allennlp.training.optimizers - Group 0: ['text_field_embedder.token_embedder_bert.bert_model.encoder.layer.11.attention.output.LayerNorm.bias', 'text_field_embedder.token_embedder_bert.bert_model.encoder.layer.2.intermediate.dense.bias', 'text_field_embedder.token_embedder_bert.bert_model.encoder.layer.10.attention.output.dense.weight', 'text_field_embedder.token_embedder_bert.bert_model.encoder.layer.1.attention.self.query.weight', 'text_field_embedder.token_embedder_bert.bert_model.encoder.layer.6.attention.output.dense.weight', 'text_field_embedder.token_embedder_bert.bert_model.encoder.layer.11.attention.output.dense.weight', 'text_field_embedder.token_embedder_bert.bert_model.encoder.layer.6.attention.output.dense.bias', 'text_field_embedder.token_embedder_bert.bert_model.encoder.layer.8.attention.output.dense.bias', 'text_field_embedder.token_embedder_bert.bert_model.encoder.layer.8.output.LayerNorm.bias', 'text_field_embedder.token_embedder_bert.bert_model.encoder.layer.1.attention.output.dense.weight', 'text_field_embedder.token_embedder_bert.bert_model.encoder.layer.9.attention.self.query.weight', 'text_field_embedder.token_embedder_bert.bert_model.encoder.layer.11.attention.self.key.weight', 'text_field_embedder.token_embedder_bert.bert_model.encoder.layer.4.attention.self.query.bias', 'text_field_embedder.token_embedder_bert.bert_model.encoder.layer.11.output.LayerNorm.bias', 'text_field_embedder.token_embedder_bert.bert_model.encoder.layer.9.intermediate.dense.weight', 'text_field_embedder.token_embedder_bert.bert_model.encoder.layer.11.attention.self.key.bias', 'text_field_embedder.token_embedder_bert.bert_model.encoder.layer.9.attention.self.query.bias', 'text_field_embedder.token_embedder_bert.bert_model.encoder.layer.8.attention.self.value.bias', 'text_field_embedder.token_embedder_bert.bert_model.encoder.layer.10.attention.output.LayerNorm.weight', 'text_field_embedder.token_embedder_bert.bert_model.encoder.layer.10.attention.self.value.weight', 'text_field_embedder.token_embedder_bert.bert_model.encoder.layer.2.attention.self.query.weight', 'text_field_embedder.token_embedder_bert.bert_model.encoder.layer.3.output.LayerNorm.bias', 'text_field_embedder.token_embedder_bert.bert_model.encoder.layer.3.attention.self.value.weight', 'text_field_embedder.token_embedder_bert.bert_model.encoder.layer.10.output.dense.weight', 'text_field_embedder.token_embedder_bert.bert_model.encoder.layer.1.attention.self.key.weight', 'text_field_embedder.token_embedder_bert.bert_model.encoder.layer.10.intermediate.dense.bias', 'text_field_embedder.token_embedder_bert.bert_model.encoder.layer.8.output.dense.weight', 'text_field_embedder.token_embedder_bert.bert_model.encoder.layer.1.output.dense.weight', 'text_field_embedder.token_embedder_bert.bert_model.encoder.layer.8.output.LayerNorm.weight', 'text_field_embedder.token_embedder_bert.bert_model.embeddings.LayerNorm.weight', 'text_field_embedder.token_embedder_bert.bert_model.encoder.layer.3.intermediate.dense.weight', 'text_field_embedder.token_embedder_bert.bert_model.encoder.layer.10.attention.self.query.weight', 'text_field_embedder.token_embedder_bert.bert_model.encoder.layer.6.output.dense.weight', 'text_field_embedder.token_embedder_bert.bert_model.encoder.layer.7.attention.self.query.weight', 'text_field_embedder.token_embedder_bert.bert_model.encoder.layer.11.attention.self.query.bias', 'text_field_embedder.token_embedder_bert.bert_model.encoder.layer.5.output.LayerNorm.bias', 'text_field_embedder.token_embedder_bert.bert_model.encoder.layer.6.output.LayerNorm.weight', 'text_field_embedder.token_embedder_bert.bert_model.encoder.layer.5.attention.self.query.bias', 'text_field_embedder.token_embedder_bert.bert_model.encoder.layer.0.attention.output.LayerNorm.weight', 'text_field_embedder.token_embedder_bert.bert_model.encoder.layer.2.intermediate.dense.weight', 'text_field_embedder.token_embedder_bert.bert_model.encoder.layer.0.output.LayerNorm.weight', 'text_field_embedder.token_embedder_bert.bert_model.encoder.layer.8.output.dense.bias', 'text_field_embedder.token_embedder_bert.bert_model.encoder.layer.5.output.LayerNorm.weight', 'text_field_embedder.token_embedder_bert.bert_model.encoder.layer.1.attention.self.value.bias', 'text_field_embedder.token_embedder_bert.bert_model.encoder.layer.5.output.dense.weight', 'text_field_embedder.token_embedder_bert.bert_model.encoder.layer.11.intermediate.dense.bias', 'text_field_embedder.token_embedder_bert.bert_model.encoder.layer.6.attention.self.key.bias', 'text_field_embedder.token_embedder_bert.bert_model.encoder.layer.8.attention.output.LayerNorm.weight', 'text_field_embedder.token_embedder_bert.bert_model.encoder.layer.0.attention.output.dense.weight', 'text_field_embedder.token_embedder_bert.bert_model.encoder.layer.4.attention.self.value.weight', 'text_field_embedder.token_embedder_bert.bert_model.encoder.layer.3.attention.output.LayerNorm.weight', 'text_field_embedder.token_embedder_bert.bert_model.encoder.layer.5.attention.output.LayerNorm.bias', 'text_field_embedder.token_embedder_bert.bert_model.encoder.layer.9.output.dense.bias', 'text_field_embedder.token_embedder_bert.bert_model.encoder.layer.2.output.dense.bias', 'text_field_embedder.token_embedder_bert.bert_model.encoder.layer.6.attention.self.value.bias', 'text_field_embedder.token_embedder_bert.bert_model.encoder.layer.1.intermediate.dense.weight', 'text_field_embedder.token_embedder_bert.bert_model.encoder.layer.5.intermediate.dense.bias', 'text_field_embedder.token_embedder_bert.bert_model.encoder.layer.4.attention.output.dense.bias', 'text_field_embedder.token_embedder_bert.bert_model.encoder.layer.7.intermediate.dense.weight', 'text_field_embedder.token_embedder_bert.bert_model.encoder.layer.2.attention.self.key.bias', 'text_field_embedder.token_embedder_bert.bert_model.encoder.layer.0.intermediate.dense.bias', 'text_field_embedder.token_embedder_bert.bert_model.encoder.layer.9.attention.output.dense.bias', 'text_field_embedder.token_embedder_bert.bert_model.encoder.layer.11.intermediate.dense.weight', 'text_field_embedder.token_embedder_bert.bert_model.encoder.layer.3.attention.self.key.weight', 'text_field_embedder.token_embedder_bert.bert_model.encoder.layer.7.output.LayerNorm.bias', 'text_field_embedder.token_embedder_bert.bert_model.encoder.layer.4.output.LayerNorm.bias', 'text_field_embedder.token_embedder_bert.bert_model.encoder.layer.2.attention.output.LayerNorm.weight', 'text_field_embedder.token_embedder_bert.bert_model.encoder.layer.3.attention.output.LayerNorm.bias', 'text_field_embedder.token_embedder_bert.bert_model.encoder.layer.8.attention.self.query.bias', 'text_field_embedder.token_embedder_bert.bert_model.encoder.layer.4.output.dense.bias', 'text_field_embedder.token_embedder_bert.bert_model.encoder.layer.6.output.LayerNorm.bias', 'text_field_embedder.token_embedder_bert.bert_model.encoder.layer.1.output.LayerNorm.weight', 'text_field_embedder.token_embedder_bert.bert_model.encoder.layer.0.intermediate.dense.weight', 'text_field_embedder.token_embedder_bert.bert_model.encoder.layer.5.attention.self.value.weight', 'text_field_embedder.token_embedder_bert.bert_model.encoder.layer.6.intermediate.dense.weight', 'text_field_embedder.token_embedder_bert.bert_model.encoder.layer.7.intermediate.dense.bias', 'text_field_embedder.token_embedder_bert.bert_model.embeddings.LayerNorm.bias', 'text_field_embedder.token_embedder_bert.bert_model.encoder.layer.10.attention.self.value.bias', 'text_field_embedder.token_embedder_bert.bert_model.encoder.layer.6.output.dense.bias', 'text_field_embedder.token_embedder_bert.bert_model.encoder.layer.3.intermediate.dense.bias', 'text_field_embedder.token_embedder_bert.bert_model.encoder.layer.1.intermediate.dense.bias', 'text_field_embedder.token_embedder_bert.bert_model.encoder.layer.2.attention.output.dense.weight', 'text_field_embedder.token_embedder_bert.bert_model.encoder.layer.5.attention.output.dense.weight', 'text_field_embedder.token_embedder_bert.bert_model.encoder.layer.7.attention.output.LayerNorm.bias', 'text_field_embedder.token_embedder_bert.bert_model.encoder.layer.8.attention.output.LayerNorm.bias', 'text_field_embedder.token_embedder_bert.bert_model.encoder.layer.10.attention.self.query.bias', 'text_field_embedder.token_embedder_bert.bert_model.encoder.layer.9.intermediate.dense.bias', 'text_field_embedder.token_embedder_bert.bert_model.encoder.layer.3.output.LayerNorm.weight', 'text_field_embedder.token_embedder_bert.bert_model.encoder.layer.0.attention.self.key.bias', 'text_field_embedder.token_embedder_bert.bert_model.encoder.layer.3.attention.output.dense.weight', 'text_field_embedder.token_embedder_bert.bert_model.encoder.layer.11.attention.self.value.weight', 'text_field_embedder.token_embedder_bert.bert_model.encoder.layer.0.attention.self.key.weight', 'text_field_embedder.token_embedder_bert.bert_model.encoder.layer.7.attention.output.LayerNorm.weight', 'text_field_embedder.token_embedder_bert.bert_model.encoder.layer.1.attention.output.LayerNorm.bias', 'text_field_embedder.token_embedder_bert.bert_model.encoder.layer.5.attention.self.key.weight', 'text_field_embedder.token_embedder_bert.bert_model.encoder.layer.2.attention.self.value.bias', 'text_field_embedder.token_embedder_bert.bert_model.encoder.layer.1.attention.self.value.weight', 'text_field_embedder.token_embedder_bert.bert_model.encoder.layer.10.attention.self.key.weight', 'text_field_embedder.token_embedder_bert.bert_model.encoder.layer.6.attention.self.value.weight', 'text_field_embedder.token_embedder_bert.bert_model.encoder.layer.3.output.dense.bias', 'text_field_embedder.token_embedder_bert.bert_model.encoder.layer.7.attention.self.key.weight', 'text_field_embedder.token_embedder_bert.bert_model.encoder.layer.3.attention.output.dense.bias', 'text_field_embedder.token_embedder_bert.bert_model.encoder.layer.5.attention.self.value.bias', 'text_field_embedder.token_embedder_bert.bert_model.encoder.layer.7.attention.output.dense.bias', 'text_field_embedder.token_embedder_bert.bert_model.encoder.layer.1.output.LayerNorm.bias', 'text_field_embedder.token_embedder_bert.bert_model.encoder.layer.9.output.dense.weight', 'text_field_embedder.token_embedder_bert.bert_model.encoder.layer.7.attention.self.query.bias', 'text_field_embedder.token_embedder_bert.bert_model.encoder.layer.2.attention.output.dense.bias', 'text_field_embedder.token_embedder_bert.bert_model.encoder.layer.0.attention.output.LayerNorm.bias', 'text_field_embedder.token_embedder_bert.bert_model.encoder.layer.5.output.dense.bias', 'text_field_embedder.token_embedder_bert.bert_model.encoder.layer.11.output.LayerNorm.weight', 'text_field_embedder.token_embedder_bert.bert_model.encoder.layer.9.attention.output.LayerNorm.bias', 'text_field_embedder.token_embedder_bert.bert_model.encoder.layer.0.output.dense.weight', 'text_field_embedder.token_embedder_bert.bert_model.encoder.layer.2.output.LayerNorm.bias', 'text_field_embedder.token_embedder_bert.bert_model.encoder.layer.4.attention.output.LayerNorm.weight', 'text_field_embedder.token_embedder_bert.bert_model.encoder.layer.5.attention.output.dense.bias', 'text_field_embedder.token_embedder_bert.bert_model.encoder.layer.11.output.dense.weight', 'text_field_embedder.token_embedder_bert.bert_model.encoder.layer.6.attention.self.query.weight', 'text_field_embedder.token_embedder_bert.bert_model.encoder.layer.0.output.LayerNorm.bias', 'text_field_embedder.token_embedder_bert.bert_model.encoder.layer.9.attention.self.value.weight', 'text_field_embedder.token_embedder_bert.bert_model.encoder.layer.0.attention.self.query.bias', 'text_field_embedder.token_embedder_bert.bert_model.encoder.layer.6.attention.output.LayerNorm.bias', 'text_field_embedder.token_embedder_bert.bert_model.encoder.layer.10.output.LayerNorm.bias', 'text_field_embedder.token_embedder_bert.bert_model.encoder.layer.1.output.dense.bias', 'text_field_embedder.token_embedder_bert.bert_model.encoder.layer.6.attention.self.key.weight', 'text_field_embedder.token_embedder_bert.bert_model.encoder.layer.11.output.dense.bias', 'text_field_embedder.token_embedder_bert.bert_model.encoder.layer.0.attention.self.value.weight', 'text_field_embedder.token_embedder_bert.bert_model.encoder.layer.0.attention.self.value.bias', 'text_field_embedder.token_embedder_bert.bert_model.encoder.layer.2.output.dense.weight', 'text_field_embedder.token_embedder_bert.bert_model.encoder.layer.6.attention.output.LayerNorm.weight', 'text_field_embedder.token_embedder_bert.bert_model.encoder.layer.10.output.dense.bias', 'text_field_embedder.token_embedder_bert.bert_model.encoder.layer.2.attention.output.LayerNorm.bias', 'text_field_embedder.token_embedder_bert.bert_model.encoder.layer.3.output.dense.weight', 'text_field_embedder.token_embedder_bert.bert_model.encoder.layer.7.output.LayerNorm.weight', 'text_field_embedder.token_embedder_bert.bert_model.encoder.layer.4.intermediate.dense.weight', 'text_field_embedder.token_embedder_bert.bert_model.encoder.layer.7.attention.self.key.bias', 'text_field_embedder.token_embedder_bert.bert_model.embeddings.token_type_embeddings.weight', 'text_field_embedder.token_embedder_bert.bert_model.encoder.layer.9.attention.self.key.weight', 'text_field_embedder.token_embedder_bert.bert_model.encoder.layer.4.output.dense.weight', 'text_field_embedder.token_embedder_bert.bert_model.encoder.layer.7.output.dense.bias', 'text_field_embedder.token_embedder_bert.bert_model.encoder.layer.6.intermediate.dense.bias', 'text_field_embedder.token_embedder_bert.bert_model.encoder.layer.11.attention.self.query.weight', 'text_field_embedder.token_embedder_bert.bert_model.encoder.layer.1.attention.self.key.bias', 'text_field_embedder.token_embedder_bert.bert_model.encoder.layer.1.attention.self.query.bias', 'text_field_embedder.token_embedder_bert.bert_model.encoder.layer.8.attention.self.value.weight', 'text_field_embedder.token_embedder_bert.bert_model.encoder.layer.4.attention.self.key.bias', 'text_field_embedder.token_embedder_bert.bert_model.encoder.layer.5.intermediate.dense.weight', 'text_field_embedder.token_embedder_bert.bert_model.encoder.layer.0.output.dense.bias', 'text_field_embedder.token_embedder_bert.bert_model.encoder.layer.11.attention.output.LayerNorm.weight', 'text_field_embedder.token_embedder_bert.bert_model.encoder.layer.4.attention.self.query.weight', 'text_field_embedder.token_embedder_bert.bert_model.encoder.layer.10.output.LayerNorm.weight', 'text_field_embedder.token_embedder_bert.bert_model.encoder.layer.9.output.LayerNorm.bias', 'text_field_embedder.token_embedder_bert.bert_model.encoder.layer.0.attention.self.query.weight', 'text_field_embedder.token_embedder_bert.bert_model.encoder.layer.8.intermediate.dense.weight', 'text_field_embedder.token_embedder_bert.bert_model.encoder.layer.11.attention.output.dense.bias', 'text_field_embedder.token_embedder_bert.bert_model.encoder.layer.4.attention.self.key.weight', 'text_field_embedder.token_embedder_bert.bert_model.encoder.layer.0.attention.output.dense.bias', 'text_field_embedder.token_embedder_bert.bert_model.encoder.layer.4.output.LayerNorm.weight', 'text_field_embedder.token_embedder_bert.bert_model.encoder.layer.3.attention.self.query.bias', 'text_field_embedder.token_embedder_bert.bert_model.encoder.layer.5.attention.self.query.weight', 'text_field_embedder.token_embedder_bert.bert_model.encoder.layer.8.attention.output.dense.weight', 'text_field_embedder.token_embedder_bert.bert_model.encoder.layer.9.attention.self.value.bias', 'text_field_embedder.token_embedder_bert.bert_model.encoder.layer.8.attention.self.key.weight', 'text_field_embedder.token_embedder_bert.bert_model.encoder.layer.11.attention.self.value.bias', 'text_field_embedder.token_embedder_bert.bert_model.encoder.layer.7.output.dense.weight', 'text_field_embedder.token_embedder_bert.bert_model.encoder.layer.6.attention.self.query.bias', 'text_field_embedder.token_embedder_bert.bert_model.encoder.layer.8.intermediate.dense.bias', 'text_field_embedder.token_embedder_bert.bert_model.embeddings.position_embeddings.weight', 'text_field_embedder.token_embedder_bert.bert_model.encoder.layer.3.attention.self.query.weight', 'text_field_embedder.token_embedder_bert.bert_model.encoder.layer.8.attention.self.query.weight', 'text_field_embedder.token_embedder_bert.bert_model.encoder.layer.2.attention.self.key.weight', 'text_field_embedder.token_embedder_bert.bert_model.encoder.layer.9.attention.self.key.bias', 'text_field_embedder.token_embedder_bert.bert_model.encoder.layer.2.attention.self.query.bias', 'text_field_embedder.token_embedder_bert.bert_model.encoder.layer.7.attention.self.value.bias', 'text_field_embedder.token_embedder_bert.bert_model.encoder.layer.8.attention.self.key.bias', 'text_field_embedder.token_embedder_bert.bert_model.encoder.layer.3.attention.self.value.bias', 'text_field_embedder.token_embedder_bert.bert_model.encoder.layer.9.output.LayerNorm.weight', 'text_field_embedder.token_embedder_bert.bert_model.encoder.layer.9.attention.output.LayerNorm.weight', 'text_field_embedder.token_embedder_bert.bert_model.encoder.layer.10.attention.output.LayerNorm.bias', 'text_field_embedder.token_embedder_bert.bert_model.encoder.layer.10.intermediate.dense.weight', 'text_field_embedder.token_embedder_bert.bert_model.encoder.layer.7.attention.self.value.weight', 'text_field_embedder.token_embedder_bert.bert_model.encoder.layer.9.attention.output.dense.weight', 'text_field_embedder.token_embedder_bert.bert_model.encoder.layer.4.attention.output.LayerNorm.bias', 'text_field_embedder.token_embedder_bert.bert_model.encoder.layer.4.attention.output.dense.weight', 'text_field_embedder.token_embedder_bert.bert_model.encoder.layer.4.intermediate.dense.bias', 'text_field_embedder.token_embedder_bert.bert_model.encoder.layer.1.attention.output.dense.bias', 'text_field_embedder.token_embedder_bert.bert_model.encoder.layer.5.attention.self.key.bias', 'text_field_embedder.token_embedder_bert.bert_model.encoder.layer.10.attention.output.dense.bias', 'text_field_embedder.token_embedder_bert.bert_model.encoder.layer.2.attention.self.value.weight', 'text_field_embedder.token_embedder_bert.bert_model.encoder.layer.10.attention.self.key.bias', 'text_field_embedder.token_embedder_bert.bert_model.encoder.layer.3.attention.self.key.bias', 'text_field_embedder.token_embedder_bert.bert_model.embeddings.word_embeddings.weight', 'text_field_embedder.token_embedder_bert.bert_model.encoder.layer.1.attention.output.LayerNorm.weight', 'text_field_embedder.token_embedder_bert.bert_model.encoder.layer.5.attention.output.LayerNorm.weight', 'text_field_embedder.token_embedder_bert.bert_model.encoder.layer.4.attention.self.value.bias', 'text_field_embedder.token_embedder_bert.bert_model.encoder.layer.7.attention.output.dense.weight', 'text_field_embedder.token_embedder_bert.bert_model.encoder.layer.2.output.LayerNorm.weight'], {}
2021-05-12 00:23:03,441 - INFO - allennlp.training.optimizers - Group 1: ['decoders.lemmas.task_output.head.weight', 'scalar_mix.deps.scalar_parameters.11', 'scalar_mix.lemmas.scalar_parameters.9', 'scalar_mix.deps.scalar_parameters.0', 'scalar_mix.lemmas.scalar_parameters.1', 'scalar_mix.lemmas.scalar_parameters.0', 'decoders.feats.task_output.tail.1.1.weight', 'scalar_mix.upos.scalar_parameters.5', 'decoders.deps.child_arc_feedforward._linear_layers.0.bias', 'scalar_mix.upos.scalar_parameters.11', 'decoders.deps.arc_attention._bias', 'scalar_mix.feats.scalar_parameters.8', 'scalar_mix.lemmas.scalar_parameters.3', 'decoders.deps._head_sentinel', 'decoders.lemmas.task_output.tail.1.0.weight', 'scalar_mix.upos.scalar_parameters.7', 'scalar_mix.lemmas.scalar_parameters.6', 'scalar_mix.feats.gamma', 'decoders.deps.child_tag_feedforward._linear_layers.0.weight', 'scalar_mix.deps.scalar_parameters.1', 'scalar_mix.lemmas.scalar_parameters.4', 'scalar_mix.upos.scalar_parameters.8', 'scalar_mix.deps.gamma', 'scalar_mix.lemmas.scalar_parameters.11', 'decoders.lemmas.task_output.tail.0.1.weight', 'scalar_mix.upos.gamma', 'scalar_mix.feats.scalar_parameters.2', 'scalar_mix.deps.scalar_parameters.2', 'scalar_mix.deps.scalar_parameters.6', 'scalar_mix.deps.scalar_parameters.8', 'scalar_mix.deps.scalar_parameters.3', 'decoders.deps.child_arc_feedforward._linear_layers.0.weight', 'decoders.deps.head_tag_feedforward._linear_layers.0.bias', 'scalar_mix.upos.scalar_parameters.2', 'scalar_mix.lemmas.gamma', 'scalar_mix.lemmas.scalar_parameters.7', 'scalar_mix.feats.scalar_parameters.11', 'decoders.deps.head_arc_feedforward._linear_layers.0.bias', 'decoders.feats.task_output.head.weight', 'scalar_mix.deps.scalar_parameters.10', 'decoders.upos.task_output._module.bias', 'decoders.feats.task_output.tail.1.0.weight', 'scalar_mix.feats.scalar_parameters.10', 'decoders.deps.head_arc_feedforward._linear_layers.0.weight', 'decoders.lemmas.task_output.tail.1.1.weight', 'scalar_mix.deps.scalar_parameters.7', 'scalar_mix.deps.scalar_parameters.5', 'scalar_mix.upos.scalar_parameters.6', 'scalar_mix.feats.scalar_parameters.9', 'scalar_mix.lemmas.scalar_parameters.5', 'scalar_mix.feats.scalar_parameters.5', 'text_field_embedder.token_embedder_bert.bert_model.pooler.dense.bias', 'scalar_mix.upos.scalar_parameters.4', 'scalar_mix.deps.scalar_parameters.4', 'text_field_embedder.token_embedder_bert.bert_model.pooler.dense.weight', 'scalar_mix.deps.scalar_parameters.9', 'decoders.upos.task_output._module.weight', 'decoders.feats.task_output.tail.0.0.weight', 'scalar_mix.upos.scalar_parameters.1', 'decoders.deps.arc_attention._weight_matrix', 'scalar_mix.feats.scalar_parameters.4', 'scalar_mix.feats.scalar_parameters.6', 'scalar_mix.upos.scalar_parameters.3', 'decoders.deps.head_tag_feedforward._linear_layers.0.weight', 'scalar_mix.feats.scalar_parameters.7', 'scalar_mix.feats.scalar_parameters.1', 'decoders.feats.task_output.tail.0.1.weight', 'scalar_mix.upos.scalar_parameters.9', 'decoders.deps.tag_bilinear.weight', 'scalar_mix.feats.scalar_parameters.3', 'scalar_mix.lemmas.scalar_parameters.10', 'scalar_mix.feats.scalar_parameters.0', 'decoders.deps.child_tag_feedforward._linear_layers.0.bias', 'decoders.deps.tag_bilinear.bias', 'scalar_mix.upos.scalar_parameters.10', 'decoders.lemmas.task_output.tail.0.0.weight', 'scalar_mix.upos.scalar_parameters.0', 'scalar_mix.lemmas.scalar_parameters.2', 'scalar_mix.lemmas.scalar_parameters.8'], {}
2021-05-12 00:23:03,442 - INFO - allennlp.training.optimizers - Group 2: [], {}
2021-05-12 00:23:03,442 - WARNING - allennlp.training.optimizers - When constructing parameter groups, ^text_field_embedder.*._scalar_mix does not match any parameter name
2021-05-12 00:23:03,442 - WARNING - allennlp.training.optimizers - When constructing parameter groups, ^shared_encoder does not match any parameter name
2021-05-12 00:23:03,442 - INFO - allennlp.training.optimizers - Number of trainable parameters: 198563643
2021-05-12 00:23:03,446 - INFO - allennlp.common.util - The following parameters are Frozen (without gradient):
2021-05-12 00:23:03,448 - INFO - allennlp.common.util - The following parameters are Tunable (with gradient):
2021-05-12 00:23:03,448 - INFO - allennlp.common.util - text_field_embedder.token_embedder_bert.bert_model.embeddings.word_embeddings.weight
2021-05-12 00:23:03,449 - INFO - allennlp.common.util - text_field_embedder.token_embedder_bert.bert_model.embeddings.position_embeddings.weight
2021-05-12 00:23:03,449 - INFO - allennlp.common.util - text_field_embedder.token_embedder_bert.bert_model.embeddings.token_type_embeddings.weight
2021-05-12 00:23:03,449 - INFO - allennlp.common.util - text_field_embedder.token_embedder_bert.bert_model.embeddings.LayerNorm.weight
2021-05-12 00:23:03,449 - INFO - allennlp.common.util - text_field_embedder.token_embedder_bert.bert_model.embeddings.LayerNorm.bias
2021-05-12 00:23:03,449 - INFO - allennlp.common.util - text_field_embedder.token_embedder_bert.bert_model.encoder.layer.0.attention.self.query.weight
2021-05-12 00:23:03,449 - INFO - allennlp.common.util - text_field_embedder.token_embedder_bert.bert_model.encoder.layer.0.attention.self.query.bias
2021-05-12 00:23:03,449 - INFO - allennlp.common.util - text_field_embedder.token_embedder_bert.bert_model.encoder.layer.0.attention.self.key.weight
2021-05-12 00:23:03,449 - INFO - allennlp.common.util - text_field_embedder.token_embedder_bert.bert_model.encoder.layer.0.attention.self.key.bias
2021-05-12 00:23:03,449 - INFO - allennlp.common.util - text_field_embedder.token_embedder_bert.bert_model.encoder.layer.0.attention.self.value.weight
2021-05-12 00:23:03,449 - INFO - allennlp.common.util - text_field_embedder.token_embedder_bert.bert_model.encoder.layer.0.attention.self.value.bias
2021-05-12 00:23:03,449 - INFO - allennlp.common.util - text_field_embedder.token_embedder_bert.bert_model.encoder.layer.0.attention.output.dense.weight
2021-05-12 00:23:03,449 - INFO - allennlp.common.util - text_field_embedder.token_embedder_bert.bert_model.encoder.layer.0.attention.output.dense.bias
2021-05-12 00:23:03,449 - INFO - allennlp.common.util - text_field_embedder.token_embedder_bert.bert_model.encoder.layer.0.attention.output.LayerNorm.weight
2021-05-12 00:23:03,450 - INFO - allennlp.common.util - text_field_embedder.token_embedder_bert.bert_model.encoder.layer.0.attention.output.LayerNorm.bias
2021-05-12 00:23:03,450 - INFO - allennlp.common.util - text_field_embedder.token_embedder_bert.bert_model.encoder.layer.0.intermediate.dense.weight
2021-05-12 00:23:03,450 - INFO - allennlp.common.util - text_field_embedder.token_embedder_bert.bert_model.encoder.layer.0.intermediate.dense.bias
2021-05-12 00:23:03,450 - INFO - allennlp.common.util - text_field_embedder.token_embedder_bert.bert_model.encoder.layer.0.output.dense.weight
2021-05-12 00:23:03,450 - INFO - allennlp.common.util - text_field_embedder.token_embedder_bert.bert_model.encoder.layer.0.output.dense.bias
2021-05-12 00:23:03,450 - INFO - allennlp.common.util - text_field_embedder.token_embedder_bert.bert_model.encoder.layer.0.output.LayerNorm.weight
2021-05-12 00:23:03,450 - INFO - allennlp.common.util - text_field_embedder.token_embedder_bert.bert_model.encoder.layer.0.output.LayerNorm.bias
2021-05-12 00:23:03,450 - INFO - allennlp.common.util - text_field_embedder.token_embedder_bert.bert_model.encoder.layer.1.attention.self.query.weight
2021-05-12 00:23:03,450 - INFO - allennlp.common.util - text_field_embedder.token_embedder_bert.bert_model.encoder.layer.1.attention.self.query.bias
2021-05-12 00:23:03,450 - INFO - allennlp.common.util - text_field_embedder.token_embedder_bert.bert_model.encoder.layer.1.attention.self.key.weight
2021-05-12 00:23:03,450 - INFO - allennlp.common.util - text_field_embedder.token_embedder_bert.bert_model.encoder.layer.1.attention.self.key.bias
2021-05-12 00:23:03,450 - INFO - allennlp.common.util - text_field_embedder.token_embedder_bert.bert_model.encoder.layer.1.attention.self.value.weight
2021-05-12 00:23:03,450 - INFO - allennlp.common.util - text_field_embedder.token_embedder_bert.bert_model.encoder.layer.1.attention.self.value.bias
2021-05-12 00:23:03,450 - INFO - allennlp.common.util - text_field_embedder.token_embedder_bert.bert_model.encoder.layer.1.attention.output.dense.weight
2021-05-12 00:23:03,451 - INFO - allennlp.common.util - text_field_embedder.token_embedder_bert.bert_model.encoder.layer.1.attention.output.dense.bias
2021-05-12 00:23:03,451 - INFO - allennlp.common.util - text_field_embedder.token_embedder_bert.bert_model.encoder.layer.1.attention.output.LayerNorm.weight
2021-05-12 00:23:03,451 - INFO - allennlp.common.util - text_field_embedder.token_embedder_bert.bert_model.encoder.layer.1.attention.output.LayerNorm.bias
2021-05-12 00:23:03,451 - INFO - allennlp.common.util - text_field_embedder.token_embedder_bert.bert_model.encoder.layer.1.intermediate.dense.weight
2021-05-12 00:23:03,451 - INFO - allennlp.common.util - text_field_embedder.token_embedder_bert.bert_model.encoder.layer.1.intermediate.dense.bias
2021-05-12 00:23:03,451 - INFO - allennlp.common.util - text_field_embedder.token_embedder_bert.bert_model.encoder.layer.1.output.dense.weight
2021-05-12 00:23:03,451 - INFO - allennlp.common.util - text_field_embedder.token_embedder_bert.bert_model.encoder.layer.1.output.dense.bias
2021-05-12 00:23:03,451 - INFO - allennlp.common.util - text_field_embedder.token_embedder_bert.bert_model.encoder.layer.1.output.LayerNorm.weight
2021-05-12 00:23:03,451 - INFO - allennlp.common.util - text_field_embedder.token_embedder_bert.bert_model.encoder.layer.1.output.LayerNorm.bias
2021-05-12 00:23:03,451 - INFO - allennlp.common.util - text_field_embedder.token_embedder_bert.bert_model.encoder.layer.2.attention.self.query.weight
2021-05-12 00:23:03,451 - INFO - allennlp.common.util - text_field_embedder.token_embedder_bert.bert_model.encoder.layer.2.attention.self.query.bias
2021-05-12 00:23:03,451 - INFO - allennlp.common.util - text_field_embedder.token_embedder_bert.bert_model.encoder.layer.2.attention.self.key.weight
2021-05-12 00:23:03,451 - INFO - allennlp.common.util - text_field_embedder.token_embedder_bert.bert_model.encoder.layer.2.attention.self.key.bias
2021-05-12 00:23:03,452 - INFO - allennlp.common.util - text_field_embedder.token_embedder_bert.bert_model.encoder.layer.2.attention.self.value.weight
2021-05-12 00:23:03,452 - INFO - allennlp.common.util - text_field_embedder.token_embedder_bert.bert_model.encoder.layer.2.attention.self.value.bias
2021-05-12 00:23:03,452 - INFO - allennlp.common.util - text_field_embedder.token_embedder_bert.bert_model.encoder.layer.2.attention.output.dense.weight
2021-05-12 00:23:03,452 - INFO - allennlp.common.util - text_field_embedder.token_embedder_bert.bert_model.encoder.layer.2.attention.output.dense.bias
2021-05-12 00:23:03,452 - INFO - allennlp.common.util - text_field_embedder.token_embedder_bert.bert_model.encoder.layer.2.attention.output.LayerNorm.weight
2021-05-12 00:23:03,452 - INFO - allennlp.common.util - text_field_embedder.token_embedder_bert.bert_model.encoder.layer.2.attention.output.LayerNorm.bias
2021-05-12 00:23:03,452 - INFO - allennlp.common.util - text_field_embedder.token_embedder_bert.bert_model.encoder.layer.2.intermediate.dense.weight
2021-05-12 00:23:03,452 - INFO - allennlp.common.util - text_field_embedder.token_embedder_bert.bert_model.encoder.layer.2.intermediate.dense.bias
2021-05-12 00:23:03,452 - INFO - allennlp.common.util - text_field_embedder.token_embedder_bert.bert_model.encoder.layer.2.output.dense.weight
2021-05-12 00:23:03,452 - INFO - allennlp.common.util - text_field_embedder.token_embedder_bert.bert_model.encoder.layer.2.output.dense.bias
2021-05-12 00:23:03,452 - INFO - allennlp.common.util - text_field_embedder.token_embedder_bert.bert_model.encoder.layer.2.output.LayerNorm.weight
2021-05-12 00:23:03,452 - INFO - allennlp.common.util - text_field_embedder.token_embedder_bert.bert_model.encoder.layer.2.output.LayerNorm.bias
2021-05-12 00:23:03,452 - INFO - allennlp.common.util - text_field_embedder.token_embedder_bert.bert_model.encoder.layer.3.attention.self.query.weight
2021-05-12 00:23:03,452 - INFO - allennlp.common.util - text_field_embedder.token_embedder_bert.bert_model.encoder.layer.3.attention.self.query.bias
2021-05-12 00:23:03,453 - INFO - allennlp.common.util - text_field_embedder.token_embedder_bert.bert_model.encoder.layer.3.attention.self.key.weight
2021-05-12 00:23:03,453 - INFO - allennlp.common.util - text_field_embedder.token_embedder_bert.bert_model.encoder.layer.3.attention.self.key.bias
2021-05-12 00:23:03,453 - INFO - allennlp.common.util - text_field_embedder.token_embedder_bert.bert_model.encoder.layer.3.attention.self.value.weight
2021-05-12 00:23:03,453 - INFO - allennlp.common.util - text_field_embedder.token_embedder_bert.bert_model.encoder.layer.3.attention.self.value.bias
2021-05-12 00:23:03,453 - INFO - allennlp.common.util - text_field_embedder.token_embedder_bert.bert_model.encoder.layer.3.attention.output.dense.weight
2021-05-12 00:23:03,453 - INFO - allennlp.common.util - text_field_embedder.token_embedder_bert.bert_model.encoder.layer.3.attention.output.dense.bias
2021-05-12 00:23:03,453 - INFO - allennlp.common.util - text_field_embedder.token_embedder_bert.bert_model.encoder.layer.3.attention.output.LayerNorm.weight
2021-05-12 00:23:03,453 - INFO - allennlp.common.util - text_field_embedder.token_embedder_bert.bert_model.encoder.layer.3.attention.output.LayerNorm.bias
2021-05-12 00:23:03,453 - INFO - allennlp.common.util - text_field_embedder.token_embedder_bert.bert_model.encoder.layer.3.intermediate.dense.weight
2021-05-12 00:23:03,453 - INFO - allennlp.common.util - text_field_embedder.token_embedder_bert.bert_model.encoder.layer.3.intermediate.dense.bias
2021-05-12 00:23:03,453 - INFO - allennlp.common.util - text_field_embedder.token_embedder_bert.bert_model.encoder.layer.3.output.dense.weight
2021-05-12 00:23:03,453 - INFO - allennlp.common.util - text_field_embedder.token_embedder_bert.bert_model.encoder.layer.3.output.dense.bias
2021-05-12 00:23:03,453 - INFO - allennlp.common.util - text_field_embedder.token_embedder_bert.bert_model.encoder.layer.3.output.LayerNorm.weight
2021-05-12 00:23:03,453 - INFO - allennlp.common.util - text_field_embedder.token_embedder_bert.bert_model.encoder.layer.3.output.LayerNorm.bias
2021-05-12 00:23:03,454 - INFO - allennlp.common.util - text_field_embedder.token_embedder_bert.bert_model.encoder.layer.4.attention.self.query.weight
2021-05-12 00:23:03,454 - INFO - allennlp.common.util - text_field_embedder.token_embedder_bert.bert_model.encoder.layer.4.attention.self.query.bias
2021-05-12 00:23:03,454 - INFO - allennlp.common.util - text_field_embedder.token_embedder_bert.bert_model.encoder.layer.4.attention.self.key.weight
2021-05-12 00:23:03,454 - INFO - allennlp.common.util - text_field_embedder.token_embedder_bert.bert_model.encoder.layer.4.attention.self.key.bias
2021-05-12 00:23:03,454 - INFO - allennlp.common.util - text_field_embedder.token_embedder_bert.bert_model.encoder.layer.4.attention.self.value.weight
2021-05-12 00:23:03,454 - INFO - allennlp.common.util - text_field_embedder.token_embedder_bert.bert_model.encoder.layer.4.attention.self.value.bias
2021-05-12 00:23:03,454 - INFO - allennlp.common.util - text_field_embedder.token_embedder_bert.bert_model.encoder.layer.4.attention.output.dense.weight
2021-05-12 00:23:03,454 - INFO - allennlp.common.util - text_field_embedder.token_embedder_bert.bert_model.encoder.layer.4.attention.output.dense.bias
2021-05-12 00:23:03,454 - INFO - allennlp.common.util - text_field_embedder.token_embedder_bert.bert_model.encoder.layer.4.attention.output.LayerNorm.weight
2021-05-12 00:23:03,454 - INFO - allennlp.common.util - text_field_embedder.token_embedder_bert.bert_model.encoder.layer.4.attention.output.LayerNorm.bias
2021-05-12 00:23:03,454 - INFO - allennlp.common.util - text_field_embedder.token_embedder_bert.bert_model.encoder.layer.4.intermediate.dense.weight
2021-05-12 00:23:03,454 - INFO - allennlp.common.util - text_field_embedder.token_embedder_bert.bert_model.encoder.layer.4.intermediate.dense.bias
2021-05-12 00:23:03,454 - INFO - allennlp.common.util - text_field_embedder.token_embedder_bert.bert_model.encoder.layer.4.output.dense.weight
2021-05-12 00:23:03,454 - INFO - allennlp.common.util - text_field_embedder.token_embedder_bert.bert_model.encoder.layer.4.output.dense.bias
2021-05-12 00:23:03,455 - INFO - allennlp.common.util - text_field_embedder.token_embedder_bert.bert_model.encoder.layer.4.output.LayerNorm.weight
2021-05-12 00:23:03,455 - INFO - allennlp.common.util - text_field_embedder.token_embedder_bert.bert_model.encoder.layer.4.output.LayerNorm.bias
2021-05-12 00:23:03,455 - INFO - allennlp.common.util - text_field_embedder.token_embedder_bert.bert_model.encoder.layer.5.attention.self.query.weight
2021-05-12 00:23:03,455 - INFO - allennlp.common.util - text_field_embedder.token_embedder_bert.bert_model.encoder.layer.5.attention.self.query.bias
2021-05-12 00:23:03,455 - INFO - allennlp.common.util - text_field_embedder.token_embedder_bert.bert_model.encoder.layer.5.attention.self.key.weight
2021-05-12 00:23:03,455 - INFO - allennlp.common.util - text_field_embedder.token_embedder_bert.bert_model.encoder.layer.5.attention.self.key.bias
2021-05-12 00:23:03,455 - INFO - allennlp.common.util - text_field_embedder.token_embedder_bert.bert_model.encoder.layer.5.attention.self.value.weight
2021-05-12 00:23:03,455 - INFO - allennlp.common.util - text_field_embedder.token_embedder_bert.bert_model.encoder.layer.5.attention.self.value.bias
2021-05-12 00:23:03,455 - INFO - allennlp.common.util - text_field_embedder.token_embedder_bert.bert_model.encoder.layer.5.attention.output.dense.weight
2021-05-12 00:23:03,455 - INFO - allennlp.common.util - text_field_embedder.token_embedder_bert.bert_model.encoder.layer.5.attention.output.dense.bias
2021-05-12 00:23:03,455 - INFO - allennlp.common.util - text_field_embedder.token_embedder_bert.bert_model.encoder.layer.5.attention.output.LayerNorm.weight
2021-05-12 00:23:03,455 - INFO - allennlp.common.util - text_field_embedder.token_embedder_bert.bert_model.encoder.layer.5.attention.output.LayerNorm.bias
2021-05-12 00:23:03,455 - INFO - allennlp.common.util - text_field_embedder.token_embedder_bert.bert_model.encoder.layer.5.intermediate.dense.weight
2021-05-12 00:23:03,456 - INFO - allennlp.common.util - text_field_embedder.token_embedder_bert.bert_model.encoder.layer.5.intermediate.dense.bias
2021-05-12 00:23:03,456 - INFO - allennlp.common.util - text_field_embedder.token_embedder_bert.bert_model.encoder.layer.5.output.dense.weight
2021-05-12 00:23:03,456 - INFO - allennlp.common.util - text_field_embedder.token_embedder_bert.bert_model.encoder.layer.5.output.dense.bias
2021-05-12 00:23:03,456 - INFO - allennlp.common.util - text_field_embedder.token_embedder_bert.bert_model.encoder.layer.5.output.LayerNorm.weight
2021-05-12 00:23:03,456 - INFO - allennlp.common.util - text_field_embedder.token_embedder_bert.bert_model.encoder.layer.5.output.LayerNorm.bias
2021-05-12 00:23:03,456 - INFO - allennlp.common.util - text_field_embedder.token_embedder_bert.bert_model.encoder.layer.6.attention.self.query.weight
2021-05-12 00:23:03,456 - INFO - allennlp.common.util - text_field_embedder.token_embedder_bert.bert_model.encoder.layer.6.attention.self.query.bias
2021-05-12 00:23:03,456 - INFO - allennlp.common.util - text_field_embedder.token_embedder_bert.bert_model.encoder.layer.6.attention.self.key.weight
2021-05-12 00:23:03,456 - INFO - allennlp.common.util - text_field_embedder.token_embedder_bert.bert_model.encoder.layer.6.attention.self.key.bias
2021-05-12 00:23:03,456 - INFO - allennlp.common.util - text_field_embedder.token_embedder_bert.bert_model.encoder.layer.6.attention.self.value.weight
2021-05-12 00:23:03,456 - INFO - allennlp.common.util - text_field_embedder.token_embedder_bert.bert_model.encoder.layer.6.attention.self.value.bias
2021-05-12 00:23:03,456 - INFO - allennlp.common.util - text_field_embedder.token_embedder_bert.bert_model.encoder.layer.6.attention.output.dense.weight
2021-05-12 00:23:03,456 - INFO - allennlp.common.util - text_field_embedder.token_embedder_bert.bert_model.encoder.layer.6.attention.output.dense.bias
2021-05-12 00:23:03,456 - INFO - allennlp.common.util - text_field_embedder.token_embedder_bert.bert_model.encoder.layer.6.attention.output.LayerNorm.weight
2021-05-12 00:23:03,457 - INFO - allennlp.common.util - text_field_embedder.token_embedder_bert.bert_model.encoder.layer.6.attention.output.LayerNorm.bias
2021-05-12 00:23:03,457 - INFO - allennlp.common.util - text_field_embedder.token_embedder_bert.bert_model.encoder.layer.6.intermediate.dense.weight
2021-05-12 00:23:03,457 - INFO - allennlp.common.util - text_field_embedder.token_embedder_bert.bert_model.encoder.layer.6.intermediate.dense.bias
2021-05-12 00:23:03,457 - INFO - allennlp.common.util - text_field_embedder.token_embedder_bert.bert_model.encoder.layer.6.output.dense.weight
2021-05-12 00:23:03,457 - INFO - allennlp.common.util - text_field_embedder.token_embedder_bert.bert_model.encoder.layer.6.output.dense.bias
2021-05-12 00:23:03,457 - INFO - allennlp.common.util - text_field_embedder.token_embedder_bert.bert_model.encoder.layer.6.output.LayerNorm.weight
2021-05-12 00:23:03,457 - INFO - allennlp.common.util - text_field_embedder.token_embedder_bert.bert_model.encoder.layer.6.output.LayerNorm.bias
2021-05-12 00:23:03,457 - INFO - allennlp.common.util - text_field_embedder.token_embedder_bert.bert_model.encoder.layer.7.attention.self.query.weight
2021-05-12 00:23:03,457 - INFO - allennlp.common.util - text_field_embedder.token_embedder_bert.bert_model.encoder.layer.7.attention.self.query.bias
2021-05-12 00:23:03,457 - INFO - allennlp.common.util - text_field_embedder.token_embedder_bert.bert_model.encoder.layer.7.attention.self.key.weight
2021-05-12 00:23:03,457 - INFO - allennlp.common.util - text_field_embedder.token_embedder_bert.bert_model.encoder.layer.7.attention.self.key.bias
2021-05-12 00:23:03,457 - INFO - allennlp.common.util - text_field_embedder.token_embedder_bert.bert_model.encoder.layer.7.attention.self.value.weight
2021-05-12 00:23:03,457 - INFO - allennlp.common.util - text_field_embedder.token_embedder_bert.bert_model.encoder.layer.7.attention.self.value.bias
2021-05-12 00:23:03,457 - INFO - allennlp.common.util - text_field_embedder.token_embedder_bert.bert_model.encoder.layer.7.attention.output.dense.weight
2021-05-12 00:23:03,458 - INFO - allennlp.common.util - text_field_embedder.token_embedder_bert.bert_model.encoder.layer.7.attention.output.dense.bias
2021-05-12 00:23:03,458 - INFO - allennlp.common.util - text_field_embedder.token_embedder_bert.bert_model.encoder.layer.7.attention.output.LayerNorm.weight
2021-05-12 00:23:03,458 - INFO - allennlp.common.util - text_field_embedder.token_embedder_bert.bert_model.encoder.layer.7.attention.output.LayerNorm.bias
2021-05-12 00:23:03,458 - INFO - allennlp.common.util - text_field_embedder.token_embedder_bert.bert_model.encoder.layer.7.intermediate.dense.weight
2021-05-12 00:23:03,458 - INFO - allennlp.common.util - text_field_embedder.token_embedder_bert.bert_model.encoder.layer.7.intermediate.dense.bias
2021-05-12 00:23:03,458 - INFO - allennlp.common.util - text_field_embedder.token_embedder_bert.bert_model.encoder.layer.7.output.dense.weight
2021-05-12 00:23:03,458 - INFO - allennlp.common.util - text_field_embedder.token_embedder_bert.bert_model.encoder.layer.7.output.dense.bias
2021-05-12 00:23:03,458 - INFO - allennlp.common.util - text_field_embedder.token_embedder_bert.bert_model.encoder.layer.7.output.LayerNorm.weight
2021-05-12 00:23:03,458 - INFO - allennlp.common.util - text_field_embedder.token_embedder_bert.bert_model.encoder.layer.7.output.LayerNorm.bias
2021-05-12 00:23:03,458 - INFO - allennlp.common.util - text_field_embedder.token_embedder_bert.bert_model.encoder.layer.8.attention.self.query.weight
2021-05-12 00:23:03,458 - INFO - allennlp.common.util - text_field_embedder.token_embedder_bert.bert_model.encoder.layer.8.attention.self.query.bias
2021-05-12 00:23:03,458 - INFO - allennlp.common.util - text_field_embedder.token_embedder_bert.bert_model.encoder.layer.8.attention.self.key.weight
2021-05-12 00:23:03,458 - INFO - allennlp.common.util - text_field_embedder.token_embedder_bert.bert_model.encoder.layer.8.attention.self.key.bias
2021-05-12 00:23:03,458 - INFO - allennlp.common.util - text_field_embedder.token_embedder_bert.bert_model.encoder.layer.8.attention.self.value.weight
2021-05-12 00:23:03,459 - INFO - allennlp.common.util - text_field_embedder.token_embedder_bert.bert_model.encoder.layer.8.attention.self.value.bias
2021-05-12 00:23:03,459 - INFO - allennlp.common.util - text_field_embedder.token_embedder_bert.bert_model.encoder.layer.8.attention.output.dense.weight
2021-05-12 00:23:03,459 - INFO - allennlp.common.util - text_field_embedder.token_embedder_bert.bert_model.encoder.layer.8.attention.output.dense.bias
2021-05-12 00:23:03,459 - INFO - allennlp.common.util - text_field_embedder.token_embedder_bert.bert_model.encoder.layer.8.attention.output.LayerNorm.weight
2021-05-12 00:23:03,459 - INFO - allennlp.common.util - text_field_embedder.token_embedder_bert.bert_model.encoder.layer.8.attention.output.LayerNorm.bias
2021-05-12 00:23:03,459 - INFO - allennlp.common.util - text_field_embedder.token_embedder_bert.bert_model.encoder.layer.8.intermediate.dense.weight
2021-05-12 00:23:03,459 - INFO - allennlp.common.util - text_field_embedder.token_embedder_bert.bert_model.encoder.layer.8.intermediate.dense.bias
2021-05-12 00:23:03,459 - INFO - allennlp.common.util - text_field_embedder.token_embedder_bert.bert_model.encoder.layer.8.output.dense.weight
2021-05-12 00:23:03,459 - INFO - allennlp.common.util - text_field_embedder.token_embedder_bert.bert_model.encoder.layer.8.output.dense.bias
2021-05-12 00:23:03,459 - INFO - allennlp.common.util - text_field_embedder.token_embedder_bert.bert_model.encoder.layer.8.output.LayerNorm.weight
2021-05-12 00:23:03,459 - INFO - allennlp.common.util - text_field_embedder.token_embedder_bert.bert_model.encoder.layer.8.output.LayerNorm.bias
2021-05-12 00:23:03,459 - INFO - allennlp.common.util - text_field_embedder.token_embedder_bert.bert_model.encoder.layer.9.attention.self.query.weight
2021-05-12 00:23:03,459 - INFO - allennlp.common.util - text_field_embedder.token_embedder_bert.bert_model.encoder.layer.9.attention.self.query.bias
2021-05-12 00:23:03,460 - INFO - allennlp.common.util - text_field_embedder.token_embedder_bert.bert_model.encoder.layer.9.attention.self.key.weight
2021-05-12 00:23:03,460 - INFO - allennlp.common.util - text_field_embedder.token_embedder_bert.bert_model.encoder.layer.9.attention.self.key.bias
2021-05-12 00:23:03,460 - INFO - allennlp.common.util - text_field_embedder.token_embedder_bert.bert_model.encoder.layer.9.attention.self.value.weight
2021-05-12 00:23:03,460 - INFO - allennlp.common.util - text_field_embedder.token_embedder_bert.bert_model.encoder.layer.9.attention.self.value.bias
2021-05-12 00:23:03,460 - INFO - allennlp.common.util - text_field_embedder.token_embedder_bert.bert_model.encoder.layer.9.attention.output.dense.weight
2021-05-12 00:23:03,460 - INFO - allennlp.common.util - text_field_embedder.token_embedder_bert.bert_model.encoder.layer.9.attention.output.dense.bias
2021-05-12 00:23:03,460 - INFO - allennlp.common.util - text_field_embedder.token_embedder_bert.bert_model.encoder.layer.9.attention.output.LayerNorm.weight
2021-05-12 00:23:03,460 - INFO - allennlp.common.util - text_field_embedder.token_embedder_bert.bert_model.encoder.layer.9.attention.output.LayerNorm.bias
2021-05-12 00:23:03,460 - INFO - allennlp.common.util - text_field_embedder.token_embedder_bert.bert_model.encoder.layer.9.intermediate.dense.weight
2021-05-12 00:23:03,460 - INFO - allennlp.common.util - text_field_embedder.token_embedder_bert.bert_model.encoder.layer.9.intermediate.dense.bias
2021-05-12 00:23:03,460 - INFO - allennlp.common.util - text_field_embedder.token_embedder_bert.bert_model.encoder.layer.9.output.dense.weight
2021-05-12 00:23:03,460 - INFO - allennlp.common.util - text_field_embedder.token_embedder_bert.bert_model.encoder.layer.9.output.dense.bias
2021-05-12 00:23:03,460 - INFO - allennlp.common.util - text_field_embedder.token_embedder_bert.bert_model.encoder.layer.9.output.LayerNorm.weight
2021-05-12 00:23:03,460 - INFO - allennlp.common.util - text_field_embedder.token_embedder_bert.bert_model.encoder.layer.9.output.LayerNorm.bias
2021-05-12 00:23:03,461 - INFO - allennlp.common.util - text_field_embedder.token_embedder_bert.bert_model.encoder.layer.10.attention.self.query.weight
2021-05-12 00:23:03,461 - INFO - allennlp.common.util - text_field_embedder.token_embedder_bert.bert_model.encoder.layer.10.attention.self.query.bias
2021-05-12 00:23:03,461 - INFO - allennlp.common.util - text_field_embedder.token_embedder_bert.bert_model.encoder.layer.10.attention.self.key.weight
2021-05-12 00:23:03,461 - INFO - allennlp.common.util - text_field_embedder.token_embedder_bert.bert_model.encoder.layer.10.attention.self.key.bias
2021-05-12 00:23:03,461 - INFO - allennlp.common.util - text_field_embedder.token_embedder_bert.bert_model.encoder.layer.10.attention.self.value.weight
2021-05-12 00:23:03,461 - INFO - allennlp.common.util - text_field_embedder.token_embedder_bert.bert_model.encoder.layer.10.attention.self.value.bias
2021-05-12 00:23:03,461 - INFO - allennlp.common.util - text_field_embedder.token_embedder_bert.bert_model.encoder.layer.10.attention.output.dense.weight
2021-05-12 00:23:03,461 - INFO - allennlp.common.util - text_field_embedder.token_embedder_bert.bert_model.encoder.layer.10.attention.output.dense.bias
2021-05-12 00:23:03,461 - INFO - allennlp.common.util - text_field_embedder.token_embedder_bert.bert_model.encoder.layer.10.attention.output.LayerNorm.weight
2021-05-12 00:23:03,461 - INFO - allennlp.common.util - text_field_embedder.token_embedder_bert.bert_model.encoder.layer.10.attention.output.LayerNorm.bias
2021-05-12 00:23:03,461 - INFO - allennlp.common.util - text_field_embedder.token_embedder_bert.bert_model.encoder.layer.10.intermediate.dense.weight
2021-05-12 00:23:03,461 - INFO - allennlp.common.util - text_field_embedder.token_embedder_bert.bert_model.encoder.layer.10.intermediate.dense.bias
2021-05-12 00:23:03,461 - INFO - allennlp.common.util - text_field_embedder.token_embedder_bert.bert_model.encoder.layer.10.output.dense.weight
2021-05-12 00:23:03,461 - INFO - allennlp.common.util - text_field_embedder.token_embedder_bert.bert_model.encoder.layer.10.output.dense.bias
2021-05-12 00:23:03,462 - INFO - allennlp.common.util - text_field_embedder.token_embedder_bert.bert_model.encoder.layer.10.output.LayerNorm.weight
2021-05-12 00:23:03,462 - INFO - allennlp.common.util - text_field_embedder.token_embedder_bert.bert_model.encoder.layer.10.output.LayerNorm.bias
2021-05-12 00:23:03,462 - INFO - allennlp.common.util - text_field_embedder.token_embedder_bert.bert_model.encoder.layer.11.attention.self.query.weight
2021-05-12 00:23:03,462 - INFO - allennlp.common.util - text_field_embedder.token_embedder_bert.bert_model.encoder.layer.11.attention.self.query.bias
2021-05-12 00:23:03,462 - INFO - allennlp.common.util - text_field_embedder.token_embedder_bert.bert_model.encoder.layer.11.attention.self.key.weight
2021-05-12 00:23:03,462 - INFO - allennlp.common.util - text_field_embedder.token_embedder_bert.bert_model.encoder.layer.11.attention.self.key.bias
2021-05-12 00:23:03,462 - INFO - allennlp.common.util - text_field_embedder.token_embedder_bert.bert_model.encoder.layer.11.attention.self.value.weight
2021-05-12 00:23:03,462 - INFO - allennlp.common.util - text_field_embedder.token_embedder_bert.bert_model.encoder.layer.11.attention.self.value.bias
2021-05-12 00:23:03,462 - INFO - allennlp.common.util - text_field_embedder.token_embedder_bert.bert_model.encoder.layer.11.attention.output.dense.weight
2021-05-12 00:23:03,462 - INFO - allennlp.common.util - text_field_embedder.token_embedder_bert.bert_model.encoder.layer.11.attention.output.dense.bias
2021-05-12 00:23:03,462 - INFO - allennlp.common.util - text_field_embedder.token_embedder_bert.bert_model.encoder.layer.11.attention.output.LayerNorm.weight
2021-05-12 00:23:03,462 - INFO - allennlp.common.util - text_field_embedder.token_embedder_bert.bert_model.encoder.layer.11.attention.output.LayerNorm.bias
2021-05-12 00:23:03,462 - INFO - allennlp.common.util - text_field_embedder.token_embedder_bert.bert_model.encoder.layer.11.intermediate.dense.weight
2021-05-12 00:23:03,462 - INFO - allennlp.common.util - text_field_embedder.token_embedder_bert.bert_model.encoder.layer.11.intermediate.dense.bias
2021-05-12 00:23:03,463 - INFO - allennlp.common.util - text_field_embedder.token_embedder_bert.bert_model.encoder.layer.11.output.dense.weight
2021-05-12 00:23:03,463 - INFO - allennlp.common.util - text_field_embedder.token_embedder_bert.bert_model.encoder.layer.11.output.dense.bias
2021-05-12 00:23:03,463 - INFO - allennlp.common.util - text_field_embedder.token_embedder_bert.bert_model.encoder.layer.11.output.LayerNorm.weight
2021-05-12 00:23:03,463 - INFO - allennlp.common.util - text_field_embedder.token_embedder_bert.bert_model.encoder.layer.11.output.LayerNorm.bias
2021-05-12 00:23:03,463 - INFO - allennlp.common.util - text_field_embedder.token_embedder_bert.bert_model.pooler.dense.weight
2021-05-12 00:23:03,463 - INFO - allennlp.common.util - text_field_embedder.token_embedder_bert.bert_model.pooler.dense.bias
2021-05-12 00:23:03,463 - INFO - allennlp.common.util - decoders.feats.task_output.head.weight
2021-05-12 00:23:03,463 - INFO - allennlp.common.util - decoders.feats.task_output.tail.0.0.weight
2021-05-12 00:23:03,463 - INFO - allennlp.common.util - decoders.feats.task_output.tail.0.1.weight
2021-05-12 00:23:03,463 - INFO - allennlp.common.util - decoders.feats.task_output.tail.1.0.weight
2021-05-12 00:23:03,463 - INFO - allennlp.common.util - decoders.feats.task_output.tail.1.1.weight
2021-05-12 00:23:03,463 - INFO - allennlp.common.util - decoders.upos.task_output._module.weight
2021-05-12 00:23:03,463 - INFO - allennlp.common.util - decoders.upos.task_output._module.bias
2021-05-12 00:23:03,464 - INFO - allennlp.common.util - decoders.deps._head_sentinel
2021-05-12 00:23:03,464 - INFO - allennlp.common.util - decoders.deps.head_arc_feedforward._linear_layers.0.weight
2021-05-12 00:23:03,464 - INFO - allennlp.common.util - decoders.deps.head_arc_feedforward._linear_layers.0.bias
2021-05-12 00:23:03,464 - INFO - allennlp.common.util - decoders.deps.child_arc_feedforward._linear_layers.0.weight
2021-05-12 00:23:03,464 - INFO - allennlp.common.util - decoders.deps.child_arc_feedforward._linear_layers.0.bias
2021-05-12 00:23:03,464 - INFO - allennlp.common.util - decoders.deps.arc_attention._weight_matrix
2021-05-12 00:23:03,464 - INFO - allennlp.common.util - decoders.deps.arc_attention._bias
2021-05-12 00:23:03,464 - INFO - allennlp.common.util - decoders.deps.head_tag_feedforward._linear_layers.0.weight
2021-05-12 00:23:03,464 - INFO - allennlp.common.util - decoders.deps.head_tag_feedforward._linear_layers.0.bias
2021-05-12 00:23:03,464 - INFO - allennlp.common.util - decoders.deps.child_tag_feedforward._linear_layers.0.weight
2021-05-12 00:23:03,464 - INFO - allennlp.common.util - decoders.deps.child_tag_feedforward._linear_layers.0.bias
2021-05-12 00:23:03,464 - INFO - allennlp.common.util - decoders.deps.tag_bilinear.weight
2021-05-12 00:23:03,465 - INFO - allennlp.common.util - decoders.deps.tag_bilinear.bias
2021-05-12 00:23:03,465 - INFO - allennlp.common.util - decoders.lemmas.task_output.head.weight
2021-05-12 00:23:03,465 - INFO - allennlp.common.util - decoders.lemmas.task_output.tail.0.0.weight
2021-05-12 00:23:03,465 - INFO - allennlp.common.util - decoders.lemmas.task_output.tail.0.1.weight
2021-05-12 00:23:03,465 - INFO - allennlp.common.util - decoders.lemmas.task_output.tail.1.0.weight
2021-05-12 00:23:03,465 - INFO - allennlp.common.util - decoders.lemmas.task_output.tail.1.1.weight
2021-05-12 00:23:03,465 - INFO - allennlp.common.util - scalar_mix.feats.gamma
2021-05-12 00:23:03,465 - INFO - allennlp.common.util - scalar_mix.feats.scalar_parameters.0
2021-05-12 00:23:03,465 - INFO - allennlp.common.util - scalar_mix.feats.scalar_parameters.1
2021-05-12 00:23:03,465 - INFO - allennlp.common.util - scalar_mix.feats.scalar_parameters.2
2021-05-12 00:23:03,465 - INFO - allennlp.common.util - scalar_mix.feats.scalar_parameters.3
2021-05-12 00:23:03,465 - INFO - allennlp.common.util - scalar_mix.feats.scalar_parameters.4
2021-05-12 00:23:03,465 - INFO - allennlp.common.util - scalar_mix.feats.scalar_parameters.5
2021-05-12 00:23:03,465 - INFO - allennlp.common.util - scalar_mix.feats.scalar_parameters.6
2021-05-12 00:23:03,466 - INFO - allennlp.common.util - scalar_mix.feats.scalar_parameters.7
2021-05-12 00:23:03,466 - INFO - allennlp.common.util - scalar_mix.feats.scalar_parameters.8
2021-05-12 00:23:03,466 - INFO - allennlp.common.util - scalar_mix.feats.scalar_parameters.9
2021-05-12 00:23:03,466 - INFO - allennlp.common.util - scalar_mix.feats.scalar_parameters.10
2021-05-12 00:23:03,466 - INFO - allennlp.common.util - scalar_mix.feats.scalar_parameters.11
2021-05-12 00:23:03,466 - INFO - allennlp.common.util - scalar_mix.upos.gamma
2021-05-12 00:23:03,466 - INFO - allennlp.common.util - scalar_mix.upos.scalar_parameters.0
2021-05-12 00:23:03,466 - INFO - allennlp.common.util - scalar_mix.upos.scalar_parameters.1
2021-05-12 00:23:03,466 - INFO - allennlp.common.util - scalar_mix.upos.scalar_parameters.2
2021-05-12 00:23:03,466 - INFO - allennlp.common.util - scalar_mix.upos.scalar_parameters.3
2021-05-12 00:23:03,466 - INFO - allennlp.common.util - scalar_mix.upos.scalar_parameters.4
2021-05-12 00:23:03,466 - INFO - allennlp.common.util - scalar_mix.upos.scalar_parameters.5
2021-05-12 00:23:03,466 - INFO - allennlp.common.util - scalar_mix.upos.scalar_parameters.6
2021-05-12 00:23:03,466 - INFO - allennlp.common.util - scalar_mix.upos.scalar_parameters.7
2021-05-12 00:23:03,466 - INFO - allennlp.common.util - scalar_mix.upos.scalar_parameters.8
2021-05-12 00:23:03,467 - INFO - allennlp.common.util - scalar_mix.upos.scalar_parameters.9
2021-05-12 00:23:03,467 - INFO - allennlp.common.util - scalar_mix.upos.scalar_parameters.10
2021-05-12 00:23:03,467 - INFO - allennlp.common.util - scalar_mix.upos.scalar_parameters.11
2021-05-12 00:23:03,467 - INFO - allennlp.common.util - scalar_mix.deps.gamma
2021-05-12 00:23:03,467 - INFO - allennlp.common.util - scalar_mix.deps.scalar_parameters.0
2021-05-12 00:23:03,467 - INFO - allennlp.common.util - scalar_mix.deps.scalar_parameters.1
2021-05-12 00:23:03,467 - INFO - allennlp.common.util - scalar_mix.deps.scalar_parameters.2
2021-05-12 00:23:03,467 - INFO - allennlp.common.util - scalar_mix.deps.scalar_parameters.3
2021-05-12 00:23:03,467 - INFO - allennlp.common.util - scalar_mix.deps.scalar_parameters.4
2021-05-12 00:23:03,467 - INFO - allennlp.common.util - scalar_mix.deps.scalar_parameters.5
2021-05-12 00:23:03,467 - INFO - allennlp.common.util - scalar_mix.deps.scalar_parameters.6
2021-05-12 00:23:03,467 - INFO - allennlp.common.util - scalar_mix.deps.scalar_parameters.7
2021-05-12 00:23:03,467 - INFO - allennlp.common.util - scalar_mix.deps.scalar_parameters.8
2021-05-12 00:23:03,467 - INFO - allennlp.common.util - scalar_mix.deps.scalar_parameters.9
2021-05-12 00:23:03,468 - INFO - allennlp.common.util - scalar_mix.deps.scalar_parameters.10
2021-05-12 00:23:03,468 - INFO - allennlp.common.util - scalar_mix.deps.scalar_parameters.11
2021-05-12 00:23:03,468 - INFO - allennlp.common.util - scalar_mix.lemmas.gamma
2021-05-12 00:23:03,468 - INFO - allennlp.common.util - scalar_mix.lemmas.scalar_parameters.0
2021-05-12 00:23:03,468 - INFO - allennlp.common.util - scalar_mix.lemmas.scalar_parameters.1
2021-05-12 00:23:03,468 - INFO - allennlp.common.util - scalar_mix.lemmas.scalar_parameters.2
2021-05-12 00:23:03,468 - INFO - allennlp.common.util - scalar_mix.lemmas.scalar_parameters.3
2021-05-12 00:23:03,468 - INFO - allennlp.common.util - scalar_mix.lemmas.scalar_parameters.4
2021-05-12 00:23:03,468 - INFO - allennlp.common.util - scalar_mix.lemmas.scalar_parameters.5
2021-05-12 00:23:03,468 - INFO - allennlp.common.util - scalar_mix.lemmas.scalar_parameters.6
2021-05-12 00:23:03,468 - INFO - allennlp.common.util - scalar_mix.lemmas.scalar_parameters.7
2021-05-12 00:23:03,468 - INFO - allennlp.common.util - scalar_mix.lemmas.scalar_parameters.8
2021-05-12 00:23:03,468 - INFO - allennlp.common.util - scalar_mix.lemmas.scalar_parameters.9
2021-05-12 00:23:03,468 - INFO - allennlp.common.util - scalar_mix.lemmas.scalar_parameters.10
2021-05-12 00:23:03,468 - INFO - allennlp.common.util - scalar_mix.lemmas.scalar_parameters.11
2021-05-12 00:23:03,469 - INFO - allennlp.common.params - trainer.learning_rate_scheduler.type = ulmfit_sqrt
2021-05-12 00:23:03,469 - INFO - allennlp.common.params - trainer.learning_rate_scheduler.model_size = 1
2021-05-12 00:23:03,469 - INFO - allennlp.common.params - trainer.learning_rate_scheduler.warmup_steps = 392
2021-05-12 00:23:03,469 - INFO - allennlp.common.params - trainer.learning_rate_scheduler.start_step = 392
2021-05-12 00:23:03,469 - INFO - allennlp.common.params - trainer.learning_rate_scheduler.factor = 5
2021-05-12 00:23:03,469 - INFO - allennlp.common.params - trainer.learning_rate_scheduler.steepness = 0.5
2021-05-12 00:23:03,470 - INFO - allennlp.common.params - trainer.learning_rate_scheduler.last_epoch = -1
2021-05-12 00:23:03,470 - INFO - allennlp.common.params - trainer.learning_rate_scheduler.gradual_unfreezing = True
2021-05-12 00:23:03,470 - INFO - allennlp.common.params - trainer.learning_rate_scheduler.discriminative_fine_tuning = True
2021-05-12 00:23:03,470 - INFO - allennlp.common.params - trainer.learning_rate_scheduler.decay_factor = 0.04
2021-05-12 00:23:03,470 - INFO - allennlp.common.params - type = default
2021-05-12 00:23:03,470 - INFO - allennlp.common.params - keep_serialized_model_every_num_seconds = None
2021-05-12 00:23:03,470 - INFO - allennlp.common.params - num_serialized_models_to_keep = 2
2021-05-12 00:23:03,470 - INFO - allennlp.common.params - model_save_interval = None
2021-05-12 00:23:03,471 - INFO - allennlp.common.params - summary_interval = 100
2021-05-12 00:23:03,471 - INFO - allennlp.common.params - histogram_interval = None
2021-05-12 00:23:03,471 - INFO - allennlp.common.params - batch_size_interval = None
2021-05-12 00:23:03,471 - INFO - allennlp.common.params - should_log_parameter_statistics = True
2021-05-12 00:23:03,471 - INFO - allennlp.common.params - should_log_learning_rate = False
2021-05-12 00:23:03,471 - INFO - allennlp.common.params - get_batch_num_total = None
2021-05-12 00:23:03,488 - INFO - allennlp.training.trainer - Beginning training.
2021-05-12 00:23:03,488 - INFO - allennlp.training.trainer - Epoch 0/4
2021-05-12 00:23:03,488 - INFO - allennlp.training.trainer - Worker 0 memory usage: 3.4G
2021-05-12 00:23:03,489 - INFO - allennlp.training.trainer - GPU 0 memory usage: 760M
2021-05-12 00:23:03,493 - INFO - allennlp.training.trainer - Training
/home/lcur0308/.conda/envs/atcs-project/lib/python3.8/site-packages/torch/nn/modules/container.py:435: UserWarning: Setting attributes on ParameterList is not supported.
  warnings.warn("Setting attributes on ParameterList is not supported.")
  0%|          | 0/784 [00:00<?, ?it/s]
2021-05-12 00:23:03,493 - INFO - allennlp.data.samplers.bucket_batch_sampler - No sorting keys given; trying to guess a good one
2021-05-12 00:23:03,606 - INFO - allennlp.data.samplers.bucket_batch_sampler - Using ['tokens'] as the sorting keys
.run/deps/UAS: 0.0679, .run/deps/LAS: 0.0038, .run/deps/UEM: 0.0312, .run/deps/LEM: 0.0000, .run/.sum: 0.0717, batch_loss: 20.5978, loss: 29.6145 ||:   1%|          | 6/784 [00:02<04:23,  2.96it/s]
.run/deps/UAS: 0.1026, .run/deps/LAS: 0.0156, .run/deps/UEM: 0.0125, .run/deps/LEM: 0.0000, .run/.sum: 0.1182, batch_loss: 23.5780, loss: 25.4943 ||:   2%|1         | 15/784 [00:04<03:31,  3.63it/s]
.run/deps/UAS: 0.1170, .run/deps/LAS: 0.0312, .run/deps/UEM: 0.0550, .run/deps/LEM: 0.0400, .run/.sum: 0.1482, batch_loss: 15.4972, loss: 22.2692 ||:   3%|3         | 25/784 [00:06<03:08,  4.03it/s]
.run/deps/UAS: 0.1216, .run/deps/LAS: 0.0368, .run/deps/UEM: 0.0423, .run/deps/LEM: 0.0294, .run/.sum: 0.1584, batch_loss: 12.7622, loss: 20.3907 ||:   4%|4         | 34/784 [00:09<03:15,  3.83it/s]
.run/deps/UAS: 0.1285, .run/deps/LAS: 0.0434, .run/deps/UEM: 0.0342, .run/deps/LEM: 0.0238, .run/.sum: 0.1719, batch_loss: 12.6298, loss: 19.0277 ||:   5%|5         | 42/784 [00:11<03:12,  3.86it/s]
.run/deps/UAS: 0.1318, .run/deps/LAS: 0.0502, .run/deps/UEM: 0.0362, .run/deps/LEM: 0.0250, .run/.sum: 0.1820, batch_loss: 12.0278, loss: 17.6505 ||:   6%|6         | 50/784 [00:13<03:13,  3.79it/s]
.run/deps/UAS: 0.1320, .run/deps/LAS: 0.0529, .run/deps/UEM: 0.0366, .run/deps/LEM: 0.0237, .run/.sum: 0.1849, batch_loss: 10.2067, loss: 16.5835 ||:   7%|7         | 58/784 [00:15<03:13,  3.75it/s]
.run/deps/UAS: 0.1453, .run/deps/LAS: 0.0642, .run/deps/UEM: 0.0317, .run/deps/LEM: 0.0205, .run/.sum: 0.2095, batch_loss: 8.0903, loss: 15.4581 ||:   9%|8         | 67/784 [00:17<03:05,  3.87it/s] 
.run/deps/UAS: 0.1578, .run/deps/LAS: 0.0748, .run/deps/UEM: 0.0283, .run/deps/LEM: 0.0183, .run/.sum: 0.2325, batch_loss: 7.1189, loss: 14.5599 ||:  10%|9         | 75/784 [00:19<03:03,  3.86it/s]
.run/deps/UAS: 0.1685, .run/deps/LAS: 0.0842, .run/deps/UEM: 0.0283, .run/deps/LEM: 0.0171, .run/.sum: 0.2527, batch_loss: 8.6222, loss: 13.7741 ||:  11%|#         | 84/784 [00:21<02:57,  3.95it/s]
.run/deps/UAS: 0.1794, .run/deps/LAS: 0.0940, .run/deps/UEM: 0.0289, .run/deps/LEM: 0.0181, .run/.sum: 0.2735, batch_loss: 7.3484, loss: 13.1732 ||:  12%|#1        | 93/784 [00:23<02:48,  4.10it/s]
.run/deps/UAS: 0.1866, .run/deps/LAS: 0.1014, .run/deps/UEM: 0.0288, .run/deps/LEM: 0.0178, .run/.sum: 0.2880, batch_loss: 5.4233, loss: 12.6088 ||:  13%|#3        | 102/784 [00:26<03:07,  3.63it/s]
.run/deps/UAS: 0.1941, .run/deps/LAS: 0.1087, .run/deps/UEM: 0.0312, .run/deps/LEM: 0.0193, .run/.sum: 0.3028, batch_loss: 3.9250, loss: 12.0829 ||:  14%|#4        | 110/784 [00:29<03:02,  3.69it/s]
.run/deps/UAS: 0.1979, .run/deps/LAS: 0.1129, .run/deps/UEM: 0.0461, .run/deps/LEM: 0.0344, .run/.sum: 0.3108, batch_loss: 6.2533, loss: 11.6135 ||:  15%|#5        | 118/784 [00:31<03:04,  3.60it/s]
.run/deps/UAS: 0.2029, .run/deps/LAS: 0.1184, .run/deps/UEM: 0.0517, .run/deps/LEM: 0.0399, .run/.sum: 0.3213, batch_loss: 4.6689, loss: 11.1594 ||:  16%|#6        | 127/784 [00:33<02:55,  3.75it/s]
.run/deps/UAS: 0.2114, .run/deps/LAS: 0.1254, .run/deps/UEM: 0.0574, .run/deps/LEM: 0.0460, .run/.sum: 0.3369, batch_loss: 4.3293, loss: 10.7148 ||:  17%|#7        | 136/784 [00:35<02:44,  3.94it/s]
.run/deps/UAS: 0.2192, .run/deps/LAS: 0.1319, .run/deps/UEM: 0.0625, .run/deps/LEM: 0.0509, .run/.sum: 0.3511, batch_loss: 5.2521, loss: 10.2907 ||:  19%|#8        | 146/784 [00:37<02:33,  4.15it/s]
.run/deps/UAS: 0.2270, .run/deps/LAS: 0.1388, .run/deps/UEM: 0.0593, .run/deps/LEM: 0.0480, .run/.sum: 0.3657, batch_loss: 3.4725, loss: 9.9530 ||:  20%|#9        | 155/784 [00:39<02:30,  4.17it/s] 
.run/deps/UAS: 0.2342, .run/deps/LAS: 0.1455, .run/deps/UEM: 0.0583, .run/deps/LEM: 0.0461, .run/.sum: 0.3797, batch_loss: 3.3417, loss: 9.6482 ||:  21%|##        | 164/784 [00:42<02:28,  4.16it/s]
.run/deps/UAS: 0.2431, .run/deps/LAS: 0.1538, .run/deps/UEM: 0.0556, .run/deps/LEM: 0.0437, .run/.sum: 0.3969, batch_loss: 3.8332, loss: 9.3717 ||:  22%|##2       | 173/784 [00:44<02:33,  3.97it/s]
.run/deps/UAS: 0.2494, .run/deps/LAS: 0.1594, .run/deps/UEM: 0.0543, .run/deps/LEM: 0.0419, .run/.sum: 0.4088, batch_loss: 3.7959, loss: 9.1123 ||:  23%|##3       | 182/784 [00:46<02:32,  3.96it/s]
.run/deps/UAS: 0.2541, .run/deps/LAS: 0.1637, .run/deps/UEM: 0.0533, .run/deps/LEM: 0.0412, .run/.sum: 0.4179, batch_loss: 5.0731, loss: 8.8769 ||:  24%|##4       | 191/784 [00:49<02:31,  3.91it/s]
.run/deps/UAS: 0.2593, .run/deps/LAS: 0.1682, .run/deps/UEM: 0.0521, .run/deps/LEM: 0.0396, .run/.sum: 0.4276, batch_loss: 4.4679, loss: 8.6821 ||:  25%|##5       | 199/784 [00:51<02:29,  3.90it/s]
.run/deps/UAS: 0.2642, .run/deps/LAS: 0.1723, .run/deps/UEM: 0.0504, .run/deps/LEM: 0.0380, .run/.sum: 0.4365, batch_loss: 3.2387, loss: 8.4948 ||:  26%|##6       | 207/784 [00:53<02:39,  3.62it/s]
.run/deps/UAS: 0.2695, .run/deps/LAS: 0.1772, .run/deps/UEM: 0.0512, .run/deps/LEM: 0.0387, .run/.sum: 0.4467, batch_loss: 2.7965, loss: 8.3217 ||:  27%|##7       | 215/784 [00:56<02:45,  3.43it/s]
.run/deps/UAS: 0.2736, .run/deps/LAS: 0.1810, .run/deps/UEM: 0.0513, .run/deps/LEM: 0.0379, .run/.sum: 0.4546, batch_loss: 3.1775, loss: 8.1313 ||:  29%|##8       | 224/784 [00:58<02:34,  3.62it/s]
.run/deps/UAS: 0.2780, .run/deps/LAS: 0.1851, .run/deps/UEM: 0.0555, .run/deps/LEM: 0.0415, .run/.sum: 0.4631, batch_loss: 2.9929, loss: 7.9809 ||:  30%|##9       | 232/784 [01:00<02:29,  3.69it/s]
.run/deps/UAS: 0.2845, .run/deps/LAS: 0.1908, .run/deps/UEM: 0.0594, .run/deps/LEM: 0.0446, .run/.sum: 0.4753, batch_loss: 2.7320, loss: 7.7961 ||:  31%|###       | 241/784 [01:02<02:21,  3.84it/s]
.run/deps/UAS: 0.2894, .run/deps/LAS: 0.1953, .run/deps/UEM: 0.0612, .run/deps/LEM: 0.0442, .run/.sum: 0.4847, batch_loss: 3.1642, loss: 7.6376 ||:  32%|###1      | 250/784 [01:04<02:14,  3.98it/s]
.run/deps/UAS: 0.2935, .run/deps/LAS: 0.1991, .run/deps/UEM: 0.0668, .run/deps/LEM: 0.0497, .run/.sum: 0.4926, batch_loss: 0.0909, loss: 7.4708 ||:  33%|###3      | 259/784 [01:07<02:08,  4.08it/s]
.run/deps/UAS: 0.2986, .run/deps/LAS: 0.2040, .run/deps/UEM: 0.0693, .run/deps/LEM: 0.0518, .run/.sum: 0.5026, batch_loss: 3.6089, loss: 7.3262 ||:  34%|###4      | 268/784 [01:09<02:05,  4.12it/s]
.run/deps/UAS: 0.3043, .run/deps/LAS: 0.2092, .run/deps/UEM: 0.0681, .run/deps/LEM: 0.0512, .run/.sum: 0.5135, batch_loss: 3.7109, loss: 7.1966 ||:  35%|###5      | 277/784 [01:11<02:05,  4.04it/s]
.run/deps/UAS: 0.3099, .run/deps/LAS: 0.2141, .run/deps/UEM: 0.0719, .run/deps/LEM: 0.0555, .run/.sum: 0.5239, batch_loss: 1.4462, loss: 7.0801 ||:  36%|###6      | 286/784 [01:13<02:06,  3.94it/s]
.run/deps/UAS: 0.3144, .run/deps/LAS: 0.2183, .run/deps/UEM: 0.0746, .run/deps/LEM: 0.0574, .run/.sum: 0.5327, batch_loss: 3.8404, loss: 6.9593 ||:  38%|###7      | 295/784 [01:15<01:59,  4.08it/s]
.run/deps/UAS: 0.3183, .run/deps/LAS: 0.2219, .run/deps/UEM: 0.0798, .run/deps/LEM: 0.0623, .run/.sum: 0.5402, batch_loss: 3.3269, loss: 6.8339 ||:  39%|###8      | 304/784 [01:18<02:04,  3.85it/s]
.run/deps/UAS: 0.3221, .run/deps/LAS: 0.2256, .run/deps/UEM: 0.0811, .run/deps/LEM: 0.0639, .run/.sum: 0.5477, batch_loss: 2.2294, loss: 6.7208 ||:  40%|###9      | 313/784 [01:20<01:59,  3.94it/s]
.run/deps/UAS: 0.3274, .run/deps/LAS: 0.2307, .run/deps/UEM: 0.0800, .run/deps/LEM: 0.0627, .run/.sum: 0.5581, batch_loss: 2.8587, loss: 6.6143 ||:  41%|####1     | 322/784 [01:23<01:56,  3.96it/s]
.run/deps/UAS: 0.3314, .run/deps/LAS: 0.2343, .run/deps/UEM: 0.0853, .run/deps/LEM: 0.0672, .run/.sum: 0.5657, batch_loss: 2.8882, loss: 6.5098 ||:  42%|####2     | 331/784 [01:25<01:53,  4.00it/s]
.run/deps/UAS: 0.3348, .run/deps/LAS: 0.2376, .run/deps/UEM: 0.0918, .run/deps/LEM: 0.0720, .run/.sum: 0.5724, batch_loss: 2.9919, loss: 6.4092 ||:  43%|####3     | 341/784 [01:27<01:44,  4.22it/s]
.run/deps/UAS: 0.3383, .run/deps/LAS: 0.2409, .run/deps/UEM: 0.0927, .run/deps/LEM: 0.0730, .run/.sum: 0.5792, batch_loss: 3.2525, loss: 6.3223 ||:  45%|####4     | 350/784 [01:29<01:46,  4.06it/s]
.run/deps/UAS: 0.3426, .run/deps/LAS: 0.2447, .run/deps/UEM: 0.0956, .run/deps/LEM: 0.0756, .run/.sum: 0.5873, batch_loss: 3.2732, loss: 6.2352 ||:  46%|####5     | 359/784 [01:32<01:47,  3.94it/s]
.run/deps/UAS: 0.3428, .run/deps/LAS: 0.2455, .run/deps/UEM: 0.0937, .run/deps/LEM: 0.0741, .run/.sum: 0.5883, batch_loss: 3.3106, loss: 6.1755 ||:  47%|####6     | 367/784 [01:34<01:53,  3.67it/s]
.run/deps/UAS: 0.3461, .run/deps/LAS: 0.2486, .run/deps/UEM: 0.0983, .run/deps/LEM: 0.0775, .run/.sum: 0.5947, batch_loss: 2.3579, loss: 6.0807 ||:  48%|####7     | 376/784 [01:36<01:45,  3.86it/s]
.run/deps/UAS: 0.3505, .run/deps/LAS: 0.2528, .run/deps/UEM: 0.0969, .run/deps/LEM: 0.0760, .run/.sum: 0.6032, batch_loss: 2.4678, loss: 6.0012 ||:  49%|####9     | 385/784 [01:38<01:40,  3.97it/s]
.run/deps/UAS: 0.3535, .run/deps/LAS: 0.2560, .run/deps/UEM: 0.1007, .run/deps/LEM: 0.0787, .run/.sum: 0.6096, batch_loss: 3.3848, loss: 5.9271 ||:  50%|#####     | 394/784 [01:41<01:39,  3.94it/s]
.run/deps/UAS: 0.3564, .run/deps/LAS: 0.2591, .run/deps/UEM: 0.1017, .run/deps/LEM: 0.0798, .run/.sum: 0.6156, batch_loss: 2.5430, loss: 5.8601 ||:  51%|#####1    | 402/784 [01:43<01:45,  3.64it/s]
.run/deps/UAS: 0.3592, .run/deps/LAS: 0.2616, .run/deps/UEM: 0.1018, .run/deps/LEM: 0.0797, .run/.sum: 0.6208, batch_loss: 1.9725, loss: 5.8001 ||:  52%|#####2    | 410/784 [01:46<01:42,  3.63it/s]
.run/deps/UAS: 0.3632, .run/deps/LAS: 0.2652, .run/deps/UEM: 0.1012, .run/deps/LEM: 0.0794, .run/.sum: 0.6285, batch_loss: 2.8220, loss: 5.7413 ||:  53%|#####3    | 418/784 [01:48<01:41,  3.61it/s]
.run/deps/UAS: 0.3664, .run/deps/LAS: 0.2682, .run/deps/UEM: 0.1012, .run/deps/LEM: 0.0791, .run/.sum: 0.6345, batch_loss: 3.1578, loss: 5.6779 ||:  54%|#####4    | 427/784 [01:50<01:34,  3.79it/s]
.run/deps/UAS: 0.3697, .run/deps/LAS: 0.2714, .run/deps/UEM: 0.1053, .run/deps/LEM: 0.0818, .run/.sum: 0.6410, batch_loss: 2.6870, loss: 5.5983 ||:  56%|#####5    | 437/784 [01:52<01:26,  4.02it/s]
.run/deps/UAS: 0.3733, .run/deps/LAS: 0.2747, .run/deps/UEM: 0.1051, .run/deps/LEM: 0.0810, .run/.sum: 0.6480, batch_loss: 2.4854, loss: 5.5370 ||:  57%|#####6    | 446/784 [01:54<01:23,  4.07it/s]
.run/deps/UAS: 0.3775, .run/deps/LAS: 0.2787, .run/deps/UEM: 0.1030, .run/deps/LEM: 0.0794, .run/.sum: 0.6562, batch_loss: 2.3970, loss: 5.4818 ||:  58%|#####8    | 455/784 [01:57<01:25,  3.87it/s]
.run/deps/UAS: 0.3808, .run/deps/LAS: 0.2819, .run/deps/UEM: 0.1063, .run/deps/LEM: 0.0818, .run/.sum: 0.6628, batch_loss: 0.7915, loss: 5.4130 ||:  59%|#####9    | 464/784 [01:59<01:19,  4.03it/s]
.run/deps/UAS: 0.3844, .run/deps/LAS: 0.2852, .run/deps/UEM: 0.1070, .run/deps/LEM: 0.0825, .run/.sum: 0.6697, batch_loss: 3.1251, loss: 5.3592 ||:  60%|######    | 473/784 [02:01<01:17,  4.00it/s]
.run/deps/UAS: 0.3869, .run/deps/LAS: 0.2878, .run/deps/UEM: 0.1113, .run/deps/LEM: 0.0865, .run/.sum: 0.6747, batch_loss: 3.0485, loss: 5.2978 ||:  61%|######1   | 482/784 [02:04<01:15,  3.98it/s]
.run/deps/UAS: 0.3887, .run/deps/LAS: 0.2896, .run/deps/UEM: 0.1098, .run/deps/LEM: 0.0851, .run/.sum: 0.6783, batch_loss: 2.4202, loss: 5.2574 ||:  62%|######2   | 490/784 [02:06<01:19,  3.69it/s]
.run/deps/UAS: 0.3916, .run/deps/LAS: 0.2924, .run/deps/UEM: 0.1136, .run/deps/LEM: 0.0887, .run/.sum: 0.6840, batch_loss: 2.2193, loss: 5.1954 ||:  64%|######3   | 499/784 [02:08<01:14,  3.83it/s]
.run/deps/UAS: 0.3940, .run/deps/LAS: 0.2948, .run/deps/UEM: 0.1137, .run/deps/LEM: 0.0885, .run/.sum: 0.6887, batch_loss: 3.3146, loss: 5.1574 ||:  65%|######4   | 507/784 [02:11<01:22,  3.35it/s]
.run/deps/UAS: 0.3967, .run/deps/LAS: 0.2975, .run/deps/UEM: 0.1142, .run/deps/LEM: 0.0882, .run/.sum: 0.6942, batch_loss: 2.6098, loss: 5.1067 ||:  66%|######5   | 516/784 [02:14<01:16,  3.53it/s]
.run/deps/UAS: 0.3990, .run/deps/LAS: 0.2998, .run/deps/UEM: 0.1143, .run/deps/LEM: 0.0884, .run/.sum: 0.6988, batch_loss: 2.4674, loss: 5.0584 ||:  67%|######7   | 526/784 [02:16<01:07,  3.84it/s]
.run/deps/UAS: 0.4018, .run/deps/LAS: 0.3024, .run/deps/UEM: 0.1143, .run/deps/LEM: 0.0884, .run/.sum: 0.7041, batch_loss: 2.8085, loss: 5.0196 ||:  68%|######8   | 535/784 [02:18<01:02,  3.98it/s]
.run/deps/UAS: 0.4045, .run/deps/LAS: 0.3051, .run/deps/UEM: 0.1158, .run/deps/LEM: 0.0900, .run/.sum: 0.7096, batch_loss: 1.2978, loss: 4.9685 ||:  69%|######9   | 544/784 [02:20<00:59,  4.03it/s]
.run/deps/UAS: 0.4079, .run/deps/LAS: 0.3082, .run/deps/UEM: 0.1145, .run/deps/LEM: 0.0886, .run/.sum: 0.7161, batch_loss: 2.4284, loss: 4.9279 ||:  71%|#######   | 553/784 [02:22<00:57,  3.99it/s]
.run/deps/UAS: 0.4099, .run/deps/LAS: 0.3103, .run/deps/UEM: 0.1171, .run/deps/LEM: 0.0903, .run/.sum: 0.7202, batch_loss: 0.8579, loss: 4.8846 ||:  72%|#######1  | 562/784 [02:24<00:54,  4.10it/s]
.run/deps/UAS: 0.4122, .run/deps/LAS: 0.3127, .run/deps/UEM: 0.1167, .run/deps/LEM: 0.0893, .run/.sum: 0.7249, batch_loss: 2.5077, loss: 4.8451 ||:  73%|#######2  | 571/784 [02:27<00:53,  3.98it/s]
.run/deps/UAS: 0.4149, .run/deps/LAS: 0.3152, .run/deps/UEM: 0.1160, .run/deps/LEM: 0.0887, .run/.sum: 0.7302, batch_loss: 2.7676, loss: 4.8094 ||:  74%|#######3  | 580/784 [02:29<00:50,  4.05it/s]
.run/deps/UAS: 0.4172, .run/deps/LAS: 0.3175, .run/deps/UEM: 0.1156, .run/deps/LEM: 0.0877, .run/.sum: 0.7348, batch_loss: 2.1032, loss: 4.7723 ||:  75%|#######5  | 589/784 [02:31<00:47,  4.14it/s]
.run/deps/UAS: 0.4199, .run/deps/LAS: 0.3202, .run/deps/UEM: 0.1179, .run/deps/LEM: 0.0885, .run/.sum: 0.7401, batch_loss: 1.7682, loss: 4.7223 ||:  76%|#######6  | 599/784 [02:33<00:42,  4.31it/s]
.run/deps/UAS: 0.4231, .run/deps/LAS: 0.3234, .run/deps/UEM: 0.1175, .run/deps/LEM: 0.0878, .run/.sum: 0.7465, batch_loss: 2.4454, loss: 4.6839 ||:  78%|#######7  | 608/784 [02:36<00:46,  3.81it/s]
.run/deps/UAS: 0.4257, .run/deps/LAS: 0.3260, .run/deps/UEM: 0.1187, .run/deps/LEM: 0.0887, .run/.sum: 0.7517, batch_loss: 1.8835, loss: 4.6454 ||:  79%|#######8  | 617/784 [02:38<00:42,  3.91it/s]
.run/deps/UAS: 0.4284, .run/deps/LAS: 0.3287, .run/deps/UEM: 0.1183, .run/deps/LEM: 0.0884, .run/.sum: 0.7572, batch_loss: 2.3846, loss: 4.6091 ||:  80%|#######9  | 626/784 [02:40<00:39,  3.97it/s]
.run/deps/UAS: 0.4312, .run/deps/LAS: 0.3314, .run/deps/UEM: 0.1187, .run/deps/LEM: 0.0880, .run/.sum: 0.7625, batch_loss: 1.9665, loss: 4.5725 ||:  81%|########  | 635/784 [02:43<00:36,  4.08it/s]
.run/deps/UAS: 0.4332, .run/deps/LAS: 0.3333, .run/deps/UEM: 0.1221, .run/deps/LEM: 0.0915, .run/.sum: 0.7665, batch_loss: 2.9804, loss: 4.5330 ||:  82%|########2 | 644/784 [02:45<00:33,  4.18it/s]
.run/deps/UAS: 0.4352, .run/deps/LAS: 0.3352, .run/deps/UEM: 0.1242, .run/deps/LEM: 0.0928, .run/.sum: 0.7705, batch_loss: 0.7943, loss: 4.4978 ||:  83%|########3 | 653/784 [02:47<00:30,  4.27it/s]
.run/deps/UAS: 0.4375, .run/deps/LAS: 0.3375, .run/deps/UEM: 0.1264, .run/deps/LEM: 0.0946, .run/.sum: 0.7751, batch_loss: 2.0822, loss: 4.4571 ||:  85%|########4 | 663/784 [02:49<00:27,  4.34it/s]
.run/deps/UAS: 0.4398, .run/deps/LAS: 0.3398, .run/deps/UEM: 0.1275, .run/deps/LEM: 0.0950, .run/.sum: 0.7795, batch_loss: 1.5658, loss: 4.4216 ||:  86%|########5 | 672/784 [02:51<00:25,  4.33it/s]
.run/deps/UAS: 0.4426, .run/deps/LAS: 0.3426, .run/deps/UEM: 0.1278, .run/deps/LEM: 0.0950, .run/.sum: 0.7851, batch_loss: 1.7712, loss: 4.3920 ||:  87%|########6 | 681/784 [02:53<00:24,  4.17it/s]
.run/deps/UAS: 0.4458, .run/deps/LAS: 0.3456, .run/deps/UEM: 0.1261, .run/deps/LEM: 0.0938, .run/.sum: 0.7914, batch_loss: 2.2658, loss: 4.3638 ||:  88%|########8 | 690/784 [02:56<00:23,  3.93it/s]
.run/deps/UAS: 0.4483, .run/deps/LAS: 0.3481, .run/deps/UEM: 0.1265, .run/deps/LEM: 0.0938, .run/.sum: 0.7963, batch_loss: 1.8506, loss: 4.3333 ||:  89%|########9 | 699/784 [02:58<00:21,  4.00it/s]
.run/deps/UAS: 0.4503, .run/deps/LAS: 0.3502, .run/deps/UEM: 0.1278, .run/deps/LEM: 0.0953, .run/.sum: 0.8005, batch_loss: 2.0473, loss: 4.3017 ||:  90%|######### | 708/784 [03:01<00:20,  3.74it/s]
.run/deps/UAS: 0.4519, .run/deps/LAS: 0.3518, .run/deps/UEM: 0.1315, .run/deps/LEM: 0.0989, .run/.sum: 0.8038, batch_loss: 2.3153, loss: 4.2698 ||:  91%|#########1| 717/784 [03:03<00:17,  3.86it/s]
.run/deps/UAS: 0.4543, .run/deps/LAS: 0.3544, .run/deps/UEM: 0.1303, .run/deps/LEM: 0.0978, .run/.sum: 0.8087, batch_loss: 1.9949, loss: 4.2427 ||:  93%|#########2| 726/784 [03:05<00:14,  3.95it/s]
.run/deps/UAS: 0.4564, .run/deps/LAS: 0.3566, .run/deps/UEM: 0.1315, .run/deps/LEM: 0.0983, .run/.sum: 0.8131, batch_loss: 1.1005, loss: 4.2128 ||:  94%|#########3| 735/784 [03:07<00:12,  4.03it/s]
.run/deps/UAS: 0.4580, .run/deps/LAS: 0.3584, .run/deps/UEM: 0.1314, .run/deps/LEM: 0.0979, .run/.sum: 0.8165, batch_loss: 2.8572, loss: 4.1879 ||:  95%|#########4| 744/784 [03:10<00:10,  3.93it/s]
.run/deps/UAS: 0.4603, .run/deps/LAS: 0.3607, .run/deps/UEM: 0.1305, .run/deps/LEM: 0.0971, .run/.sum: 0.8210, batch_loss: 2.4167, loss: 4.1657 ||:  96%|#########5| 752/784 [03:12<00:08,  3.93it/s]
.run/deps/UAS: 0.4625, .run/deps/LAS: 0.3629, .run/deps/UEM: 0.1306, .run/deps/LEM: 0.0969, .run/.sum: 0.8253, batch_loss: 1.7034, loss: 4.1450 ||:  97%|#########6| 760/784 [03:14<00:06,  3.88it/s]
.run/deps/UAS: 0.4645, .run/deps/LAS: 0.3649, .run/deps/UEM: 0.1300, .run/deps/LEM: 0.0962, .run/.sum: 0.8295, batch_loss: 2.1536, loss: 4.1234 ||:  98%|#########7| 768/784 [03:16<00:04,  3.85it/s]
.run/deps/UAS: 0.4663, .run/deps/LAS: 0.3668, .run/deps/UEM: 0.1312, .run/deps/LEM: 0.0971, .run/.sum: 0.8331, batch_loss: 2.3013, loss: 4.0971 ||:  99%|#########9| 777/784 [03:18<00:01,  3.92it/s]
.run/deps/UAS: 0.4684, .run/deps/LAS: 0.3688, .run/deps/UEM: 0.1302, .run/deps/LEM: 0.0962, .run/.sum: 0.8371, batch_loss: 2.1952, loss: 4.0785 ||: 100%|##########| 784/784 [03:20<00:00,  3.91it/s]
2021-05-12 00:26:26,834 - INFO - allennlp.training.trainer - Validating
  0%|          | 0/126 [00:00<?, ?it/s]
2021-05-12 00:26:26,838 - INFO - allennlp.data.samplers.bucket_batch_sampler - No sorting keys given; trying to guess a good one
2021-05-12 00:26:26,844 - INFO - allennlp.data.samplers.bucket_batch_sampler - Using ['tokens'] as the sorting keys
.run/deps/UAS: 0.8175, .run/deps/LAS: 0.7654, .run/deps/UEM: 0.5679, .run/deps/LEM: 0.4511, .run/.sum: 1.5829, batch_loss: 1.2743, loss: 1.0258 ||:  18%|#8        | 23/126 [00:02<00:08, 11.49it/s]
.run/deps/UAS: 0.8272, .run/deps/LAS: 0.7770, .run/deps/UEM: 0.4443, .run/deps/LEM: 0.3438, .run/.sum: 1.6042, batch_loss: 0.5914, loss: 1.0703 ||:  37%|###6      | 46/126 [00:04<00:07, 10.99it/s]
.run/deps/UAS: 0.8263, .run/deps/LAS: 0.7754, .run/deps/UEM: 0.4840, .run/deps/LEM: 0.3836, .run/.sum: 1.6018, batch_loss: 0.7376, loss: 1.1380 ||:  60%|#####9    | 75/126 [00:06<00:04, 12.49it/s]
.run/deps/UAS: 0.8323, .run/deps/LAS: 0.7822, .run/deps/UEM: 0.4810, .run/deps/LEM: 0.3740, .run/.sum: 1.6145, batch_loss: 0.9187, loss: 1.1218 ||:  84%|########4 | 106/126 [00:08<00:01, 13.64it/s]
.run/deps/UAS: 0.8339, .run/deps/LAS: 0.7825, .run/deps/UEM: 0.4640, .run/deps/LEM: 0.3541, .run/.sum: 1.6164, batch_loss: 0.9068, loss: 1.1127 ||: 100%|##########| 126/126 [00:09<00:00, 12.78it/s]
2021-05-12 00:26:36,702 - INFO - allennlp.training.tensorboard_writer -                        Training |  Validation
2021-05-12 00:26:36,706 - INFO - allennlp.training.tensorboard_writer - .run/.sum          |     0.837  |     1.616
2021-05-12 00:26:36,707 - INFO - allennlp.training.tensorboard_writer - .run/deps/LAS      |     0.369  |     0.782
2021-05-12 00:26:36,708 - INFO - allennlp.training.tensorboard_writer - .run/deps/LEM      |     0.096  |     0.354
2021-05-12 00:26:36,710 - INFO - allennlp.training.tensorboard_writer - .run/deps/UAS      |     0.468  |     0.834
2021-05-12 00:26:36,710 - INFO - allennlp.training.tensorboard_writer - .run/deps/UEM      |     0.130  |     0.464
2021-05-12 00:26:36,712 - INFO - allennlp.training.tensorboard_writer - gpu_0_memory_MB    |   759.616  |       N/A
2021-05-12 00:26:36,713 - INFO - allennlp.training.tensorboard_writer - loss               |     4.078  |     1.113
2021-05-12 00:26:36,713 - INFO - allennlp.training.tensorboard_writer - worker_0_memory_MB |  3452.391  |       N/A
2021-05-12 00:26:36,717 - INFO - udify.optimizers.ulmfit_sqrt - Gradual unfreezing finished. Training all layers.
2021-05-12 00:26:42,304 - INFO - allennlp.training.checkpointer - Best validation performance so far. Copying weights to 'logs/bert_finetune_en/2021.05.12_00.22.24/best.th'.
2021-05-12 00:26:44,175 - INFO - allennlp.training.trainer - Epoch duration: 0:03:40.686380
2021-05-12 00:26:44,176 - INFO - allennlp.training.trainer - Estimated training time remaining: 0:14:42
2021-05-12 00:26:44,176 - INFO - allennlp.training.trainer - Epoch 1/4
2021-05-12 00:26:44,177 - INFO - allennlp.training.trainer - Worker 0 memory usage: 4.1G
2021-05-12 00:26:44,178 - INFO - allennlp.training.trainer - GPU 0 memory usage: 5.5G
2021-05-12 00:26:44,181 - INFO - allennlp.training.trainer - Training
  0%|          | 0/784 [00:00<?, ?it/s]
.run/deps/UAS: 0.6587, .run/deps/LAS: 0.5704, .run/deps/UEM: 0.0859, .run/deps/LEM: 0.0234, .run/.sum: 1.2292, batch_loss: 1.8823, loss: 2.0298 ||:   1%|1         | 8/784 [00:02<03:16,  3.95it/s]
.run/deps/UAS: 0.6568, .run/deps/LAS: 0.5677, .run/deps/UEM: 0.1484, .run/deps/LEM: 0.0859, .run/.sum: 1.2245, batch_loss: 1.7407, loss: 1.8856 ||:   2%|2         | 16/784 [00:04<03:44,  3.41it/s]
.run/deps/UAS: 0.6656, .run/deps/LAS: 0.5755, .run/deps/UEM: 0.1659, .run/deps/LEM: 0.0986, .run/.sum: 1.2411, batch_loss: 1.5369, loss: 1.9399 ||:   3%|3         | 26/784 [00:06<03:11,  3.95it/s]
.run/deps/UAS: 0.6671, .run/deps/LAS: 0.5767, .run/deps/UEM: 0.1768, .run/deps/LEM: 0.1179, .run/.sum: 1.2439, batch_loss: 1.7900, loss: 1.8569 ||:   4%|4         | 35/784 [00:08<03:07,  4.00it/s]
.run/deps/UAS: 0.6699, .run/deps/LAS: 0.5789, .run/deps/UEM: 0.1832, .run/deps/LEM: 0.1264, .run/.sum: 1.2488, batch_loss: 2.3050, loss: 1.8057 ||:   6%|5         | 44/784 [00:11<03:01,  4.08it/s]
.run/deps/UAS: 0.6535, .run/deps/LAS: 0.5636, .run/deps/UEM: 0.1757, .run/deps/LEM: 0.1250, .run/.sum: 1.2170, batch_loss: 2.1290, loss: 1.8165 ||:   7%|6         | 53/784 [00:13<03:08,  3.89it/s]
.run/deps/UAS: 0.6578, .run/deps/LAS: 0.5663, .run/deps/UEM: 0.1784, .run/deps/LEM: 0.1270, .run/.sum: 1.2241, batch_loss: 2.1061, loss: 1.7859 ||:   8%|7         | 62/784 [00:15<03:02,  3.95it/s]
.run/deps/UAS: 0.6644, .run/deps/LAS: 0.5730, .run/deps/UEM: 0.1963, .run/deps/LEM: 0.1470, .run/.sum: 1.2374, batch_loss: 1.7428, loss: 1.7211 ||:   9%|9         | 71/784 [00:17<02:55,  4.06it/s]
.run/deps/UAS: 0.6598, .run/deps/LAS: 0.5686, .run/deps/UEM: 0.2039, .run/deps/LEM: 0.1523, .run/.sum: 1.2285, batch_loss: 1.3967, loss: 1.7158 ||:  10%|#         | 80/784 [00:20<03:03,  3.84it/s]
.run/deps/UAS: 0.6560, .run/deps/LAS: 0.5644, .run/deps/UEM: 0.1967, .run/deps/LEM: 0.1442, .run/.sum: 1.2205, batch_loss: 1.4134, loss: 1.7359 ||:  11%|#1        | 88/784 [00:22<03:04,  3.78it/s]
.run/deps/UAS: 0.6592, .run/deps/LAS: 0.5674, .run/deps/UEM: 0.2043, .run/deps/LEM: 0.1476, .run/.sum: 1.2265, batch_loss: 1.8691, loss: 1.7202 ||:  12%|#2        | 97/784 [00:24<02:57,  3.88it/s]
.run/deps/UAS: 0.6614, .run/deps/LAS: 0.5697, .run/deps/UEM: 0.2064, .run/deps/LEM: 0.1486, .run/.sum: 1.2311, batch_loss: 1.2695, loss: 1.7024 ||:  14%|#3        | 106/784 [00:27<02:51,  3.95it/s]
.run/deps/UAS: 0.6607, .run/deps/LAS: 0.5688, .run/deps/UEM: 0.2089, .run/deps/LEM: 0.1502, .run/.sum: 1.2295, batch_loss: 1.7517, loss: 1.7004 ||:  15%|#4        | 114/784 [00:29<02:51,  3.90it/s]
.run/deps/UAS: 0.6614, .run/deps/LAS: 0.5697, .run/deps/UEM: 0.2095, .run/deps/LEM: 0.1511, .run/.sum: 1.2311, batch_loss: 1.6721, loss: 1.6991 ||:  16%|#5        | 122/784 [00:31<03:04,  3.59it/s]
.run/deps/UAS: 0.6638, .run/deps/LAS: 0.5719, .run/deps/UEM: 0.2114, .run/deps/LEM: 0.1508, .run/.sum: 1.2357, batch_loss: 1.8408, loss: 1.6923 ||:  17%|#6        | 131/784 [00:34<02:54,  3.73it/s]
.run/deps/UAS: 0.6623, .run/deps/LAS: 0.5699, .run/deps/UEM: 0.2095, .run/deps/LEM: 0.1479, .run/.sum: 1.2322, batch_loss: 1.3401, loss: 1.7007 ||:  18%|#7        | 139/784 [00:36<02:54,  3.70it/s]
.run/deps/UAS: 0.6648, .run/deps/LAS: 0.5717, .run/deps/UEM: 0.2116, .run/deps/LEM: 0.1461, .run/.sum: 1.2365, batch_loss: 1.2041, loss: 1.6915 ||:  19%|#8        | 148/784 [00:38<02:45,  3.84it/s]
.run/deps/UAS: 0.6657, .run/deps/LAS: 0.5725, .run/deps/UEM: 0.2123, .run/deps/LEM: 0.1438, .run/.sum: 1.2383, batch_loss: 0.8348, loss: 1.6827 ||:  20%|#9        | 156/784 [00:40<02:41,  3.88it/s]
.run/deps/UAS: 0.6681, .run/deps/LAS: 0.5748, .run/deps/UEM: 0.2129, .run/deps/LEM: 0.1436, .run/.sum: 1.2429, batch_loss: 0.5331, loss: 1.6704 ||:  21%|##1       | 165/784 [00:42<02:33,  4.03it/s]
.run/deps/UAS: 0.6695, .run/deps/LAS: 0.5759, .run/deps/UEM: 0.2137, .run/deps/LEM: 0.1422, .run/.sum: 1.2454, batch_loss: 2.3150, loss: 1.6647 ||:  22%|##2       | 174/784 [00:44<02:28,  4.11it/s]
.run/deps/UAS: 0.6705, .run/deps/LAS: 0.5771, .run/deps/UEM: 0.2141, .run/deps/LEM: 0.1434, .run/.sum: 1.2476, batch_loss: 1.6728, loss: 1.6618 ||:  23%|##3       | 183/784 [00:46<02:24,  4.15it/s]
.run/deps/UAS: 0.6716, .run/deps/LAS: 0.5785, .run/deps/UEM: 0.2183, .run/deps/LEM: 0.1460, .run/.sum: 1.2502, batch_loss: 1.8870, loss: 1.6609 ||:  25%|##4       | 193/784 [00:48<02:19,  4.25it/s]
.run/deps/UAS: 0.6729, .run/deps/LAS: 0.5794, .run/deps/UEM: 0.2200, .run/deps/LEM: 0.1501, .run/.sum: 1.2523, batch_loss: 2.0376, loss: 1.6478 ||:  26%|##5       | 202/784 [00:50<02:15,  4.29it/s]
.run/deps/UAS: 0.6752, .run/deps/LAS: 0.5822, .run/deps/UEM: 0.2230, .run/deps/LEM: 0.1531, .run/.sum: 1.2574, batch_loss: 1.6347, loss: 1.6292 ||:  27%|##6       | 211/784 [00:53<02:13,  4.31it/s]
.run/deps/UAS: 0.6761, .run/deps/LAS: 0.5832, .run/deps/UEM: 0.2310, .run/deps/LEM: 0.1605, .run/.sum: 1.2593, batch_loss: 1.8651, loss: 1.6178 ||:  28%|##8       | 220/784 [00:55<02:20,  4.01it/s]
.run/deps/UAS: 0.6789, .run/deps/LAS: 0.5858, .run/deps/UEM: 0.2241, .run/deps/LEM: 0.1545, .run/.sum: 1.2648, batch_loss: 1.0049, loss: 1.6120 ||:  29%|##9       | 229/784 [00:57<02:18,  3.99it/s]
.run/deps/UAS: 0.6804, .run/deps/LAS: 0.5871, .run/deps/UEM: 0.2327, .run/deps/LEM: 0.1582, .run/.sum: 1.2675, batch_loss: 0.0209, loss: 1.6030 ||:  30%|###       | 239/784 [01:00<02:10,  4.19it/s]
.run/deps/UAS: 0.6806, .run/deps/LAS: 0.5874, .run/deps/UEM: 0.2341, .run/deps/LEM: 0.1593, .run/.sum: 1.2680, batch_loss: 1.3541, loss: 1.5967 ||:  32%|###1      | 248/784 [01:02<02:09,  4.13it/s]
.run/deps/UAS: 0.6821, .run/deps/LAS: 0.5888, .run/deps/UEM: 0.2430, .run/deps/LEM: 0.1674, .run/.sum: 1.2709, batch_loss: 0.4168, loss: 1.5835 ||:  33%|###2      | 258/784 [01:04<02:01,  4.32it/s]
.run/deps/UAS: 0.6813, .run/deps/LAS: 0.5885, .run/deps/UEM: 0.2467, .run/deps/LEM: 0.1704, .run/.sum: 1.2698, batch_loss: 1.5631, loss: 1.5744 ||:  34%|###4      | 267/784 [01:06<02:02,  4.20it/s]
.run/deps/UAS: 0.6823, .run/deps/LAS: 0.5893, .run/deps/UEM: 0.2473, .run/deps/LEM: 0.1719, .run/.sum: 1.2716, batch_loss: 1.8899, loss: 1.5687 ||:  35%|###5      | 276/784 [01:08<02:01,  4.17it/s]
.run/deps/UAS: 0.6840, .run/deps/LAS: 0.5908, .run/deps/UEM: 0.2423, .run/deps/LEM: 0.1682, .run/.sum: 1.2747, batch_loss: 1.5290, loss: 1.5693 ||:  36%|###6      | 285/784 [01:11<01:58,  4.20it/s]
.run/deps/UAS: 0.6849, .run/deps/LAS: 0.5919, .run/deps/UEM: 0.2417, .run/deps/LEM: 0.1677, .run/.sum: 1.2769, batch_loss: 0.7933, loss: 1.5694 ||:  38%|###7      | 294/784 [01:13<01:56,  4.20it/s]
.run/deps/UAS: 0.6867, .run/deps/LAS: 0.5935, .run/deps/UEM: 0.2422, .run/deps/LEM: 0.1675, .run/.sum: 1.2802, batch_loss: 1.6423, loss: 1.5602 ||:  39%|###8      | 303/784 [01:15<01:55,  4.16it/s]
.run/deps/UAS: 0.6865, .run/deps/LAS: 0.5935, .run/deps/UEM: 0.2382, .run/deps/LEM: 0.1647, .run/.sum: 1.2801, batch_loss: 1.4789, loss: 1.5609 ||:  40%|###9      | 312/784 [01:17<01:57,  4.03it/s]
.run/deps/UAS: 0.6859, .run/deps/LAS: 0.5932, .run/deps/UEM: 0.2338, .run/deps/LEM: 0.1614, .run/.sum: 1.2791, batch_loss: 1.7062, loss: 1.5652 ||:  41%|####      | 321/784 [01:20<02:04,  3.71it/s]
.run/deps/UAS: 0.6864, .run/deps/LAS: 0.5936, .run/deps/UEM: 0.2331, .run/deps/LEM: 0.1615, .run/.sum: 1.2801, batch_loss: 1.4815, loss: 1.5619 ||:  42%|####1     | 329/784 [01:22<02:02,  3.72it/s]
.run/deps/UAS: 0.6870, .run/deps/LAS: 0.5942, .run/deps/UEM: 0.2332, .run/deps/LEM: 0.1614, .run/.sum: 1.2812, batch_loss: 1.4857, loss: 1.5600 ||:  43%|####3     | 338/784 [01:24<01:56,  3.84it/s]
.run/deps/UAS: 0.6879, .run/deps/LAS: 0.5951, .run/deps/UEM: 0.2303, .run/deps/LEM: 0.1597, .run/.sum: 1.2831, batch_loss: 1.1728, loss: 1.5589 ||:  44%|####4     | 346/784 [01:27<01:54,  3.84it/s]
.run/deps/UAS: 0.6881, .run/deps/LAS: 0.5953, .run/deps/UEM: 0.2294, .run/deps/LEM: 0.1588, .run/.sum: 1.2833, batch_loss: 1.5513, loss: 1.5601 ||:  45%|####5     | 355/784 [01:29<01:48,  3.97it/s]
.run/deps/UAS: 0.6874, .run/deps/LAS: 0.5947, .run/deps/UEM: 0.2278, .run/deps/LEM: 0.1572, .run/.sum: 1.2821, batch_loss: 1.6437, loss: 1.5648 ||:  46%|####6     | 363/784 [01:31<01:47,  3.91it/s]
.run/deps/UAS: 0.6885, .run/deps/LAS: 0.5958, .run/deps/UEM: 0.2255, .run/deps/LEM: 0.1552, .run/.sum: 1.2843, batch_loss: 1.6481, loss: 1.5608 ||:  47%|####7     | 372/784 [01:33<01:42,  4.04it/s]
.run/deps/UAS: 0.6885, .run/deps/LAS: 0.5963, .run/deps/UEM: 0.2293, .run/deps/LEM: 0.1591, .run/.sum: 1.2849, batch_loss: 1.1239, loss: 1.5519 ||:  49%|####8     | 381/784 [01:35<01:38,  4.07it/s]
.run/deps/UAS: 0.6889, .run/deps/LAS: 0.5969, .run/deps/UEM: 0.2335, .run/deps/LEM: 0.1616, .run/.sum: 1.2858, batch_loss: 1.2640, loss: 1.5469 ||:  50%|####9     | 391/784 [01:37<01:31,  4.28it/s]
.run/deps/UAS: 0.6895, .run/deps/LAS: 0.5976, .run/deps/UEM: 0.2309, .run/deps/LEM: 0.1598, .run/.sum: 1.2871, batch_loss: 1.7358, loss: 1.5447 ||:  51%|#####1    | 400/784 [01:39<01:32,  4.17it/s]
.run/deps/UAS: 0.6902, .run/deps/LAS: 0.5982, .run/deps/UEM: 0.2295, .run/deps/LEM: 0.1588, .run/.sum: 1.2883, batch_loss: 1.7670, loss: 1.5424 ||:  52%|#####2    | 409/784 [01:42<01:30,  4.16it/s]
.run/deps/UAS: 0.6903, .run/deps/LAS: 0.5984, .run/deps/UEM: 0.2316, .run/deps/LEM: 0.1604, .run/.sum: 1.2887, batch_loss: 1.0884, loss: 1.5386 ||:  53%|#####3    | 418/784 [01:44<01:36,  3.79it/s]
.run/deps/UAS: 0.6910, .run/deps/LAS: 0.5989, .run/deps/UEM: 0.2339, .run/deps/LEM: 0.1630, .run/.sum: 1.2898, batch_loss: 1.6576, loss: 1.5337 ||:  55%|#####4    | 428/784 [01:47<01:29,  3.99it/s]
.run/deps/UAS: 0.6912, .run/deps/LAS: 0.5990, .run/deps/UEM: 0.2336, .run/deps/LEM: 0.1622, .run/.sum: 1.2903, batch_loss: 2.0713, loss: 1.5338 ||:  56%|#####5    | 437/784 [01:49<01:28,  3.92it/s]
.run/deps/UAS: 0.6914, .run/deps/LAS: 0.5993, .run/deps/UEM: 0.2356, .run/deps/LEM: 0.1640, .run/.sum: 1.2908, batch_loss: 0.0120, loss: 1.5263 ||:  57%|#####6    | 446/784 [01:51<01:24,  4.00it/s]
.run/deps/UAS: 0.6919, .run/deps/LAS: 0.5997, .run/deps/UEM: 0.2352, .run/deps/LEM: 0.1628, .run/.sum: 1.2916, batch_loss: 1.4921, loss: 1.5265 ||:  58%|#####8    | 455/784 [01:53<01:19,  4.13it/s]
.run/deps/UAS: 0.6925, .run/deps/LAS: 0.6003, .run/deps/UEM: 0.2326, .run/deps/LEM: 0.1608, .run/.sum: 1.2928, batch_loss: 1.4493, loss: 1.5283 ||:  59%|#####9    | 464/784 [01:55<01:16,  4.19it/s]
.run/deps/UAS: 0.6928, .run/deps/LAS: 0.6006, .run/deps/UEM: 0.2345, .run/deps/LEM: 0.1625, .run/.sum: 1.2934, batch_loss: 1.4930, loss: 1.5225 ||:  60%|######    | 473/784 [01:57<01:13,  4.25it/s]
.run/deps/UAS: 0.6924, .run/deps/LAS: 0.6005, .run/deps/UEM: 0.2335, .run/deps/LEM: 0.1614, .run/.sum: 1.2929, batch_loss: 1.0919, loss: 1.5239 ||:  61%|######1   | 482/784 [01:59<01:11,  4.21it/s]
.run/deps/UAS: 0.6928, .run/deps/LAS: 0.6010, .run/deps/UEM: 0.2326, .run/deps/LEM: 0.1610, .run/.sum: 1.2938, batch_loss: 0.0257, loss: 1.5205 ||:  63%|######2   | 491/784 [02:02<01:10,  4.15it/s]
.run/deps/UAS: 0.6932, .run/deps/LAS: 0.6016, .run/deps/UEM: 0.2310, .run/deps/LEM: 0.1593, .run/.sum: 1.2948, batch_loss: 1.8046, loss: 1.5202 ||:  64%|######3   | 500/784 [02:04<01:09,  4.08it/s]
.run/deps/UAS: 0.6923, .run/deps/LAS: 0.6008, .run/deps/UEM: 0.2301, .run/deps/LEM: 0.1584, .run/.sum: 1.2930, batch_loss: 2.2090, loss: 1.5209 ||:  65%|######4   | 509/784 [02:07<01:11,  3.85it/s]
.run/deps/UAS: 0.6926, .run/deps/LAS: 0.6010, .run/deps/UEM: 0.2290, .run/deps/LEM: 0.1569, .run/.sum: 1.2936, batch_loss: 1.7662, loss: 1.5210 ||:  66%|######5   | 517/784 [02:10<01:16,  3.50it/s]
.run/deps/UAS: 0.6931, .run/deps/LAS: 0.6015, .run/deps/UEM: 0.2284, .run/deps/LEM: 0.1559, .run/.sum: 1.2946, batch_loss: 1.4448, loss: 1.5209 ||:  67%|######7   | 526/784 [02:12<01:09,  3.71it/s]
.run/deps/UAS: 0.6934, .run/deps/LAS: 0.6019, .run/deps/UEM: 0.2291, .run/deps/LEM: 0.1570, .run/.sum: 1.2953, batch_loss: 1.5244, loss: 1.5162 ||:  68%|######8   | 535/784 [02:14<01:04,  3.83it/s]
.run/deps/UAS: 0.6933, .run/deps/LAS: 0.6019, .run/deps/UEM: 0.2276, .run/deps/LEM: 0.1562, .run/.sum: 1.2951, batch_loss: 1.5675, loss: 1.5178 ||:  69%|######9   | 543/784 [02:16<01:03,  3.77it/s]
.run/deps/UAS: 0.6934, .run/deps/LAS: 0.6020, .run/deps/UEM: 0.2304, .run/deps/LEM: 0.1593, .run/.sum: 1.2954, batch_loss: 1.3689, loss: 1.5115 ||:  70%|#######   | 552/784 [02:18<00:59,  3.90it/s]
.run/deps/UAS: 0.6936, .run/deps/LAS: 0.6022, .run/deps/UEM: 0.2297, .run/deps/LEM: 0.1590, .run/.sum: 1.2958, batch_loss: 1.5787, loss: 1.5113 ||:  72%|#######1  | 561/784 [02:20<00:56,  3.97it/s]
.run/deps/UAS: 0.6943, .run/deps/LAS: 0.6031, .run/deps/UEM: 0.2342, .run/deps/LEM: 0.1634, .run/.sum: 1.2973, batch_loss: 0.6980, loss: 1.5040 ||:  73%|#######2  | 571/784 [02:22<00:50,  4.24it/s]
.run/deps/UAS: 0.6944, .run/deps/LAS: 0.6032, .run/deps/UEM: 0.2321, .run/deps/LEM: 0.1620, .run/.sum: 1.2976, batch_loss: 2.1197, loss: 1.5032 ||:  74%|#######3  | 580/784 [02:25<00:49,  4.11it/s]
.run/deps/UAS: 0.6955, .run/deps/LAS: 0.6044, .run/deps/UEM: 0.2309, .run/deps/LEM: 0.1605, .run/.sum: 1.2999, batch_loss: 1.1466, loss: 1.4992 ||:  75%|#######5  | 589/784 [02:27<00:46,  4.21it/s]
.run/deps/UAS: 0.6964, .run/deps/LAS: 0.6054, .run/deps/UEM: 0.2312, .run/deps/LEM: 0.1608, .run/.sum: 1.3018, batch_loss: 0.8549, loss: 1.4954 ||:  76%|#######6  | 598/784 [02:29<00:43,  4.28it/s]
.run/deps/UAS: 0.6969, .run/deps/LAS: 0.6058, .run/deps/UEM: 0.2307, .run/deps/LEM: 0.1600, .run/.sum: 1.3027, batch_loss: 1.6284, loss: 1.4949 ||:  78%|#######7  | 608/784 [02:31<00:41,  4.28it/s]
.run/deps/UAS: 0.6963, .run/deps/LAS: 0.6057, .run/deps/UEM: 0.2301, .run/deps/LEM: 0.1599, .run/.sum: 1.3020, batch_loss: 2.2391, loss: 1.4990 ||:  79%|#######8  | 617/784 [02:34<00:44,  3.77it/s]
.run/deps/UAS: 0.6968, .run/deps/LAS: 0.6060, .run/deps/UEM: 0.2292, .run/deps/LEM: 0.1589, .run/.sum: 1.3028, batch_loss: 1.3157, loss: 1.4989 ||:  80%|#######9  | 626/784 [02:36<00:41,  3.84it/s]
.run/deps/UAS: 0.6967, .run/deps/LAS: 0.6060, .run/deps/UEM: 0.2300, .run/deps/LEM: 0.1593, .run/.sum: 1.3027, batch_loss: 1.4728, loss: 1.4974 ||:  81%|########  | 634/784 [02:38<00:38,  3.88it/s]
.run/deps/UAS: 0.6970, .run/deps/LAS: 0.6063, .run/deps/UEM: 0.2290, .run/deps/LEM: 0.1591, .run/.sum: 1.3033, batch_loss: 1.4796, loss: 1.4958 ||:  82%|########1 | 642/784 [02:40<00:36,  3.89it/s]
.run/deps/UAS: 0.6974, .run/deps/LAS: 0.6068, .run/deps/UEM: 0.2300, .run/deps/LEM: 0.1602, .run/.sum: 1.3042, batch_loss: 1.2294, loss: 1.4910 ||:  83%|########3 | 652/784 [02:43<00:32,  4.07it/s]
.run/deps/UAS: 0.6980, .run/deps/LAS: 0.6074, .run/deps/UEM: 0.2313, .run/deps/LEM: 0.1618, .run/.sum: 1.3054, batch_loss: 1.1311, loss: 1.4861 ||:  84%|########4 | 661/784 [02:45<00:29,  4.19it/s]
.run/deps/UAS: 0.6981, .run/deps/LAS: 0.6076, .run/deps/UEM: 0.2294, .run/deps/LEM: 0.1603, .run/.sum: 1.3057, batch_loss: 1.9952, loss: 1.4876 ||:  85%|########5 | 670/784 [02:47<00:29,  3.92it/s]
.run/deps/UAS: 0.6983, .run/deps/LAS: 0.6079, .run/deps/UEM: 0.2294, .run/deps/LEM: 0.1603, .run/.sum: 1.3062, batch_loss: 1.4819, loss: 1.4872 ||:  86%|########6 | 678/784 [02:49<00:26,  3.93it/s]
.run/deps/UAS: 0.6984, .run/deps/LAS: 0.6081, .run/deps/UEM: 0.2285, .run/deps/LEM: 0.1597, .run/.sum: 1.3066, batch_loss: 1.7197, loss: 1.4882 ||:  88%|########7 | 686/784 [02:51<00:25,  3.90it/s]
.run/deps/UAS: 0.6968, .run/deps/LAS: 0.6066, .run/deps/UEM: 0.2277, .run/deps/LEM: 0.1585, .run/.sum: 1.3034, batch_loss: 2.7953, loss: 1.4909 ||:  89%|########8 | 695/784 [02:54<00:24,  3.66it/s]
.run/deps/UAS: 0.6967, .run/deps/LAS: 0.6067, .run/deps/UEM: 0.2296, .run/deps/LEM: 0.1599, .run/.sum: 1.3033, batch_loss: 1.4672, loss: 1.4880 ||:  90%|########9 | 704/784 [02:56<00:20,  3.82it/s]
.run/deps/UAS: 0.6967, .run/deps/LAS: 0.6067, .run/deps/UEM: 0.2291, .run/deps/LEM: 0.1597, .run/.sum: 1.3034, batch_loss: 1.3709, loss: 1.4867 ||:  91%|######### | 713/784 [02:58<00:18,  3.90it/s]
.run/deps/UAS: 0.6970, .run/deps/LAS: 0.6072, .run/deps/UEM: 0.2289, .run/deps/LEM: 0.1598, .run/.sum: 1.3042, batch_loss: 1.2471, loss: 1.4843 ||:  92%|#########1| 721/784 [03:01<00:17,  3.64it/s]
.run/deps/UAS: 0.6971, .run/deps/LAS: 0.6073, .run/deps/UEM: 0.2289, .run/deps/LEM: 0.1600, .run/.sum: 1.3045, batch_loss: 1.7346, loss: 1.4825 ||:  93%|#########3| 730/784 [03:03<00:14,  3.73it/s]
.run/deps/UAS: 0.6974, .run/deps/LAS: 0.6077, .run/deps/UEM: 0.2303, .run/deps/LEM: 0.1614, .run/.sum: 1.3051, batch_loss: 1.3483, loss: 1.4810 ||:  94%|#########4| 740/784 [03:06<00:11,  3.98it/s]
.run/deps/UAS: 0.6970, .run/deps/LAS: 0.6075, .run/deps/UEM: 0.2320, .run/deps/LEM: 0.1629, .run/.sum: 1.3045, batch_loss: 2.1127, loss: 1.4782 ||:  96%|#########5| 749/784 [03:08<00:08,  4.00it/s]
.run/deps/UAS: 0.6974, .run/deps/LAS: 0.6080, .run/deps/UEM: 0.2316, .run/deps/LEM: 0.1621, .run/.sum: 1.3053, batch_loss: 1.1549, loss: 1.4774 ||:  97%|#########6| 758/784 [03:10<00:06,  4.05it/s]
.run/deps/UAS: 0.6976, .run/deps/LAS: 0.6081, .run/deps/UEM: 0.2312, .run/deps/LEM: 0.1615, .run/.sum: 1.3057, batch_loss: 1.6831, loss: 1.4757 ||:  98%|#########7| 767/784 [03:12<00:04,  3.99it/s]
.run/deps/UAS: 0.6969, .run/deps/LAS: 0.6074, .run/deps/UEM: 0.2310, .run/deps/LEM: 0.1617, .run/.sum: 1.3044, batch_loss: 1.9650, loss: 1.4758 ||:  99%|#########8| 776/784 [03:15<00:02,  3.79it/s]
.run/deps/UAS: 0.6972, .run/deps/LAS: 0.6077, .run/deps/UEM: 0.2306, .run/deps/LEM: 0.1607, .run/.sum: 1.3049, batch_loss: 1.2314, loss: 1.4754 ||: 100%|##########| 784/784 [03:17<00:00,  3.97it/s]
2021-05-12 00:30:04,427 - INFO - allennlp.training.trainer - Validating
  0%|          | 0/126 [00:00<?, ?it/s]
.run/deps/UAS: 0.8655, .run/deps/LAS: 0.8194, .run/deps/UEM: 0.6250, .run/deps/LEM: 0.5035, .run/.sum: 1.6849, batch_loss: 0.5927, loss: 0.5596 ||:  14%|#4        | 18/126 [00:02<00:12,  8.79it/s]
.run/deps/UAS: 0.8664, .run/deps/LAS: 0.8228, .run/deps/UEM: 0.5781, .run/deps/LEM: 0.4813, .run/.sum: 1.6892, batch_loss: 0.5757, loss: 0.6659 ||:  32%|###1      | 40/126 [00:04<00:08,  9.99it/s]
.run/deps/UAS: 0.8716, .run/deps/LAS: 0.8292, .run/deps/UEM: 0.5938, .run/deps/LEM: 0.4839, .run/.sum: 1.7008, batch_loss: 0.0033, loss: 0.6453 ||:  56%|#####5    | 70/126 [00:06<00:04, 12.16it/s]
.run/deps/UAS: 0.8691, .run/deps/LAS: 0.8259, .run/deps/UEM: 0.5631, .run/deps/LEM: 0.4422, .run/.sum: 1.6950, batch_loss: 1.0293, loss: 0.6657 ||:  75%|#######5  | 95/126 [00:08<00:02, 11.59it/s]
.run/deps/UAS: 0.8678, .run/deps/LAS: 0.8248, .run/deps/UEM: 0.5296, .run/deps/LEM: 0.4111, .run/.sum: 1.6926, batch_loss: 0.4651, loss: 0.6582 ||:  94%|#########4| 119/126 [00:11<00:00, 10.19it/s]
.run/deps/UAS: 0.8661, .run/deps/LAS: 0.8234, .run/deps/UEM: 0.5305, .run/deps/LEM: 0.4141, .run/.sum: 1.6895, batch_loss: 0.6812, loss: 0.6571 ||: 100%|##########| 126/126 [00:12<00:00, 10.37it/s]
2021-05-12 00:30:16,578 - INFO - allennlp.training.tensorboard_writer -                        Training |  Validation
2021-05-12 00:30:16,579 - INFO - allennlp.training.tensorboard_writer - .run/.sum          |     1.305  |     1.689
2021-05-12 00:30:16,579 - INFO - allennlp.training.tensorboard_writer - .run/deps/LAS      |     0.608  |     0.823
2021-05-12 00:30:16,579 - INFO - allennlp.training.tensorboard_writer - .run/deps/LEM      |     0.161  |     0.414
2021-05-12 00:30:16,579 - INFO - allennlp.training.tensorboard_writer - .run/deps/UAS      |     0.697  |     0.866
2021-05-12 00:30:16,580 - INFO - allennlp.training.tensorboard_writer - .run/deps/UEM      |     0.231  |     0.530
2021-05-12 00:30:16,580 - INFO - allennlp.training.tensorboard_writer - gpu_0_memory_MB    |  5612.324  |       N/A
2021-05-12 00:30:16,580 - INFO - allennlp.training.tensorboard_writer - loss               |     1.475  |     0.657
2021-05-12 00:30:16,580 - INFO - allennlp.training.tensorboard_writer - worker_0_memory_MB |  4218.797  |       N/A
2021-05-12 00:30:16,584 - INFO - udify.optimizers.ulmfit_sqrt - Gradual unfreezing finished. Training all layers.
2021-05-12 00:30:22,234 - INFO - allennlp.training.checkpointer - Best validation performance so far. Copying weights to 'logs/bert_finetune_en/2021.05.12_00.22.24/best.th'.
2021-05-12 00:30:24,293 - INFO - allennlp.training.trainer - Epoch duration: 0:03:40.116400
2021-05-12 00:30:24,293 - INFO - allennlp.training.trainer - Estimated training time remaining: 0:11:01
2021-05-12 00:30:24,294 - INFO - allennlp.training.trainer - Epoch 2/4
2021-05-12 00:30:24,294 - INFO - allennlp.training.trainer - Worker 0 memory usage: 4.1G
2021-05-12 00:30:24,294 - INFO - allennlp.training.trainer - GPU 0 memory usage: 5.5G
2021-05-12 00:30:24,297 - INFO - allennlp.training.trainer - Training
  0%|          | 0/784 [00:00<?, ?it/s]
.run/deps/UAS: 0.7340, .run/deps/LAS: 0.6516, .run/deps/UEM: 0.3203, .run/deps/LEM: 0.2500, .run/.sum: 1.3856, batch_loss: 0.9777, loss: 1.2086 ||:   1%|1         | 8/784 [00:02<03:18,  3.91it/s]
.run/deps/UAS: 0.7180, .run/deps/LAS: 0.6273, .run/deps/UEM: 0.1992, .run/deps/LEM: 0.1406, .run/.sum: 1.3453, batch_loss: 1.3602, loss: 1.3276 ||:   2%|2         | 16/784 [00:04<03:18,  3.87it/s]
.run/deps/UAS: 0.7210, .run/deps/LAS: 0.6371, .run/deps/UEM: 0.2150, .run/deps/LEM: 0.1500, .run/.sum: 1.3581, batch_loss: 0.9171, loss: 1.3428 ||:   3%|3         | 25/784 [00:06<03:06,  4.08it/s]
.run/deps/UAS: 0.7243, .run/deps/LAS: 0.6426, .run/deps/UEM: 0.2059, .run/deps/LEM: 0.1434, .run/.sum: 1.3669, batch_loss: 1.8271, loss: 1.3287 ||:   4%|4         | 34/784 [00:08<03:23,  3.68it/s]
.run/deps/UAS: 0.7274, .run/deps/LAS: 0.6475, .run/deps/UEM: 0.2180, .run/deps/LEM: 0.1541, .run/.sum: 1.3749, batch_loss: 1.2453, loss: 1.3286 ||:   5%|5         | 43/784 [00:11<03:09,  3.92it/s]
.run/deps/UAS: 0.7230, .run/deps/LAS: 0.6431, .run/deps/UEM: 0.2083, .run/deps/LEM: 0.1471, .run/.sum: 1.3660, batch_loss: 0.7120, loss: 1.3442 ||:   7%|6         | 51/784 [00:13<03:06,  3.92it/s]
.run/deps/UAS: 0.7200, .run/deps/LAS: 0.6390, .run/deps/UEM: 0.2333, .run/deps/LEM: 0.1729, .run/.sum: 1.3589, batch_loss: 1.8999, loss: 1.3265 ||:   8%|7         | 60/784 [00:15<03:03,  3.95it/s]
.run/deps/UAS: 0.7224, .run/deps/LAS: 0.6413, .run/deps/UEM: 0.2264, .run/deps/LEM: 0.1667, .run/.sum: 1.3637, batch_loss: 1.4103, loss: 1.3147 ||:   9%|8         | 69/784 [00:17<02:56,  4.06it/s]
.run/deps/UAS: 0.7207, .run/deps/LAS: 0.6399, .run/deps/UEM: 0.2204, .run/deps/LEM: 0.1619, .run/.sum: 1.3606, batch_loss: 1.5317, loss: 1.3222 ||:  10%|9         | 78/784 [00:19<03:00,  3.92it/s]
.run/deps/UAS: 0.7220, .run/deps/LAS: 0.6405, .run/deps/UEM: 0.2277, .run/deps/LEM: 0.1674, .run/.sum: 1.3626, batch_loss: 0.0046, loss: 1.3165 ||:  11%|#1        | 87/784 [00:22<02:54,  3.98it/s]
.run/deps/UAS: 0.7229, .run/deps/LAS: 0.6410, .run/deps/UEM: 0.2274, .run/deps/LEM: 0.1662, .run/.sum: 1.3638, batch_loss: 1.5012, loss: 1.3316 ||:  12%|#2        | 97/784 [00:24<02:46,  4.12it/s]
.run/deps/UAS: 0.7224, .run/deps/LAS: 0.6401, .run/deps/UEM: 0.2246, .run/deps/LEM: 0.1627, .run/.sum: 1.3625, batch_loss: 1.5543, loss: 1.3343 ||:  14%|#3        | 106/784 [00:26<02:45,  4.09it/s]
.run/deps/UAS: 0.7226, .run/deps/LAS: 0.6401, .run/deps/UEM: 0.2152, .run/deps/LEM: 0.1538, .run/.sum: 1.3627, batch_loss: 1.4592, loss: 1.3393 ||:  15%|#4        | 115/784 [00:28<02:43,  4.10it/s]
.run/deps/UAS: 0.7252, .run/deps/LAS: 0.6425, .run/deps/UEM: 0.2340, .run/deps/LEM: 0.1720, .run/.sum: 1.3677, batch_loss: 1.2624, loss: 1.3137 ||:  16%|#5        | 125/784 [00:30<02:33,  4.30it/s]
.run/deps/UAS: 0.7275, .run/deps/LAS: 0.6451, .run/deps/UEM: 0.2267, .run/deps/LEM: 0.1679, .run/.sum: 1.3726, batch_loss: 1.2769, loss: 1.3077 ||:  17%|#7        | 134/784 [00:33<02:50,  3.80it/s]
.run/deps/UAS: 0.7292, .run/deps/LAS: 0.6462, .run/deps/UEM: 0.2334, .run/deps/LEM: 0.1740, .run/.sum: 1.3753, batch_loss: 1.2597, loss: 1.2950 ||:  18%|#8        | 143/784 [00:35<02:41,  3.97it/s]
.run/deps/UAS: 0.7270, .run/deps/LAS: 0.6438, .run/deps/UEM: 0.2373, .run/deps/LEM: 0.1739, .run/.sum: 1.3708, batch_loss: 1.3540, loss: 1.3019 ||:  19%|#9        | 152/784 [00:38<02:41,  3.90it/s]
.run/deps/UAS: 0.7278, .run/deps/LAS: 0.6443, .run/deps/UEM: 0.2387, .run/deps/LEM: 0.1727, .run/.sum: 1.3722, batch_loss: 0.7834, loss: 1.2996 ||:  21%|##        | 161/784 [00:40<02:36,  3.97it/s]
.run/deps/UAS: 0.7293, .run/deps/LAS: 0.6456, .run/deps/UEM: 0.2474, .run/deps/LEM: 0.1806, .run/.sum: 1.3749, batch_loss: 1.7650, loss: 1.2943 ||:  22%|##1       | 171/784 [00:42<02:24,  4.24it/s]
.run/deps/UAS: 0.7276, .run/deps/LAS: 0.6437, .run/deps/UEM: 0.2365, .run/deps/LEM: 0.1729, .run/.sum: 1.3713, batch_loss: 1.3117, loss: 1.3096 ||:  23%|##2       | 180/784 [00:45<02:32,  3.97it/s]
.run/deps/UAS: 0.7282, .run/deps/LAS: 0.6439, .run/deps/UEM: 0.2418, .run/deps/LEM: 0.1780, .run/.sum: 1.3721, batch_loss: 1.3593, loss: 1.3078 ||:  24%|##4       | 190/784 [00:47<02:21,  4.19it/s]
.run/deps/UAS: 0.7293, .run/deps/LAS: 0.6447, .run/deps/UEM: 0.2440, .run/deps/LEM: 0.1778, .run/.sum: 1.3741, batch_loss: 1.3617, loss: 1.3069 ||:  25%|##5       | 199/784 [00:49<02:17,  4.26it/s]
.run/deps/UAS: 0.7225, .run/deps/LAS: 0.6383, .run/deps/UEM: 0.2501, .run/deps/LEM: 0.1833, .run/.sum: 1.3608, batch_loss: 1.5107, loss: 1.3055 ||:  27%|##6       | 208/784 [00:52<02:28,  3.87it/s]
.run/deps/UAS: 0.7240, .run/deps/LAS: 0.6391, .run/deps/UEM: 0.2481, .run/deps/LEM: 0.1812, .run/.sum: 1.3632, batch_loss: 1.5141, loss: 1.3061 ||:  28%|##7       | 218/784 [00:54<02:19,  4.07it/s]
.run/deps/UAS: 0.7246, .run/deps/LAS: 0.6397, .run/deps/UEM: 0.2539, .run/deps/LEM: 0.1870, .run/.sum: 1.3642, batch_loss: 0.0422, loss: 1.2995 ||:  29%|##8       | 227/784 [00:56<02:16,  4.08it/s]
.run/deps/UAS: 0.7259, .run/deps/LAS: 0.6407, .run/deps/UEM: 0.2583, .run/deps/LEM: 0.1897, .run/.sum: 1.3666, batch_loss: 1.0116, loss: 1.2955 ||:  30%|###       | 236/784 [00:58<02:19,  3.92it/s]
.run/deps/UAS: 0.7264, .run/deps/LAS: 0.6411, .run/deps/UEM: 0.2628, .run/deps/LEM: 0.1937, .run/.sum: 1.3674, batch_loss: 1.3281, loss: 1.2903 ||:  31%|###1      | 245/784 [01:00<02:12,  4.06it/s]
.run/deps/UAS: 0.7276, .run/deps/LAS: 0.6423, .run/deps/UEM: 0.2584, .run/deps/LEM: 0.1905, .run/.sum: 1.3699, batch_loss: 1.5814, loss: 1.2920 ||:  32%|###2      | 254/784 [01:03<02:07,  4.15it/s]
.run/deps/UAS: 0.7267, .run/deps/LAS: 0.6413, .run/deps/UEM: 0.2641, .run/deps/LEM: 0.1928, .run/.sum: 1.3680, batch_loss: 0.8639, loss: 1.2923 ||:  34%|###3      | 263/784 [01:05<02:04,  4.18it/s]
.run/deps/UAS: 0.7260, .run/deps/LAS: 0.6408, .run/deps/UEM: 0.2678, .run/deps/LEM: 0.1979, .run/.sum: 1.3669, batch_loss: 0.3657, loss: 1.2869 ||:  35%|###4      | 272/784 [01:07<02:00,  4.23it/s]
.run/deps/UAS: 0.7266, .run/deps/LAS: 0.6413, .run/deps/UEM: 0.2665, .run/deps/LEM: 0.1966, .run/.sum: 1.3679, batch_loss: 1.1244, loss: 1.2866 ||:  36%|###5      | 282/784 [01:09<01:55,  4.33it/s]
.run/deps/UAS: 0.7259, .run/deps/LAS: 0.6410, .run/deps/UEM: 0.2608, .run/deps/LEM: 0.1921, .run/.sum: 1.3669, batch_loss: 0.7993, loss: 1.2895 ||:  37%|###7      | 291/784 [01:11<01:57,  4.19it/s]
.run/deps/UAS: 0.7263, .run/deps/LAS: 0.6414, .run/deps/UEM: 0.2561, .run/deps/LEM: 0.1877, .run/.sum: 1.3678, batch_loss: 1.9457, loss: 1.2931 ||:  38%|###8      | 300/784 [01:13<01:56,  4.17it/s]
.run/deps/UAS: 0.7265, .run/deps/LAS: 0.6414, .run/deps/UEM: 0.2515, .run/deps/LEM: 0.1843, .run/.sum: 1.3678, batch_loss: 1.6400, loss: 1.2985 ||:  39%|###9      | 309/784 [01:16<01:57,  4.05it/s]
.run/deps/UAS: 0.7269, .run/deps/LAS: 0.6421, .run/deps/UEM: 0.2544, .run/deps/LEM: 0.1877, .run/.sum: 1.3691, batch_loss: 1.5471, loss: 1.2947 ||:  41%|####      | 319/784 [01:18<01:50,  4.22it/s]
.run/deps/UAS: 0.7277, .run/deps/LAS: 0.6431, .run/deps/UEM: 0.2537, .run/deps/LEM: 0.1862, .run/.sum: 1.3707, batch_loss: 1.4511, loss: 1.2951 ||:  42%|####1     | 328/784 [01:20<01:47,  4.25it/s]
.run/deps/UAS: 0.7267, .run/deps/LAS: 0.6422, .run/deps/UEM: 0.2543, .run/deps/LEM: 0.1862, .run/.sum: 1.3688, batch_loss: 1.6638, loss: 1.2953 ||:  43%|####2     | 337/784 [01:23<01:57,  3.80it/s]
.run/deps/UAS: 0.7274, .run/deps/LAS: 0.6428, .run/deps/UEM: 0.2531, .run/deps/LEM: 0.1836, .run/.sum: 1.3702, batch_loss: 1.5127, loss: 1.2945 ||:  44%|####4     | 346/784 [01:25<01:51,  3.93it/s]
.run/deps/UAS: 0.7283, .run/deps/LAS: 0.6435, .run/deps/UEM: 0.2546, .run/deps/LEM: 0.1849, .run/.sum: 1.3717, batch_loss: 0.5551, loss: 1.2916 ||:  45%|####5     | 355/784 [01:27<01:45,  4.07it/s]
.run/deps/UAS: 0.7270, .run/deps/LAS: 0.6420, .run/deps/UEM: 0.2494, .run/deps/LEM: 0.1807, .run/.sum: 1.3690, batch_loss: 1.9360, loss: 1.3000 ||:  46%|####6     | 364/784 [01:30<01:47,  3.90it/s]
.run/deps/UAS: 0.7259, .run/deps/LAS: 0.6409, .run/deps/UEM: 0.2509, .run/deps/LEM: 0.1817, .run/.sum: 1.3668, batch_loss: 1.9271, loss: 1.3027 ||:  48%|####7     | 373/784 [01:32<01:45,  3.89it/s]
.run/deps/UAS: 0.7255, .run/deps/LAS: 0.6407, .run/deps/UEM: 0.2481, .run/deps/LEM: 0.1793, .run/.sum: 1.3662, batch_loss: 1.5479, loss: 1.3069 ||:  49%|####8     | 381/784 [01:34<01:46,  3.79it/s]
.run/deps/UAS: 0.7250, .run/deps/LAS: 0.6402, .run/deps/UEM: 0.2455, .run/deps/LEM: 0.1768, .run/.sum: 1.3652, batch_loss: 1.9084, loss: 1.3106 ||:  50%|####9     | 389/784 [01:36<01:45,  3.74it/s]
.run/deps/UAS: 0.7253, .run/deps/LAS: 0.6406, .run/deps/UEM: 0.2458, .run/deps/LEM: 0.1764, .run/.sum: 1.3659, batch_loss: 0.7505, loss: 1.3070 ||:  51%|#####     | 398/784 [01:38<01:38,  3.92it/s]
.run/deps/UAS: 0.7262, .run/deps/LAS: 0.6417, .run/deps/UEM: 0.2461, .run/deps/LEM: 0.1768, .run/.sum: 1.3679, batch_loss: 1.1334, loss: 1.3048 ||:  52%|#####2    | 408/784 [01:41<01:31,  4.12it/s]
.run/deps/UAS: 0.7271, .run/deps/LAS: 0.6425, .run/deps/UEM: 0.2475, .run/deps/LEM: 0.1783, .run/.sum: 1.3696, batch_loss: 1.3350, loss: 1.3005 ||:  53%|#####3    | 418/784 [01:43<01:26,  4.24it/s]
.run/deps/UAS: 0.7264, .run/deps/LAS: 0.6416, .run/deps/UEM: 0.2456, .run/deps/LEM: 0.1765, .run/.sum: 1.3680, batch_loss: 1.6493, loss: 1.3048 ||:  54%|#####4    | 427/784 [01:46<01:30,  3.95it/s]
.run/deps/UAS: 0.7267, .run/deps/LAS: 0.6419, .run/deps/UEM: 0.2434, .run/deps/LEM: 0.1747, .run/.sum: 1.3686, batch_loss: 1.7762, loss: 1.3071 ||:  55%|#####5    | 435/784 [01:48<01:32,  3.78it/s]
.run/deps/UAS: 0.7264, .run/deps/LAS: 0.6417, .run/deps/UEM: 0.2448, .run/deps/LEM: 0.1758, .run/.sum: 1.3681, batch_loss: 1.9507, loss: 1.3059 ||:  57%|#####6    | 444/784 [01:50<01:26,  3.93it/s]
.run/deps/UAS: 0.7269, .run/deps/LAS: 0.6422, .run/deps/UEM: 0.2459, .run/deps/LEM: 0.1777, .run/.sum: 1.3690, batch_loss: 1.0465, loss: 1.3017 ||:  58%|#####7    | 453/784 [01:52<01:22,  4.03it/s]
.run/deps/UAS: 0.7271, .run/deps/LAS: 0.6426, .run/deps/UEM: 0.2472, .run/deps/LEM: 0.1794, .run/.sum: 1.3697, batch_loss: 0.1891, loss: 1.2992 ||:  59%|#####8    | 462/784 [01:54<01:17,  4.16it/s]
.run/deps/UAS: 0.7269, .run/deps/LAS: 0.6424, .run/deps/UEM: 0.2446, .run/deps/LEM: 0.1769, .run/.sum: 1.3693, batch_loss: 1.1439, loss: 1.3015 ||:  60%|######    | 471/784 [01:56<01:17,  4.04it/s]
.run/deps/UAS: 0.7263, .run/deps/LAS: 0.6419, .run/deps/UEM: 0.2446, .run/deps/LEM: 0.1762, .run/.sum: 1.3682, batch_loss: 1.7684, loss: 1.3052 ||:  61%|######1   | 480/784 [01:59<01:15,  4.02it/s]
.run/deps/UAS: 0.7262, .run/deps/LAS: 0.6416, .run/deps/UEM: 0.2471, .run/deps/LEM: 0.1778, .run/.sum: 1.3678, batch_loss: 1.1417, loss: 1.3049 ||:  62%|######2   | 489/784 [02:01<01:13,  4.04it/s]
.run/deps/UAS: 0.7269, .run/deps/LAS: 0.6424, .run/deps/UEM: 0.2475, .run/deps/LEM: 0.1781, .run/.sum: 1.3693, batch_loss: 1.9919, loss: 1.3054 ||:  64%|######3   | 499/784 [02:03<01:07,  4.23it/s]
.run/deps/UAS: 0.7261, .run/deps/LAS: 0.6419, .run/deps/UEM: 0.2479, .run/deps/LEM: 0.1789, .run/.sum: 1.3680, batch_loss: 1.4866, loss: 1.3060 ||:  65%|######4   | 508/784 [02:06<01:08,  4.03it/s]
.run/deps/UAS: 0.7263, .run/deps/LAS: 0.6419, .run/deps/UEM: 0.2456, .run/deps/LEM: 0.1769, .run/.sum: 1.3682, batch_loss: 1.6243, loss: 1.3090 ||:  66%|######5   | 517/784 [02:08<01:05,  4.05it/s]
.run/deps/UAS: 0.7268, .run/deps/LAS: 0.6425, .run/deps/UEM: 0.2444, .run/deps/LEM: 0.1764, .run/.sum: 1.3693, batch_loss: 1.5221, loss: 1.3071 ||:  67%|######7   | 526/784 [02:10<01:03,  4.04it/s]
.run/deps/UAS: 0.7270, .run/deps/LAS: 0.6426, .run/deps/UEM: 0.2452, .run/deps/LEM: 0.1769, .run/.sum: 1.3697, batch_loss: 1.3384, loss: 1.3051 ||:  68%|######8   | 535/784 [02:13<01:06,  3.77it/s]
.run/deps/UAS: 0.7270, .run/deps/LAS: 0.6427, .run/deps/UEM: 0.2468, .run/deps/LEM: 0.1784, .run/.sum: 1.3696, batch_loss: 0.1143, loss: 1.3027 ||:  69%|######9   | 544/784 [02:15<01:02,  3.87it/s]
.run/deps/UAS: 0.7265, .run/deps/LAS: 0.6422, .run/deps/UEM: 0.2450, .run/deps/LEM: 0.1773, .run/.sum: 1.3688, batch_loss: 1.5554, loss: 1.3045 ||:  70%|#######   | 552/784 [02:17<01:02,  3.72it/s]
.run/deps/UAS: 0.7272, .run/deps/LAS: 0.6429, .run/deps/UEM: 0.2451, .run/deps/LEM: 0.1781, .run/.sum: 1.3700, batch_loss: 0.7725, loss: 1.3014 ||:  72%|#######1  | 561/784 [02:19<00:57,  3.87it/s]
.run/deps/UAS: 0.7277, .run/deps/LAS: 0.6434, .run/deps/UEM: 0.2440, .run/deps/LEM: 0.1767, .run/.sum: 1.3712, batch_loss: 1.3180, loss: 1.3017 ||:  73%|#######2  | 571/784 [02:22<00:52,  4.05it/s]
.run/deps/UAS: 0.7283, .run/deps/LAS: 0.6439, .run/deps/UEM: 0.2443, .run/deps/LEM: 0.1761, .run/.sum: 1.3721, batch_loss: 1.3880, loss: 1.2997 ||:  74%|#######4  | 581/784 [02:24<00:48,  4.16it/s]
.run/deps/UAS: 0.7285, .run/deps/LAS: 0.6442, .run/deps/UEM: 0.2456, .run/deps/LEM: 0.1766, .run/.sum: 1.3727, batch_loss: 1.3432, loss: 1.2971 ||:  75%|#######5  | 590/784 [02:26<00:45,  4.25it/s]
.run/deps/UAS: 0.7285, .run/deps/LAS: 0.6442, .run/deps/UEM: 0.2439, .run/deps/LEM: 0.1749, .run/.sum: 1.3727, batch_loss: 1.4259, loss: 1.2993 ||:  76%|#######6  | 599/784 [02:28<00:46,  4.01it/s]
.run/deps/UAS: 0.7291, .run/deps/LAS: 0.6448, .run/deps/UEM: 0.2443, .run/deps/LEM: 0.1752, .run/.sum: 1.3739, batch_loss: 1.3323, loss: 1.2983 ||:  78%|#######7  | 609/784 [02:31<00:41,  4.18it/s]
.run/deps/UAS: 0.7292, .run/deps/LAS: 0.6449, .run/deps/UEM: 0.2451, .run/deps/LEM: 0.1759, .run/.sum: 1.3740, batch_loss: 1.6583, loss: 1.2978 ||:  79%|#######8  | 618/784 [02:33<00:39,  4.19it/s]
.run/deps/UAS: 0.7294, .run/deps/LAS: 0.6452, .run/deps/UEM: 0.2472, .run/deps/LEM: 0.1772, .run/.sum: 1.3746, batch_loss: 1.7776, loss: 1.2947 ||:  80%|#######9  | 627/784 [02:35<00:37,  4.22it/s]
.run/deps/UAS: 0.7292, .run/deps/LAS: 0.6448, .run/deps/UEM: 0.2460, .run/deps/LEM: 0.1756, .run/.sum: 1.3740, batch_loss: 1.8932, loss: 1.2993 ||:  81%|########1 | 636/784 [02:38<00:39,  3.75it/s]
.run/deps/UAS: 0.7284, .run/deps/LAS: 0.6439, .run/deps/UEM: 0.2461, .run/deps/LEM: 0.1762, .run/.sum: 1.3724, batch_loss: 1.4675, loss: 1.2993 ||:  82%|########2 | 644/784 [02:40<00:38,  3.65it/s]
.run/deps/UAS: 0.7290, .run/deps/LAS: 0.6445, .run/deps/UEM: 0.2461, .run/deps/LEM: 0.1756, .run/.sum: 1.3736, batch_loss: 0.8463, loss: 1.2976 ||:  83%|########3 | 653/784 [02:42<00:34,  3.84it/s]
.run/deps/UAS: 0.7291, .run/deps/LAS: 0.6445, .run/deps/UEM: 0.2463, .run/deps/LEM: 0.1764, .run/.sum: 1.3736, batch_loss: 1.2004, loss: 1.2954 ||:  84%|########4 | 661/784 [02:44<00:31,  3.87it/s]
.run/deps/UAS: 0.7291, .run/deps/LAS: 0.6445, .run/deps/UEM: 0.2455, .run/deps/LEM: 0.1756, .run/.sum: 1.3736, batch_loss: 1.3766, loss: 1.2961 ||:  85%|########5 | 670/784 [02:47<00:28,  3.96it/s]
.run/deps/UAS: 0.7289, .run/deps/LAS: 0.6444, .run/deps/UEM: 0.2451, .run/deps/LEM: 0.1742, .run/.sum: 1.3733, batch_loss: 1.4305, loss: 1.2969 ||:  87%|########6 | 679/784 [02:49<00:26,  3.95it/s]
.run/deps/UAS: 0.7290, .run/deps/LAS: 0.6444, .run/deps/UEM: 0.2458, .run/deps/LEM: 0.1747, .run/.sum: 1.3734, batch_loss: 1.4998, loss: 1.2965 ||:  88%|########7 | 688/784 [02:51<00:23,  4.05it/s]
.run/deps/UAS: 0.7291, .run/deps/LAS: 0.6445, .run/deps/UEM: 0.2458, .run/deps/LEM: 0.1749, .run/.sum: 1.3736, batch_loss: 0.8949, loss: 1.2950 ||:  89%|########8 | 697/784 [02:53<00:21,  4.07it/s]
.run/deps/UAS: 0.7292, .run/deps/LAS: 0.6447, .run/deps/UEM: 0.2498, .run/deps/LEM: 0.1790, .run/.sum: 1.3738, batch_loss: 1.8075, loss: 1.2909 ||:  90%|######### | 707/784 [02:55<00:18,  4.17it/s]
.run/deps/UAS: 0.7295, .run/deps/LAS: 0.6450, .run/deps/UEM: 0.2506, .run/deps/LEM: 0.1793, .run/.sum: 1.3744, batch_loss: 0.6146, loss: 1.2901 ||:  91%|#########1| 716/784 [02:57<00:16,  4.23it/s]
.run/deps/UAS: 0.7297, .run/deps/LAS: 0.6451, .run/deps/UEM: 0.2517, .run/deps/LEM: 0.1804, .run/.sum: 1.3747, batch_loss: 1.3753, loss: 1.2879 ||:  92%|#########2| 725/784 [02:59<00:13,  4.28it/s]
.run/deps/UAS: 0.7301, .run/deps/LAS: 0.6455, .run/deps/UEM: 0.2522, .run/deps/LEM: 0.1807, .run/.sum: 1.3756, batch_loss: 0.9743, loss: 1.2860 ||:  94%|#########3| 734/784 [03:02<00:12,  3.96it/s]
.run/deps/UAS: 0.7301, .run/deps/LAS: 0.6456, .run/deps/UEM: 0.2531, .run/deps/LEM: 0.1812, .run/.sum: 1.3758, batch_loss: 1.5031, loss: 1.2842 ||:  95%|#########4| 744/784 [03:04<00:09,  4.14it/s]
.run/deps/UAS: 0.7295, .run/deps/LAS: 0.6451, .run/deps/UEM: 0.2546, .run/deps/LEM: 0.1814, .run/.sum: 1.3746, batch_loss: 1.1280, loss: 1.2834 ||:  96%|#########6| 753/784 [03:07<00:07,  4.03it/s]
.run/deps/UAS: 0.7300, .run/deps/LAS: 0.6457, .run/deps/UEM: 0.2545, .run/deps/LEM: 0.1810, .run/.sum: 1.3756, batch_loss: 0.8788, loss: 1.2818 ||:  97%|#########7| 762/784 [03:09<00:05,  4.11it/s]
.run/deps/UAS: 0.7303, .run/deps/LAS: 0.6461, .run/deps/UEM: 0.2538, .run/deps/LEM: 0.1801, .run/.sum: 1.3763, batch_loss: 1.1835, loss: 1.2823 ||:  98%|#########8| 771/784 [03:11<00:03,  4.17it/s]
.run/deps/UAS: 0.7304, .run/deps/LAS: 0.6463, .run/deps/UEM: 0.2545, .run/deps/LEM: 0.1809, .run/.sum: 1.3767, batch_loss: 0.7259, loss: 1.2792 ||:  99%|#########9| 780/784 [03:13<00:00,  4.09it/s]
.run/deps/UAS: 0.7305, .run/deps/LAS: 0.6465, .run/deps/UEM: 0.2536, .run/deps/LEM: 0.1801, .run/.sum: 1.3770, batch_loss: 1.3811, loss: 1.2798 ||: 100%|##########| 784/784 [03:14<00:00,  4.03it/s]
2021-05-12 00:33:41,906 - INFO - allennlp.training.trainer - Validating
  0%|          | 0/126 [00:00<?, ?it/s]
.run/deps/UAS: 0.8779, .run/deps/LAS: 0.8365, .run/deps/UEM: 0.5216, .run/deps/LEM: 0.4081, .run/.sum: 1.7144, batch_loss: 0.8367, loss: 0.7360 ||:  19%|#9        | 24/126 [00:02<00:08, 11.36it/s]
.run/deps/UAS: 0.8731, .run/deps/LAS: 0.8319, .run/deps/UEM: 0.4905, .run/deps/LEM: 0.3916, .run/.sum: 1.7050, batch_loss: 0.8030, loss: 0.6958 ||:  37%|###7      | 47/126 [00:04<00:08,  9.29it/s]
.run/deps/UAS: 0.8712, .run/deps/LAS: 0.8302, .run/deps/UEM: 0.5128, .run/deps/LEM: 0.4138, .run/.sum: 1.7014, batch_loss: 0.6536, loss: 0.6679 ||:  55%|#####4    | 69/126 [00:06<00:05,  9.96it/s]
.run/deps/UAS: 0.8746, .run/deps/LAS: 0.8348, .run/deps/UEM: 0.5382, .run/deps/LEM: 0.4389, .run/.sum: 1.7093, batch_loss: 0.5932, loss: 0.6619 ||:  79%|#######8  | 99/126 [00:09<00:02, 11.48it/s]
.run/deps/UAS: 0.8776, .run/deps/LAS: 0.8381, .run/deps/UEM: 0.5529, .run/deps/LEM: 0.4505, .run/.sum: 1.7157, batch_loss: 0.1515, loss: 0.6399 ||: 100%|##########| 126/126 [00:10<00:00, 11.54it/s]
2021-05-12 00:33:52,833 - INFO - allennlp.training.tensorboard_writer -                        Training |  Validation
2021-05-12 00:33:52,833 - INFO - allennlp.training.tensorboard_writer - .run/.sum          |     1.377  |     1.716
2021-05-12 00:33:52,834 - INFO - allennlp.training.tensorboard_writer - .run/deps/LAS      |     0.646  |     0.838
2021-05-12 00:33:52,834 - INFO - allennlp.training.tensorboard_writer - .run/deps/LEM      |     0.180  |     0.451
2021-05-12 00:33:52,834 - INFO - allennlp.training.tensorboard_writer - .run/deps/UAS      |     0.731  |     0.878
2021-05-12 00:33:52,834 - INFO - allennlp.training.tensorboard_writer - .run/deps/UEM      |     0.254  |     0.553
2021-05-12 00:33:52,834 - INFO - allennlp.training.tensorboard_writer - gpu_0_memory_MB    |  5612.324  |       N/A
2021-05-12 00:33:52,835 - INFO - allennlp.training.tensorboard_writer - loss               |     1.280  |     0.640
2021-05-12 00:33:52,835 - INFO - allennlp.training.tensorboard_writer - worker_0_memory_MB |  4223.586  |       N/A
2021-05-12 00:33:52,838 - INFO - udify.optimizers.ulmfit_sqrt - Gradual unfreezing finished. Training all layers.
2021-05-12 00:33:58,553 - INFO - allennlp.training.checkpointer - Best validation performance so far. Copying weights to 'logs/bert_finetune_en/2021.05.12_00.22.24/best.th'.
2021-05-12 00:34:01,052 - INFO - allennlp.training.trainer - Epoch duration: 0:03:36.758961
2021-05-12 00:34:01,053 - INFO - allennlp.training.trainer - Estimated training time remaining: 0:07:18
2021-05-12 00:34:01,053 - INFO - allennlp.training.trainer - Epoch 3/4
2021-05-12 00:34:01,053 - INFO - allennlp.training.trainer - Worker 0 memory usage: 4.1G
2021-05-12 00:34:01,053 - INFO - allennlp.training.trainer - GPU 0 memory usage: 5.5G
2021-05-12 00:34:01,055 - INFO - allennlp.training.trainer - Training
  0%|          | 0/784 [00:00<?, ?it/s]
.run/deps/UAS: 0.8344, .run/deps/LAS: 0.7537, .run/deps/UEM: 0.7411, .run/deps/LEM: 0.6071, .run/.sum: 1.5881, batch_loss: 0.1155, loss: 0.5991 ||:   1%|          | 7/784 [00:02<03:44,  3.46it/s]
.run/deps/UAS: 0.7524, .run/deps/LAS: 0.6642, .run/deps/UEM: 0.4625, .run/deps/LEM: 0.3750, .run/.sum: 1.4166, batch_loss: 1.5425, loss: 0.9510 ||:   2%|1         | 15/784 [00:04<03:28,  3.69it/s]
.run/deps/UAS: 0.7591, .run/deps/LAS: 0.6664, .run/deps/UEM: 0.3950, .run/deps/LEM: 0.2975, .run/.sum: 1.4255, batch_loss: 1.4915, loss: 1.0538 ||:   3%|3         | 25/784 [00:06<03:03,  4.13it/s]
.run/deps/UAS: 0.7528, .run/deps/LAS: 0.6671, .run/deps/UEM: 0.3860, .run/deps/LEM: 0.2923, .run/.sum: 1.4200, batch_loss: 0.8977, loss: 1.0675 ||:   4%|4         | 34/784 [00:08<03:00,  4.16it/s]
.run/deps/UAS: 0.7493, .run/deps/LAS: 0.6623, .run/deps/UEM: 0.3488, .run/deps/LEM: 0.2587, .run/.sum: 1.4115, batch_loss: 1.4793, loss: 1.1019 ||:   5%|5         | 43/784 [00:10<02:57,  4.18it/s]
.run/deps/UAS: 0.7466, .run/deps/LAS: 0.6605, .run/deps/UEM: 0.3041, .run/deps/LEM: 0.2212, .run/.sum: 1.4071, batch_loss: 1.5921, loss: 1.1514 ||:   7%|6         | 52/784 [00:13<03:19,  3.67it/s]
.run/deps/UAS: 0.7533, .run/deps/LAS: 0.6681, .run/deps/UEM: 0.3115, .run/deps/LEM: 0.2275, .run/.sum: 1.4214, batch_loss: 1.0688, loss: 1.1272 ||:   8%|7         | 61/784 [00:15<03:04,  3.91it/s]
.run/deps/UAS: 0.7432, .run/deps/LAS: 0.6573, .run/deps/UEM: 0.2946, .run/deps/LEM: 0.2116, .run/.sum: 1.4005, batch_loss: 1.4076, loss: 1.1542 ||:   9%|8         | 70/784 [00:18<03:08,  3.79it/s]
.run/deps/UAS: 0.7452, .run/deps/LAS: 0.6588, .run/deps/UEM: 0.3000, .run/deps/LEM: 0.2109, .run/.sum: 1.4040, batch_loss: 1.7070, loss: 1.1723 ||:  10%|#         | 80/784 [00:20<02:57,  3.97it/s]
.run/deps/UAS: 0.7460, .run/deps/LAS: 0.6602, .run/deps/UEM: 0.2978, .run/deps/LEM: 0.2128, .run/.sum: 1.4062, batch_loss: 1.2298, loss: 1.1674 ||:  11%|#1        | 89/784 [00:22<02:51,  4.04it/s]
.run/deps/UAS: 0.7473, .run/deps/LAS: 0.6621, .run/deps/UEM: 0.2902, .run/deps/LEM: 0.2085, .run/.sum: 1.4094, batch_loss: 1.2391, loss: 1.1690 ||:  12%|#2        | 98/784 [00:24<02:49,  4.05it/s]
.run/deps/UAS: 0.7495, .run/deps/LAS: 0.6636, .run/deps/UEM: 0.2921, .run/deps/LEM: 0.2103, .run/.sum: 1.4130, batch_loss: 0.6875, loss: 1.1659 ||:  14%|#3        | 107/784 [00:26<02:45,  4.10it/s]
.run/deps/UAS: 0.7462, .run/deps/LAS: 0.6612, .run/deps/UEM: 0.2807, .run/deps/LEM: 0.2031, .run/.sum: 1.4074, batch_loss: 1.0009, loss: 1.1841 ||:  15%|#4        | 116/784 [00:29<02:50,  3.93it/s]
.run/deps/UAS: 0.7496, .run/deps/LAS: 0.6646, .run/deps/UEM: 0.2778, .run/deps/LEM: 0.2034, .run/.sum: 1.4142, batch_loss: 1.2168, loss: 1.1755 ||:  16%|#6        | 126/784 [00:31<02:41,  4.08it/s]
.run/deps/UAS: 0.7494, .run/deps/LAS: 0.6647, .run/deps/UEM: 0.2806, .run/deps/LEM: 0.2051, .run/.sum: 1.4141, batch_loss: 1.1188, loss: 1.1751 ||:  17%|#7        | 135/784 [00:33<02:36,  4.14it/s]
.run/deps/UAS: 0.7475, .run/deps/LAS: 0.6628, .run/deps/UEM: 0.2760, .run/deps/LEM: 0.2023, .run/.sum: 1.4103, batch_loss: 1.2943, loss: 1.1882 ||:  18%|#8        | 144/784 [00:36<02:37,  4.06it/s]
.run/deps/UAS: 0.7482, .run/deps/LAS: 0.6636, .run/deps/UEM: 0.2700, .run/deps/LEM: 0.1969, .run/.sum: 1.4118, batch_loss: 0.9650, loss: 1.1990 ||:  20%|#9        | 153/784 [00:38<02:46,  3.79it/s]
.run/deps/UAS: 0.7481, .run/deps/LAS: 0.6634, .run/deps/UEM: 0.2670, .run/deps/LEM: 0.1910, .run/.sum: 1.4115, batch_loss: 1.1681, loss: 1.2072 ||:  21%|##        | 162/784 [00:40<02:37,  3.95it/s]
.run/deps/UAS: 0.7482, .run/deps/LAS: 0.6634, .run/deps/UEM: 0.2643, .run/deps/LEM: 0.1882, .run/.sum: 1.4116, batch_loss: 1.5198, loss: 1.2099 ||:  22%|##1       | 171/784 [00:42<02:30,  4.09it/s]
.run/deps/UAS: 0.7462, .run/deps/LAS: 0.6617, .run/deps/UEM: 0.2594, .run/deps/LEM: 0.1837, .run/.sum: 1.4080, batch_loss: 1.0499, loss: 1.2189 ||:  23%|##2       | 180/784 [00:45<02:27,  4.09it/s]
.run/deps/UAS: 0.7444, .run/deps/LAS: 0.6597, .run/deps/UEM: 0.2546, .run/deps/LEM: 0.1782, .run/.sum: 1.4040, batch_loss: 1.4334, loss: 1.2274 ||:  24%|##4       | 189/784 [00:47<02:29,  3.98it/s]
.run/deps/UAS: 0.7436, .run/deps/LAS: 0.6594, .run/deps/UEM: 0.2472, .run/deps/LEM: 0.1714, .run/.sum: 1.4030, batch_loss: 1.2801, loss: 1.2321 ||:  25%|##5       | 198/784 [00:49<02:28,  3.95it/s]
.run/deps/UAS: 0.7436, .run/deps/LAS: 0.6594, .run/deps/UEM: 0.2409, .run/deps/LEM: 0.1660, .run/.sum: 1.4029, batch_loss: 1.4512, loss: 1.2375 ||:  26%|##6       | 206/784 [00:51<02:28,  3.88it/s]
.run/deps/UAS: 0.7446, .run/deps/LAS: 0.6605, .run/deps/UEM: 0.2459, .run/deps/LEM: 0.1703, .run/.sum: 1.4051, batch_loss: 1.1737, loss: 1.2341 ||:  27%|##7       | 215/784 [00:53<02:20,  4.04it/s]
.run/deps/UAS: 0.7460, .run/deps/LAS: 0.6617, .run/deps/UEM: 0.2450, .run/deps/LEM: 0.1702, .run/.sum: 1.4077, batch_loss: 1.1958, loss: 1.2304 ||:  29%|##8       | 224/784 [00:56<02:18,  4.04it/s]
.run/deps/UAS: 0.7463, .run/deps/LAS: 0.6619, .run/deps/UEM: 0.2497, .run/deps/LEM: 0.1738, .run/.sum: 1.4081, batch_loss: 1.4022, loss: 1.2208 ||:  30%|##9       | 233/784 [00:58<02:14,  4.09it/s]
.run/deps/UAS: 0.7469, .run/deps/LAS: 0.6632, .run/deps/UEM: 0.2503, .run/deps/LEM: 0.1741, .run/.sum: 1.4100, batch_loss: 1.5531, loss: 1.2164 ||:  31%|###       | 242/784 [01:00<02:11,  4.12it/s]
.run/deps/UAS: 0.7472, .run/deps/LAS: 0.6635, .run/deps/UEM: 0.2565, .run/deps/LEM: 0.1790, .run/.sum: 1.4107, batch_loss: 1.1642, loss: 1.2191 ||:  32%|###2      | 251/784 [01:03<02:16,  3.91it/s]
.run/deps/UAS: 0.7466, .run/deps/LAS: 0.6630, .run/deps/UEM: 0.2577, .run/deps/LEM: 0.1805, .run/.sum: 1.4096, batch_loss: 1.5897, loss: 1.2222 ||:  33%|###3      | 259/784 [01:05<02:16,  3.85it/s]
.run/deps/UAS: 0.7470, .run/deps/LAS: 0.6633, .run/deps/UEM: 0.2535, .run/deps/LEM: 0.1754, .run/.sum: 1.4103, batch_loss: 1.2025, loss: 1.2256 ||:  34%|###4      | 269/784 [01:07<02:06,  4.06it/s]
.run/deps/UAS: 0.7482, .run/deps/LAS: 0.6643, .run/deps/UEM: 0.2612, .run/deps/LEM: 0.1821, .run/.sum: 1.4125, batch_loss: 1.1689, loss: 1.2151 ||:  36%|###5      | 279/784 [01:09<01:59,  4.21it/s]
.run/deps/UAS: 0.7469, .run/deps/LAS: 0.6633, .run/deps/UEM: 0.2602, .run/deps/LEM: 0.1832, .run/.sum: 1.4102, batch_loss: 1.3289, loss: 1.2128 ||:  37%|###6      | 288/784 [01:11<02:02,  4.05it/s]
.run/deps/UAS: 0.7478, .run/deps/LAS: 0.6645, .run/deps/UEM: 0.2605, .run/deps/LEM: 0.1844, .run/.sum: 1.4123, batch_loss: 0.9058, loss: 1.2070 ||:  38%|###8      | 298/784 [01:14<01:55,  4.21it/s]
.run/deps/UAS: 0.7469, .run/deps/LAS: 0.6639, .run/deps/UEM: 0.2567, .run/deps/LEM: 0.1816, .run/.sum: 1.4108, batch_loss: 1.6560, loss: 1.2118 ||:  39%|###9      | 307/784 [01:16<01:57,  4.05it/s]
.run/deps/UAS: 0.7467, .run/deps/LAS: 0.6637, .run/deps/UEM: 0.2581, .run/deps/LEM: 0.1820, .run/.sum: 1.4104, batch_loss: 1.2447, loss: 1.2098 ||:  40%|####      | 316/784 [01:18<01:54,  4.09it/s]
.run/deps/UAS: 0.7467, .run/deps/LAS: 0.6639, .run/deps/UEM: 0.2563, .run/deps/LEM: 0.1796, .run/.sum: 1.4106, batch_loss: 1.2095, loss: 1.2103 ||:  41%|####1     | 325/784 [01:20<01:52,  4.08it/s]
.run/deps/UAS: 0.7463, .run/deps/LAS: 0.6631, .run/deps/UEM: 0.2564, .run/deps/LEM: 0.1795, .run/.sum: 1.4094, batch_loss: 1.9793, loss: 1.2153 ||:  43%|####2     | 334/784 [01:23<01:49,  4.12it/s]
.run/deps/UAS: 0.7463, .run/deps/LAS: 0.6631, .run/deps/UEM: 0.2555, .run/deps/LEM: 0.1786, .run/.sum: 1.4094, batch_loss: 1.6412, loss: 1.2174 ||:  44%|####3     | 343/784 [01:25<01:46,  4.14it/s]
.run/deps/UAS: 0.7448, .run/deps/LAS: 0.6617, .run/deps/UEM: 0.2520, .run/deps/LEM: 0.1761, .run/.sum: 1.4066, batch_loss: 0.9699, loss: 1.2219 ||:  45%|####4     | 352/784 [01:28<01:57,  3.67it/s]
.run/deps/UAS: 0.7452, .run/deps/LAS: 0.6622, .run/deps/UEM: 0.2524, .run/deps/LEM: 0.1761, .run/.sum: 1.4074, batch_loss: 0.9810, loss: 1.2220 ||:  46%|####6     | 362/784 [01:30<01:47,  3.92it/s]
.run/deps/UAS: 0.7446, .run/deps/LAS: 0.6616, .run/deps/UEM: 0.2552, .run/deps/LEM: 0.1781, .run/.sum: 1.4062, batch_loss: 1.3034, loss: 1.2229 ||:  47%|####7     | 371/784 [01:32<01:42,  4.01it/s]
.run/deps/UAS: 0.7450, .run/deps/LAS: 0.6622, .run/deps/UEM: 0.2579, .run/deps/LEM: 0.1806, .run/.sum: 1.4072, batch_loss: 1.0717, loss: 1.2180 ||:  48%|####8     | 380/784 [01:34<01:38,  4.11it/s]
.run/deps/UAS: 0.7453, .run/deps/LAS: 0.6625, .run/deps/UEM: 0.2583, .run/deps/LEM: 0.1808, .run/.sum: 1.4078, batch_loss: 1.4270, loss: 1.2183 ||:  50%|####9     | 390/784 [01:36<01:32,  4.25it/s]
.run/deps/UAS: 0.7458, .run/deps/LAS: 0.6631, .run/deps/UEM: 0.2605, .run/deps/LEM: 0.1833, .run/.sum: 1.4089, batch_loss: 0.2052, loss: 1.2132 ||:  51%|#####1    | 400/784 [01:39<01:28,  4.36it/s]
.run/deps/UAS: 0.7455, .run/deps/LAS: 0.6630, .run/deps/UEM: 0.2627, .run/deps/LEM: 0.1857, .run/.sum: 1.4085, batch_loss: 0.8294, loss: 1.2117 ||:  52%|#####2    | 409/784 [01:41<01:27,  4.29it/s]
.run/deps/UAS: 0.7463, .run/deps/LAS: 0.6639, .run/deps/UEM: 0.2660, .run/deps/LEM: 0.1878, .run/.sum: 1.4101, batch_loss: 1.1655, loss: 1.2076 ||:  53%|#####3    | 419/784 [01:43<01:22,  4.43it/s]
.run/deps/UAS: 0.7466, .run/deps/LAS: 0.6642, .run/deps/UEM: 0.2650, .run/deps/LEM: 0.1875, .run/.sum: 1.4108, batch_loss: 0.3124, loss: 1.2068 ||:  55%|#####4    | 428/784 [01:45<01:22,  4.33it/s]
.run/deps/UAS: 0.7462, .run/deps/LAS: 0.6638, .run/deps/UEM: 0.2693, .run/deps/LEM: 0.1924, .run/.sum: 1.4099, batch_loss: 1.4636, loss: 1.2016 ||:  56%|#####5    | 437/784 [01:47<01:21,  4.24it/s]
.run/deps/UAS: 0.7458, .run/deps/LAS: 0.6633, .run/deps/UEM: 0.2656, .run/deps/LEM: 0.1892, .run/.sum: 1.4091, batch_loss: 0.9965, loss: 1.2045 ||:  57%|#####6    | 446/784 [01:49<01:20,  4.18it/s]
.run/deps/UAS: 0.7461, .run/deps/LAS: 0.6637, .run/deps/UEM: 0.2659, .run/deps/LEM: 0.1890, .run/.sum: 1.4097, batch_loss: 1.3903, loss: 1.2051 ||:  58%|#####8    | 455/784 [01:52<01:22,  3.97it/s]
.run/deps/UAS: 0.7459, .run/deps/LAS: 0.6636, .run/deps/UEM: 0.2700, .run/deps/LEM: 0.1932, .run/.sum: 1.4095, batch_loss: 1.2700, loss: 1.1988 ||:  59%|#####9    | 463/784 [01:54<01:21,  3.96it/s]
.run/deps/UAS: 0.7466, .run/deps/LAS: 0.6641, .run/deps/UEM: 0.2683, .run/deps/LEM: 0.1917, .run/.sum: 1.4108, batch_loss: 1.0661, loss: 1.2008 ||:  60%|######    | 472/784 [01:56<01:16,  4.06it/s]
.run/deps/UAS: 0.7466, .run/deps/LAS: 0.6640, .run/deps/UEM: 0.2705, .run/deps/LEM: 0.1950, .run/.sum: 1.4106, batch_loss: 0.0002, loss: 1.1958 ||:  61%|######1   | 481/784 [01:58<01:15,  4.04it/s]
.run/deps/UAS: 0.7464, .run/deps/LAS: 0.6638, .run/deps/UEM: 0.2687, .run/deps/LEM: 0.1941, .run/.sum: 1.4102, batch_loss: 0.0004, loss: 1.1963 ||:  62%|######2   | 490/784 [02:01<01:13,  4.00it/s]
.run/deps/UAS: 0.7465, .run/deps/LAS: 0.6640, .run/deps/UEM: 0.2685, .run/deps/LEM: 0.1943, .run/.sum: 1.4105, batch_loss: 0.7232, loss: 1.1946 ||:  64%|######3   | 499/784 [02:03<01:09,  4.08it/s]
.run/deps/UAS: 0.7463, .run/deps/LAS: 0.6638, .run/deps/UEM: 0.2689, .run/deps/LEM: 0.1953, .run/.sum: 1.4101, batch_loss: 0.9396, loss: 1.1947 ||:  65%|######4   | 508/784 [02:05<01:07,  4.06it/s]
.run/deps/UAS: 0.7459, .run/deps/LAS: 0.6636, .run/deps/UEM: 0.2710, .run/deps/LEM: 0.1961, .run/.sum: 1.4095, batch_loss: 1.8376, loss: 1.1930 ||:  66%|######5   | 517/784 [02:07<01:05,  4.11it/s]
.run/deps/UAS: 0.7459, .run/deps/LAS: 0.6634, .run/deps/UEM: 0.2704, .run/deps/LEM: 0.1956, .run/.sum: 1.4093, batch_loss: 1.7375, loss: 1.1944 ||:  67%|######7   | 526/784 [02:10<01:03,  4.04it/s]
.run/deps/UAS: 0.7459, .run/deps/LAS: 0.6636, .run/deps/UEM: 0.2734, .run/deps/LEM: 0.1991, .run/.sum: 1.4095, batch_loss: 1.5173, loss: 1.1899 ||:  68%|######8   | 535/784 [02:12<01:00,  4.15it/s]
.run/deps/UAS: 0.7454, .run/deps/LAS: 0.6630, .run/deps/UEM: 0.2734, .run/deps/LEM: 0.1988, .run/.sum: 1.4084, batch_loss: 1.1465, loss: 1.1927 ||:  69%|######9   | 544/784 [02:14<00:58,  4.13it/s]
.run/deps/UAS: 0.7455, .run/deps/LAS: 0.6631, .run/deps/UEM: 0.2731, .run/deps/LEM: 0.1986, .run/.sum: 1.4087, batch_loss: 1.3812, loss: 1.1941 ||:  71%|#######   | 553/784 [02:16<01:00,  3.85it/s]
.run/deps/UAS: 0.7452, .run/deps/LAS: 0.6630, .run/deps/UEM: 0.2727, .run/deps/LEM: 0.1981, .run/.sum: 1.4082, batch_loss: 1.5489, loss: 1.1961 ||:  72%|#######1  | 561/784 [02:19<00:57,  3.86it/s]
.run/deps/UAS: 0.7454, .run/deps/LAS: 0.6631, .run/deps/UEM: 0.2745, .run/deps/LEM: 0.1996, .run/.sum: 1.4085, batch_loss: 1.1286, loss: 1.1935 ||:  73%|#######2  | 570/784 [02:21<00:53,  3.97it/s]
.run/deps/UAS: 0.7451, .run/deps/LAS: 0.6627, .run/deps/UEM: 0.2747, .run/deps/LEM: 0.1998, .run/.sum: 1.4078, batch_loss: 1.3984, loss: 1.1935 ||:  74%|#######3  | 579/784 [02:23<00:52,  3.94it/s]
.run/deps/UAS: 0.7456, .run/deps/LAS: 0.6634, .run/deps/UEM: 0.2740, .run/deps/LEM: 0.1996, .run/.sum: 1.4090, batch_loss: 0.8597, loss: 1.1931 ||:  75%|#######5  | 588/784 [02:25<00:48,  4.07it/s]
.run/deps/UAS: 0.7456, .run/deps/LAS: 0.6632, .run/deps/UEM: 0.2740, .run/deps/LEM: 0.1997, .run/.sum: 1.4088, batch_loss: 1.7602, loss: 1.1943 ||:  76%|#######6  | 597/784 [02:27<00:46,  3.98it/s]
.run/deps/UAS: 0.7459, .run/deps/LAS: 0.6636, .run/deps/UEM: 0.2736, .run/deps/LEM: 0.1994, .run/.sum: 1.4096, batch_loss: 1.0546, loss: 1.1917 ||:  77%|#######7  | 606/784 [02:30<00:44,  4.04it/s]
.run/deps/UAS: 0.7459, .run/deps/LAS: 0.6635, .run/deps/UEM: 0.2729, .run/deps/LEM: 0.1986, .run/.sum: 1.4094, batch_loss: 1.3131, loss: 1.1927 ||:  78%|#######8  | 615/784 [02:32<00:41,  4.05it/s]
.run/deps/UAS: 0.7458, .run/deps/LAS: 0.6634, .run/deps/UEM: 0.2718, .run/deps/LEM: 0.1980, .run/.sum: 1.4092, batch_loss: 1.7482, loss: 1.1940 ||:  80%|#######9  | 624/784 [02:34<00:39,  4.06it/s]
.run/deps/UAS: 0.7461, .run/deps/LAS: 0.6637, .run/deps/UEM: 0.2733, .run/deps/LEM: 0.1990, .run/.sum: 1.4098, batch_loss: 0.9370, loss: 1.1922 ||:  81%|########  | 633/784 [02:36<00:36,  4.18it/s]
.run/deps/UAS: 0.7459, .run/deps/LAS: 0.6635, .run/deps/UEM: 0.2725, .run/deps/LEM: 0.1988, .run/.sum: 1.4094, batch_loss: 1.7051, loss: 1.1932 ||:  82%|########1 | 642/784 [02:38<00:35,  4.05it/s]
.run/deps/UAS: 0.7460, .run/deps/LAS: 0.6634, .run/deps/UEM: 0.2731, .run/deps/LEM: 0.1998, .run/.sum: 1.4093, batch_loss: 0.8837, loss: 1.1914 ||:  83%|########3 | 651/784 [02:41<00:36,  3.66it/s]
.run/deps/UAS: 0.7460, .run/deps/LAS: 0.6634, .run/deps/UEM: 0.2747, .run/deps/LEM: 0.2005, .run/.sum: 1.4094, batch_loss: 1.2007, loss: 1.1905 ||:  84%|########4 | 660/784 [02:43<00:32,  3.80it/s]
.run/deps/UAS: 0.7466, .run/deps/LAS: 0.6641, .run/deps/UEM: 0.2761, .run/deps/LEM: 0.2010, .run/.sum: 1.4107, batch_loss: 1.0472, loss: 1.1872 ||:  85%|########5 | 669/784 [02:46<00:28,  3.97it/s]
.run/deps/UAS: 0.7472, .run/deps/LAS: 0.6647, .run/deps/UEM: 0.2778, .run/deps/LEM: 0.2024, .run/.sum: 1.4119, batch_loss: 1.4274, loss: 1.1860 ||:  87%|########6 | 679/784 [02:48<00:25,  4.09it/s]
.run/deps/UAS: 0.7474, .run/deps/LAS: 0.6650, .run/deps/UEM: 0.2774, .run/deps/LEM: 0.2014, .run/.sum: 1.4124, batch_loss: 1.3033, loss: 1.1882 ||:  88%|########7 | 689/784 [02:50<00:22,  4.26it/s]
.run/deps/UAS: 0.7476, .run/deps/LAS: 0.6652, .run/deps/UEM: 0.2751, .run/deps/LEM: 0.1991, .run/.sum: 1.4129, batch_loss: 1.3561, loss: 1.1899 ||:  89%|########9 | 698/784 [02:52<00:20,  4.18it/s]
.run/deps/UAS: 0.7461, .run/deps/LAS: 0.6636, .run/deps/UEM: 0.2742, .run/deps/LEM: 0.1984, .run/.sum: 1.4098, batch_loss: 1.3955, loss: 1.1904 ||:  90%|######### | 707/784 [02:55<00:20,  3.83it/s]
.run/deps/UAS: 0.7460, .run/deps/LAS: 0.6637, .run/deps/UEM: 0.2724, .run/deps/LEM: 0.1965, .run/.sum: 1.4097, batch_loss: 1.6392, loss: 1.1910 ||:  91%|#########1| 716/784 [02:57<00:17,  3.81it/s]
.run/deps/UAS: 0.7461, .run/deps/LAS: 0.6635, .run/deps/UEM: 0.2724, .run/deps/LEM: 0.1960, .run/.sum: 1.4096, batch_loss: 0.7215, loss: 1.1922 ||:  92%|#########2| 724/784 [02:59<00:15,  3.85it/s]
.run/deps/UAS: 0.7463, .run/deps/LAS: 0.6637, .run/deps/UEM: 0.2728, .run/deps/LEM: 0.1963, .run/.sum: 1.4099, batch_loss: 1.2827, loss: 1.1918 ||:  93%|#########3| 733/784 [03:01<00:12,  3.99it/s]
.run/deps/UAS: 0.7465, .run/deps/LAS: 0.6639, .run/deps/UEM: 0.2721, .run/deps/LEM: 0.1957, .run/.sum: 1.4104, batch_loss: 1.0555, loss: 1.1927 ||:  95%|#########4| 742/784 [03:04<00:10,  4.09it/s]
.run/deps/UAS: 0.7465, .run/deps/LAS: 0.6639, .run/deps/UEM: 0.2717, .run/deps/LEM: 0.1948, .run/.sum: 1.4104, batch_loss: 0.8390, loss: 1.1926 ||:  96%|#########5| 751/784 [03:07<00:09,  3.66it/s]
.run/deps/UAS: 0.7467, .run/deps/LAS: 0.6641, .run/deps/UEM: 0.2703, .run/deps/LEM: 0.1936, .run/.sum: 1.4108, batch_loss: 1.1892, loss: 1.1936 ||:  97%|#########6| 760/784 [03:09<00:06,  3.79it/s]
.run/deps/UAS: 0.7468, .run/deps/LAS: 0.6640, .run/deps/UEM: 0.2699, .run/deps/LEM: 0.1934, .run/.sum: 1.4108, batch_loss: 1.6725, loss: 1.1939 ||:  98%|#########8| 769/784 [03:11<00:03,  3.87it/s]
.run/deps/UAS: 0.7459, .run/deps/LAS: 0.6632, .run/deps/UEM: 0.2683, .run/deps/LEM: 0.1917, .run/.sum: 1.4091, batch_loss: 1.1511, loss: 1.1963 ||:  99%|#########9| 777/784 [03:13<00:01,  3.71it/s]
.run/deps/UAS: 0.7460, .run/deps/LAS: 0.6634, .run/deps/UEM: 0.2693, .run/deps/LEM: 0.1923, .run/.sum: 1.4094, batch_loss: 1.5630, loss: 1.1957 ||: 100%|##########| 784/784 [03:15<00:00,  4.01it/s]
2021-05-12 00:37:19,357 - INFO - allennlp.training.trainer - Validating
  0%|          | 0/126 [00:00<?, ?it/s]
.run/deps/UAS: 0.8805, .run/deps/LAS: 0.8488, .run/deps/UEM: 0.4549, .run/deps/LEM: 0.3576, .run/.sum: 1.7292, batch_loss: 0.1815, loss: 0.6511 ||:  14%|#4        | 18/126 [00:02<00:12,  8.97it/s]
.run/deps/UAS: 0.8871, .run/deps/LAS: 0.8506, .run/deps/UEM: 0.4924, .run/deps/LEM: 0.3754, .run/.sum: 1.7377, batch_loss: 0.4375, loss: 0.6507 ||:  33%|###3      | 42/126 [00:04<00:08, 10.48it/s]
.run/deps/UAS: 0.8834, .run/deps/LAS: 0.8448, .run/deps/UEM: 0.5201, .run/deps/LEM: 0.4064, .run/.sum: 1.7283, batch_loss: 0.8634, loss: 0.6441 ||:  50%|#####     | 63/126 [00:06<00:06,  9.87it/s]
.run/deps/UAS: 0.8821, .run/deps/LAS: 0.8436, .run/deps/UEM: 0.5367, .run/deps/LEM: 0.4236, .run/.sum: 1.7256, batch_loss: 0.7915, loss: 0.6348 ||:  68%|######8   | 86/126 [00:08<00:04,  9.92it/s]
.run/deps/UAS: 0.8836, .run/deps/LAS: 0.8459, .run/deps/UEM: 0.5540, .run/deps/LEM: 0.4443, .run/.sum: 1.7295, batch_loss: 0.5470, loss: 0.6039 ||:  89%|########8 | 112/126 [00:10<00:01, 10.88it/s]
.run/deps/UAS: 0.8854, .run/deps/LAS: 0.8481, .run/deps/UEM: 0.5644, .run/deps/LEM: 0.4565, .run/.sum: 1.7335, batch_loss: 0.2525, loss: 0.5882 ||: 100%|##########| 126/126 [00:11<00:00, 10.66it/s]
2021-05-12 00:37:31,179 - INFO - allennlp.training.tensorboard_writer -                        Training |  Validation
2021-05-12 00:37:31,179 - INFO - allennlp.training.tensorboard_writer - .run/.sum          |     1.409  |     1.733
2021-05-12 00:37:31,179 - INFO - allennlp.training.tensorboard_writer - .run/deps/LAS      |     0.663  |     0.848
2021-05-12 00:37:31,180 - INFO - allennlp.training.tensorboard_writer - .run/deps/LEM      |     0.192  |     0.457
2021-05-12 00:37:31,180 - INFO - allennlp.training.tensorboard_writer - .run/deps/UAS      |     0.746  |     0.885
2021-05-12 00:37:31,181 - INFO - allennlp.training.tensorboard_writer - .run/deps/UEM      |     0.269  |     0.564
2021-05-12 00:37:31,183 - INFO - allennlp.training.tensorboard_writer - gpu_0_memory_MB    |  5612.324  |       N/A
2021-05-12 00:37:31,184 - INFO - allennlp.training.tensorboard_writer - loss               |     1.196  |     0.588
2021-05-12 00:37:31,185 - INFO - allennlp.training.tensorboard_writer - worker_0_memory_MB |  4224.789  |       N/A
2021-05-12 00:37:31,189 - INFO - udify.optimizers.ulmfit_sqrt - Gradual unfreezing finished. Training all layers.
2021-05-12 00:37:36,625 - INFO - allennlp.training.checkpointer - Best validation performance so far. Copying weights to 'logs/bert_finetune_en/2021.05.12_00.22.24/best.th'.
2021-05-12 00:37:38,576 - INFO - allennlp.training.trainer - Epoch duration: 0:03:37.523310
2021-05-12 00:37:38,576 - INFO - allennlp.training.trainer - Estimated training time remaining: 0:03:38
2021-05-12 00:37:38,577 - INFO - allennlp.training.trainer - Epoch 4/4
2021-05-12 00:37:38,577 - INFO - allennlp.training.trainer - Worker 0 memory usage: 4.1G
2021-05-12 00:37:38,577 - INFO - allennlp.training.trainer - GPU 0 memory usage: 5.5G
2021-05-12 00:37:38,579 - INFO - allennlp.training.trainer - Training
  0%|          | 0/784 [00:00<?, ?it/s]
.run/deps/UAS: 0.7583, .run/deps/LAS: 0.6726, .run/deps/UEM: 0.2778, .run/deps/LEM: 0.1806, .run/.sum: 1.4308, batch_loss: 1.1541, loss: 1.1904 ||:   1%|1         | 9/784 [00:02<03:09,  4.09it/s]
.run/deps/UAS: 0.7550, .run/deps/LAS: 0.6725, .run/deps/UEM: 0.2326, .run/deps/LEM: 0.1528, .run/.sum: 1.4274, batch_loss: 1.3381, loss: 1.2291 ||:   2%|2         | 18/784 [00:04<03:07,  4.08it/s]
.run/deps/UAS: 0.7634, .run/deps/LAS: 0.6856, .run/deps/UEM: 0.2315, .run/deps/LEM: 0.1528, .run/.sum: 1.4489, batch_loss: 0.7751, loss: 1.1846 ||:   3%|3         | 27/784 [00:06<03:00,  4.18it/s]
.run/deps/UAS: 0.7479, .run/deps/LAS: 0.6688, .run/deps/UEM: 0.2552, .run/deps/LEM: 0.1823, .run/.sum: 1.4166, batch_loss: 1.3739, loss: 1.1810 ||:   5%|4         | 36/784 [00:09<03:10,  3.93it/s]
.run/deps/UAS: 0.7414, .run/deps/LAS: 0.6633, .run/deps/UEM: 0.2571, .run/deps/LEM: 0.1847, .run/.sum: 1.4046, batch_loss: 1.9503, loss: 1.1904 ||:   6%|5         | 44/784 [00:11<03:12,  3.84it/s]
.run/deps/UAS: 0.7467, .run/deps/LAS: 0.6672, .run/deps/UEM: 0.2975, .run/deps/LEM: 0.2245, .run/.sum: 1.4139, batch_loss: 0.9981, loss: 1.1433 ||:   7%|6         | 54/784 [00:13<02:54,  4.18it/s]
.run/deps/UAS: 0.7475, .run/deps/LAS: 0.6666, .run/deps/UEM: 0.2768, .run/deps/LEM: 0.2034, .run/.sum: 1.4141, batch_loss: 1.3575, loss: 1.1588 ||:   8%|8         | 63/784 [00:15<02:57,  4.06it/s]
.run/deps/UAS: 0.7524, .run/deps/LAS: 0.6717, .run/deps/UEM: 0.2925, .run/deps/LEM: 0.2214, .run/.sum: 1.4241, batch_loss: 1.0928, loss: 1.1323 ||:   9%|9         | 72/784 [00:18<03:04,  3.86it/s]
.run/deps/UAS: 0.7542, .run/deps/LAS: 0.6754, .run/deps/UEM: 0.3079, .run/deps/LEM: 0.2361, .run/.sum: 1.4295, batch_loss: 1.3040, loss: 1.1182 ||:  10%|#         | 81/784 [00:20<02:56,  3.99it/s]
.run/deps/UAS: 0.7561, .run/deps/LAS: 0.6783, .run/deps/UEM: 0.3014, .run/deps/LEM: 0.2326, .run/.sum: 1.4343, batch_loss: 1.2731, loss: 1.1145 ||:  11%|#1        | 90/784 [00:22<02:51,  4.05it/s]
.run/deps/UAS: 0.7538, .run/deps/LAS: 0.6760, .run/deps/UEM: 0.2967, .run/deps/LEM: 0.2304, .run/.sum: 1.4298, batch_loss: 1.0819, loss: 1.1147 ||:  13%|#2        | 99/784 [00:24<02:51,  3.98it/s]
.run/deps/UAS: 0.7561, .run/deps/LAS: 0.6782, .run/deps/UEM: 0.2975, .run/deps/LEM: 0.2274, .run/.sum: 1.4343, batch_loss: 1.2916, loss: 1.1123 ||:  14%|#3        | 108/784 [00:26<02:43,  4.13it/s]
.run/deps/UAS: 0.7564, .run/deps/LAS: 0.6772, .run/deps/UEM: 0.2986, .run/deps/LEM: 0.2276, .run/.sum: 1.4336, batch_loss: 0.0002, loss: 1.1079 ||:  15%|#4        | 117/784 [00:28<02:40,  4.14it/s]
.run/deps/UAS: 0.7578, .run/deps/LAS: 0.6780, .run/deps/UEM: 0.2882, .run/deps/LEM: 0.2178, .run/.sum: 1.4359, batch_loss: 1.8402, loss: 1.1188 ||:  16%|#6        | 126/784 [00:30<02:36,  4.20it/s]
.run/deps/UAS: 0.7602, .run/deps/LAS: 0.6799, .run/deps/UEM: 0.2854, .run/deps/LEM: 0.2160, .run/.sum: 1.4400, batch_loss: 1.4269, loss: 1.1200 ||:  17%|#7        | 136/784 [00:33<02:32,  4.24it/s]
.run/deps/UAS: 0.7591, .run/deps/LAS: 0.6786, .run/deps/UEM: 0.2858, .run/deps/LEM: 0.2151, .run/.sum: 1.4377, batch_loss: 1.2191, loss: 1.1251 ||:  18%|#8        | 145/784 [00:35<02:33,  4.17it/s]
.run/deps/UAS: 0.7569, .run/deps/LAS: 0.6760, .run/deps/UEM: 0.2800, .run/deps/LEM: 0.2086, .run/.sum: 1.4329, batch_loss: 1.4937, loss: 1.1314 ||:  20%|#9        | 154/784 [00:37<02:37,  4.00it/s]
.run/deps/UAS: 0.7568, .run/deps/LAS: 0.6759, .run/deps/UEM: 0.2761, .run/deps/LEM: 0.2040, .run/.sum: 1.4328, batch_loss: 1.5417, loss: 1.1341 ||:  21%|##        | 163/784 [00:40<02:33,  4.04it/s]
.run/deps/UAS: 0.7570, .run/deps/LAS: 0.6768, .run/deps/UEM: 0.2812, .run/deps/LEM: 0.2108, .run/.sum: 1.4338, batch_loss: 0.7920, loss: 1.1216 ||:  22%|##1       | 172/784 [00:42<02:43,  3.74it/s]
.run/deps/UAS: 0.7568, .run/deps/LAS: 0.6768, .run/deps/UEM: 0.2729, .run/deps/LEM: 0.2035, .run/.sum: 1.4336, batch_loss: 1.1979, loss: 1.1305 ||:  23%|##2       | 180/784 [00:45<02:42,  3.71it/s]
.run/deps/UAS: 0.7574, .run/deps/LAS: 0.6773, .run/deps/UEM: 0.2718, .run/deps/LEM: 0.2021, .run/.sum: 1.4346, batch_loss: 1.2253, loss: 1.1357 ||:  24%|##4       | 189/784 [00:47<02:33,  3.87it/s]
.run/deps/UAS: 0.7574, .run/deps/LAS: 0.6771, .run/deps/UEM: 0.2682, .run/deps/LEM: 0.1972, .run/.sum: 1.4345, batch_loss: 1.6303, loss: 1.1427 ||:  25%|##5       | 199/784 [00:49<02:24,  4.05it/s]
.run/deps/UAS: 0.7575, .run/deps/LAS: 0.6773, .run/deps/UEM: 0.2665, .run/deps/LEM: 0.1968, .run/.sum: 1.4348, batch_loss: 1.5438, loss: 1.1444 ||:  27%|##6       | 208/784 [00:51<02:21,  4.07it/s]
.run/deps/UAS: 0.7573, .run/deps/LAS: 0.6772, .run/deps/UEM: 0.2647, .run/deps/LEM: 0.1947, .run/.sum: 1.4345, batch_loss: 0.8147, loss: 1.1507 ||:  28%|##7       | 217/784 [00:53<02:16,  4.15it/s]
.run/deps/UAS: 0.7573, .run/deps/LAS: 0.6770, .run/deps/UEM: 0.2666, .run/deps/LEM: 0.1972, .run/.sum: 1.4343, batch_loss: 1.4075, loss: 1.1480 ||:  29%|##8       | 226/784 [00:55<02:13,  4.18it/s]
.run/deps/UAS: 0.7570, .run/deps/LAS: 0.6765, .run/deps/UEM: 0.2726, .run/deps/LEM: 0.2021, .run/.sum: 1.4336, batch_loss: 1.3514, loss: 1.1461 ||:  30%|##9       | 235/784 [00:57<02:09,  4.23it/s]
.run/deps/UAS: 0.7578, .run/deps/LAS: 0.6775, .run/deps/UEM: 0.2732, .run/deps/LEM: 0.2020, .run/.sum: 1.4353, batch_loss: 1.1486, loss: 1.1425 ||:  31%|###1      | 245/784 [01:00<02:06,  4.26it/s]
.run/deps/UAS: 0.7592, .run/deps/LAS: 0.6789, .run/deps/UEM: 0.2819, .run/deps/LEM: 0.2074, .run/.sum: 1.4382, batch_loss: 1.4983, loss: 1.1309 ||:  33%|###2      | 255/784 [01:02<01:58,  4.45it/s]
.run/deps/UAS: 0.7596, .run/deps/LAS: 0.6792, .run/deps/UEM: 0.2805, .run/deps/LEM: 0.2057, .run/.sum: 1.4388, batch_loss: 1.3419, loss: 1.1342 ||:  34%|###3      | 264/784 [01:05<02:11,  3.94it/s]
.run/deps/UAS: 0.7597, .run/deps/LAS: 0.6789, .run/deps/UEM: 0.2759, .run/deps/LEM: 0.2012, .run/.sum: 1.4386, batch_loss: 1.4915, loss: 1.1372 ||:  35%|###4      | 273/784 [01:07<02:11,  3.88it/s]
.run/deps/UAS: 0.7604, .run/deps/LAS: 0.6794, .run/deps/UEM: 0.2858, .run/deps/LEM: 0.2109, .run/.sum: 1.4398, batch_loss: 0.7706, loss: 1.1270 ||:  36%|###6      | 283/784 [01:09<02:00,  4.15it/s]
.run/deps/UAS: 0.7604, .run/deps/LAS: 0.6797, .run/deps/UEM: 0.2918, .run/deps/LEM: 0.2167, .run/.sum: 1.4401, batch_loss: 1.5700, loss: 1.1192 ||:  37%|###7      | 293/784 [01:11<01:55,  4.26it/s]
.run/deps/UAS: 0.7598, .run/deps/LAS: 0.6789, .run/deps/UEM: 0.2908, .run/deps/LEM: 0.2156, .run/.sum: 1.4388, batch_loss: 0.0007, loss: 1.1219 ||:  39%|###8      | 302/784 [01:14<01:53,  4.24it/s]
.run/deps/UAS: 0.7565, .run/deps/LAS: 0.6762, .run/deps/UEM: 0.2917, .run/deps/LEM: 0.2163, .run/.sum: 1.4327, batch_loss: 0.8661, loss: 1.1235 ||:  40%|###9      | 311/784 [01:16<02:01,  3.90it/s]
.run/deps/UAS: 0.7567, .run/deps/LAS: 0.6764, .run/deps/UEM: 0.2919, .run/deps/LEM: 0.2166, .run/.sum: 1.4331, batch_loss: 1.3721, loss: 1.1232 ||:  41%|####      | 320/784 [01:18<01:54,  4.05it/s]
.run/deps/UAS: 0.7573, .run/deps/LAS: 0.6771, .run/deps/UEM: 0.2932, .run/deps/LEM: 0.2182, .run/.sum: 1.4345, batch_loss: 1.0044, loss: 1.1183 ||:  42%|####2     | 330/784 [01:20<01:47,  4.22it/s]
.run/deps/UAS: 0.7573, .run/deps/LAS: 0.6772, .run/deps/UEM: 0.2915, .run/deps/LEM: 0.2161, .run/.sum: 1.4346, batch_loss: 1.4062, loss: 1.1242 ||:  43%|####3     | 339/784 [01:23<01:47,  4.14it/s]
.run/deps/UAS: 0.7574, .run/deps/LAS: 0.6773, .run/deps/UEM: 0.2919, .run/deps/LEM: 0.2172, .run/.sum: 1.4347, batch_loss: 2.0287, loss: 1.1261 ||:  44%|####4     | 348/784 [01:25<01:47,  4.05it/s]
.run/deps/UAS: 0.7583, .run/deps/LAS: 0.6782, .run/deps/UEM: 0.2944, .run/deps/LEM: 0.2169, .run/.sum: 1.4365, batch_loss: 1.6785, loss: 1.1262 ||:  46%|####5     | 358/784 [01:27<01:39,  4.28it/s]
.run/deps/UAS: 0.7584, .run/deps/LAS: 0.6785, .run/deps/UEM: 0.2911, .run/deps/LEM: 0.2136, .run/.sum: 1.4369, batch_loss: 1.3145, loss: 1.1288 ||:  47%|####6     | 367/784 [01:30<01:45,  3.96it/s]
.run/deps/UAS: 0.7583, .run/deps/LAS: 0.6782, .run/deps/UEM: 0.2876, .run/deps/LEM: 0.2108, .run/.sum: 1.4364, batch_loss: 0.7069, loss: 1.1323 ||:  48%|####7     | 376/784 [01:32<01:44,  3.90it/s]
.run/deps/UAS: 0.7585, .run/deps/LAS: 0.6782, .run/deps/UEM: 0.2864, .run/deps/LEM: 0.2093, .run/.sum: 1.4367, batch_loss: 1.0229, loss: 1.1349 ||:  49%|####9     | 385/784 [01:34<01:40,  3.96it/s]
.run/deps/UAS: 0.7585, .run/deps/LAS: 0.6785, .run/deps/UEM: 0.2872, .run/deps/LEM: 0.2104, .run/.sum: 1.4370, batch_loss: 1.1270, loss: 1.1332 ||:  50%|#####     | 394/784 [01:37<01:37,  4.01it/s]
.run/deps/UAS: 0.7582, .run/deps/LAS: 0.6784, .run/deps/UEM: 0.2868, .run/deps/LEM: 0.2106, .run/.sum: 1.4366, batch_loss: 1.1414, loss: 1.1325 ||:  51%|#####1    | 403/784 [01:39<01:34,  4.05it/s]
.run/deps/UAS: 0.7578, .run/deps/LAS: 0.6778, .run/deps/UEM: 0.2865, .run/deps/LEM: 0.2113, .run/.sum: 1.4356, batch_loss: 0.0003, loss: 1.1332 ||:  53%|#####2    | 412/784 [01:41<01:31,  4.05it/s]
.run/deps/UAS: 0.7579, .run/deps/LAS: 0.6778, .run/deps/UEM: 0.2842, .run/deps/LEM: 0.2092, .run/.sum: 1.4358, batch_loss: 1.8469, loss: 1.1374 ||:  54%|#####3    | 421/784 [01:43<01:28,  4.12it/s]
.run/deps/UAS: 0.7587, .run/deps/LAS: 0.6786, .run/deps/UEM: 0.2850, .run/deps/LEM: 0.2077, .run/.sum: 1.4374, batch_loss: 1.1823, loss: 1.1349 ||:  55%|#####4    | 431/784 [01:45<01:21,  4.31it/s]
.run/deps/UAS: 0.7586, .run/deps/LAS: 0.6783, .run/deps/UEM: 0.2829, .run/deps/LEM: 0.2056, .run/.sum: 1.4368, batch_loss: 0.9829, loss: 1.1394 ||:  56%|#####6    | 440/784 [01:47<01:21,  4.21it/s]
.run/deps/UAS: 0.7578, .run/deps/LAS: 0.6775, .run/deps/UEM: 0.2807, .run/deps/LEM: 0.2035, .run/.sum: 1.4353, batch_loss: 1.9479, loss: 1.1432 ||:  57%|#####7    | 449/784 [01:50<01:22,  4.04it/s]
.run/deps/UAS: 0.7583, .run/deps/LAS: 0.6780, .run/deps/UEM: 0.2814, .run/deps/LEM: 0.2033, .run/.sum: 1.4363, batch_loss: 1.0291, loss: 1.1416 ||:  59%|#####8    | 459/784 [01:52<01:17,  4.21it/s]
.run/deps/UAS: 0.7585, .run/deps/LAS: 0.6783, .run/deps/UEM: 0.2817, .run/deps/LEM: 0.2036, .run/.sum: 1.4368, batch_loss: 1.3633, loss: 1.1406 ||:  60%|#####9    | 468/784 [01:55<01:18,  4.01it/s]
.run/deps/UAS: 0.7589, .run/deps/LAS: 0.6788, .run/deps/UEM: 0.2794, .run/deps/LEM: 0.2017, .run/.sum: 1.4378, batch_loss: 1.2583, loss: 1.1418 ||:  61%|######    | 477/784 [01:57<01:17,  3.96it/s]
.run/deps/UAS: 0.7590, .run/deps/LAS: 0.6788, .run/deps/UEM: 0.2807, .run/deps/LEM: 0.2024, .run/.sum: 1.4378, batch_loss: 1.2881, loss: 1.1428 ||:  62%|######2   | 487/784 [01:59<01:11,  4.15it/s]
.run/deps/UAS: 0.7589, .run/deps/LAS: 0.6787, .run/deps/UEM: 0.2781, .run/deps/LEM: 0.2005, .run/.sum: 1.4376, batch_loss: 1.7360, loss: 1.1447 ||:  63%|######3   | 496/784 [02:01<01:11,  4.03it/s]
.run/deps/UAS: 0.7594, .run/deps/LAS: 0.6792, .run/deps/UEM: 0.2809, .run/deps/LEM: 0.2027, .run/.sum: 1.4386, batch_loss: 0.6096, loss: 1.1425 ||:  65%|######4   | 506/784 [02:04<01:05,  4.24it/s]
.run/deps/UAS: 0.7601, .run/deps/LAS: 0.6796, .run/deps/UEM: 0.2810, .run/deps/LEM: 0.2034, .run/.sum: 1.4397, batch_loss: 1.3492, loss: 1.1388 ||:  66%|######5   | 515/784 [02:06<01:04,  4.18it/s]
.run/deps/UAS: 0.7605, .run/deps/LAS: 0.6799, .run/deps/UEM: 0.2818, .run/deps/LEM: 0.2035, .run/.sum: 1.4404, batch_loss: 1.2862, loss: 1.1383 ||:  67%|######6   | 524/784 [02:08<01:01,  4.22it/s]
.run/deps/UAS: 0.7612, .run/deps/LAS: 0.6805, .run/deps/UEM: 0.2818, .run/deps/LEM: 0.2032, .run/.sum: 1.4417, batch_loss: 1.2944, loss: 1.1377 ||:  68%|######8   | 534/784 [02:10<00:57,  4.34it/s]
.run/deps/UAS: 0.7607, .run/deps/LAS: 0.6803, .run/deps/UEM: 0.2826, .run/deps/LEM: 0.2040, .run/.sum: 1.4410, batch_loss: 0.7035, loss: 1.1378 ||:  69%|######9   | 543/784 [02:12<00:56,  4.23it/s]
.run/deps/UAS: 0.7607, .run/deps/LAS: 0.6804, .run/deps/UEM: 0.2820, .run/deps/LEM: 0.2034, .run/.sum: 1.4411, batch_loss: 1.3053, loss: 1.1383 ||:  70%|#######   | 552/784 [02:14<00:54,  4.27it/s]
.run/deps/UAS: 0.7594, .run/deps/LAS: 0.6792, .run/deps/UEM: 0.2829, .run/deps/LEM: 0.2046, .run/.sum: 1.4386, batch_loss: 0.9214, loss: 1.1370 ||:  72%|#######1  | 561/784 [02:17<00:54,  4.07it/s]
.run/deps/UAS: 0.7591, .run/deps/LAS: 0.6789, .run/deps/UEM: 0.2836, .run/deps/LEM: 0.2053, .run/.sum: 1.4380, batch_loss: 0.8552, loss: 1.1360 ||:  73%|#######2  | 570/784 [02:20<00:56,  3.77it/s]
.run/deps/UAS: 0.7592, .run/deps/LAS: 0.6789, .run/deps/UEM: 0.2821, .run/deps/LEM: 0.2033, .run/.sum: 1.4381, batch_loss: 1.5791, loss: 1.1369 ||:  74%|#######3  | 578/784 [02:22<00:54,  3.78it/s]
.run/deps/UAS: 0.7587, .run/deps/LAS: 0.6785, .run/deps/UEM: 0.2819, .run/deps/LEM: 0.2032, .run/.sum: 1.4372, batch_loss: 0.7253, loss: 1.1368 ||:  75%|#######4  | 587/784 [02:24<00:50,  3.88it/s]
.run/deps/UAS: 0.7580, .run/deps/LAS: 0.6776, .run/deps/UEM: 0.2795, .run/deps/LEM: 0.2014, .run/.sum: 1.4356, batch_loss: 1.6441, loss: 1.1413 ||:  76%|#######5  | 595/784 [02:26<00:50,  3.77it/s]
.run/deps/UAS: 0.7568, .run/deps/LAS: 0.6763, .run/deps/UEM: 0.2760, .run/deps/LEM: 0.1987, .run/.sum: 1.4330, batch_loss: 1.2815, loss: 1.1447 ||:  77%|#######6  | 603/784 [02:29<00:50,  3.57it/s]
.run/deps/UAS: 0.7575, .run/deps/LAS: 0.6769, .run/deps/UEM: 0.2769, .run/deps/LEM: 0.1982, .run/.sum: 1.4344, batch_loss: 1.0930, loss: 1.1415 ||:  78%|#######8  | 613/784 [02:31<00:43,  3.89it/s]
.run/deps/UAS: 0.7578, .run/deps/LAS: 0.6772, .run/deps/UEM: 0.2752, .run/deps/LEM: 0.1963, .run/.sum: 1.4350, batch_loss: 1.0215, loss: 1.1418 ||:  79%|#######9  | 621/784 [02:33<00:41,  3.91it/s]
.run/deps/UAS: 0.7581, .run/deps/LAS: 0.6775, .run/deps/UEM: 0.2749, .run/deps/LEM: 0.1958, .run/.sum: 1.4355, batch_loss: 1.5017, loss: 1.1428 ||:  80%|########  | 630/784 [02:35<00:38,  4.00it/s]
.run/deps/UAS: 0.7583, .run/deps/LAS: 0.6777, .run/deps/UEM: 0.2766, .run/deps/LEM: 0.1974, .run/.sum: 1.4361, batch_loss: 0.0007, loss: 1.1398 ||:  82%|########1 | 639/784 [02:37<00:36,  3.96it/s]
.run/deps/UAS: 0.7583, .run/deps/LAS: 0.6777, .run/deps/UEM: 0.2748, .run/deps/LEM: 0.1954, .run/.sum: 1.4359, batch_loss: 1.2653, loss: 1.1421 ||:  83%|########2 | 647/784 [02:39<00:34,  3.93it/s]
.run/deps/UAS: 0.7585, .run/deps/LAS: 0.6779, .run/deps/UEM: 0.2780, .run/deps/LEM: 0.1982, .run/.sum: 1.4365, batch_loss: 1.2338, loss: 1.1382 ||:  84%|########3 | 657/784 [02:41<00:30,  4.18it/s]
.run/deps/UAS: 0.7586, .run/deps/LAS: 0.6779, .run/deps/UEM: 0.2776, .run/deps/LEM: 0.1984, .run/.sum: 1.4364, batch_loss: 1.3024, loss: 1.1375 ||:  85%|########4 | 666/784 [02:44<00:31,  3.80it/s]
.run/deps/UAS: 0.7583, .run/deps/LAS: 0.6778, .run/deps/UEM: 0.2765, .run/deps/LEM: 0.1974, .run/.sum: 1.4361, batch_loss: 1.3177, loss: 1.1391 ||:  86%|########5 | 674/784 [02:46<00:28,  3.80it/s]
.run/deps/UAS: 0.7584, .run/deps/LAS: 0.6778, .run/deps/UEM: 0.2755, .run/deps/LEM: 0.1965, .run/.sum: 1.4362, batch_loss: 1.2433, loss: 1.1400 ||:  87%|########7 | 683/784 [02:49<00:25,  3.90it/s]
.run/deps/UAS: 0.7572, .run/deps/LAS: 0.6766, .run/deps/UEM: 0.2730, .run/deps/LEM: 0.1948, .run/.sum: 1.4337, batch_loss: 1.3550, loss: 1.1435 ||:  88%|########8 | 691/784 [02:51<00:25,  3.60it/s]
.run/deps/UAS: 0.7577, .run/deps/LAS: 0.6771, .run/deps/UEM: 0.2737, .run/deps/LEM: 0.1954, .run/.sum: 1.4348, batch_loss: 0.8311, loss: 1.1398 ||:  89%|########9 | 701/784 [02:53<00:21,  3.91it/s]
.run/deps/UAS: 0.7575, .run/deps/LAS: 0.6769, .run/deps/UEM: 0.2733, .run/deps/LEM: 0.1949, .run/.sum: 1.4344, batch_loss: 1.0759, loss: 1.1407 ||:  91%|######### | 710/784 [02:56<00:18,  3.96it/s]
.run/deps/UAS: 0.7577, .run/deps/LAS: 0.6771, .run/deps/UEM: 0.2731, .run/deps/LEM: 0.1951, .run/.sum: 1.4348, batch_loss: 1.6368, loss: 1.1404 ||:  92%|#########1| 719/784 [02:58<00:16,  3.99it/s]
.run/deps/UAS: 0.7579, .run/deps/LAS: 0.6773, .run/deps/UEM: 0.2741, .run/deps/LEM: 0.1954, .run/.sum: 1.4353, batch_loss: 1.4917, loss: 1.1398 ||:  93%|#########2| 728/784 [03:00<00:13,  4.13it/s]
.run/deps/UAS: 0.7580, .run/deps/LAS: 0.6774, .run/deps/UEM: 0.2728, .run/deps/LEM: 0.1940, .run/.sum: 1.4354, batch_loss: 1.4059, loss: 1.1414 ||:  94%|#########4| 737/784 [03:02<00:11,  4.14it/s]
.run/deps/UAS: 0.7581, .run/deps/LAS: 0.6774, .run/deps/UEM: 0.2736, .run/deps/LEM: 0.1946, .run/.sum: 1.4356, batch_loss: 1.4872, loss: 1.1411 ||:  95%|#########5| 747/784 [03:04<00:08,  4.28it/s]
.run/deps/UAS: 0.7585, .run/deps/LAS: 0.6778, .run/deps/UEM: 0.2761, .run/deps/LEM: 0.1973, .run/.sum: 1.4364, batch_loss: 0.8713, loss: 1.1361 ||:  96%|#########6| 756/784 [03:06<00:06,  4.31it/s]
.run/deps/UAS: 0.7584, .run/deps/LAS: 0.6778, .run/deps/UEM: 0.2779, .run/deps/LEM: 0.1984, .run/.sum: 1.4362, batch_loss: 0.7062, loss: 1.1353 ||:  98%|#########7| 765/784 [03:09<00:04,  3.93it/s]
.run/deps/UAS: 0.7585, .run/deps/LAS: 0.6778, .run/deps/UEM: 0.2779, .run/deps/LEM: 0.1987, .run/.sum: 1.4363, batch_loss: 1.4073, loss: 1.1346 ||:  99%|#########8| 773/784 [03:11<00:02,  3.90it/s]
.run/deps/UAS: 0.7582, .run/deps/LAS: 0.6777, .run/deps/UEM: 0.2776, .run/deps/LEM: 0.1986, .run/.sum: 1.4360, batch_loss: 0.0006, loss: 1.1344 ||: 100%|#########9| 781/784 [03:13<00:00,  3.87it/s]
.run/deps/UAS: 0.7584, .run/deps/LAS: 0.6779, .run/deps/UEM: 0.2784, .run/deps/LEM: 0.1995, .run/.sum: 1.4363, batch_loss: 1.2356, loss: 1.1326 ||: 100%|##########| 784/784 [03:14<00:00,  4.04it/s]
2021-05-12 00:40:55,719 - INFO - allennlp.training.trainer - Validating
  0%|          | 0/126 [00:00<?, ?it/s]
.run/deps/UAS: 0.8837, .run/deps/LAS: 0.8438, .run/deps/UEM: 0.5099, .run/deps/LEM: 0.4013, .run/.sum: 1.7275, batch_loss: 1.1522, loss: 0.5040 ||:  15%|#5        | 19/126 [00:02<00:11,  8.98it/s]
.run/deps/UAS: 0.8777, .run/deps/LAS: 0.8415, .run/deps/UEM: 0.4949, .run/deps/LEM: 0.4071, .run/.sum: 1.7192, batch_loss: 0.8333, loss: 0.5582 ||:  29%|##9       | 37/126 [00:04<00:10,  8.83it/s]
.run/deps/UAS: 0.8858, .run/deps/LAS: 0.8497, .run/deps/UEM: 0.5363, .run/deps/LEM: 0.4365, .run/.sum: 1.7355, batch_loss: 0.3307, loss: 0.5596 ||:  49%|####9     | 62/126 [00:06<00:06, 10.39it/s]
.run/deps/UAS: 0.8843, .run/deps/LAS: 0.8478, .run/deps/UEM: 0.5800, .run/deps/LEM: 0.4794, .run/.sum: 1.7321, batch_loss: 0.6878, loss: 0.5861 ||:  68%|######8   | 86/126 [00:08<00:03, 10.79it/s]
.run/deps/UAS: 0.8884, .run/deps/LAS: 0.8512, .run/deps/UEM: 0.5778, .run/deps/LEM: 0.4694, .run/.sum: 1.7395, batch_loss: 0.4500, loss: 0.5786 ||:  88%|########8 | 111/126 [00:10<00:01, 11.24it/s]
.run/deps/UAS: 0.8885, .run/deps/LAS: 0.8520, .run/deps/UEM: 0.5724, .run/deps/LEM: 0.4635, .run/.sum: 1.7404, batch_loss: 0.3244, loss: 0.5788 ||: 100%|##########| 126/126 [00:11<00:00, 10.51it/s]
2021-05-12 00:41:07,712 - INFO - allennlp.training.tensorboard_writer -                        Training |  Validation
2021-05-12 00:41:07,713 - INFO - allennlp.training.tensorboard_writer - .run/.sum          |     1.436  |     1.740
2021-05-12 00:41:07,713 - INFO - allennlp.training.tensorboard_writer - .run/deps/LAS      |     0.678  |     0.852
2021-05-12 00:41:07,713 - INFO - allennlp.training.tensorboard_writer - .run/deps/LEM      |     0.199  |     0.464
2021-05-12 00:41:07,714 - INFO - allennlp.training.tensorboard_writer - .run/deps/UAS      |     0.758  |     0.888
2021-05-12 00:41:07,714 - INFO - allennlp.training.tensorboard_writer - .run/deps/UEM      |     0.278  |     0.572
2021-05-12 00:41:07,714 - INFO - allennlp.training.tensorboard_writer - gpu_0_memory_MB    |  5612.324  |       N/A
2021-05-12 00:41:07,714 - INFO - allennlp.training.tensorboard_writer - loss               |     1.133  |     0.579
2021-05-12 00:41:07,714 - INFO - allennlp.training.tensorboard_writer - worker_0_memory_MB |  4224.805  |       N/A
2021-05-12 00:41:07,719 - INFO - udify.optimizers.ulmfit_sqrt - Gradual unfreezing finished. Training all layers.
2021-05-12 00:41:13,266 - INFO - allennlp.training.checkpointer - Best validation performance so far. Copying weights to 'logs/bert_finetune_en/2021.05.12_00.22.24/best.th'.
2021-05-12 00:41:15,661 - INFO - allennlp.training.trainer - Epoch duration: 0:03:37.084332
2021-05-12 00:41:15,661 - INFO - allennlp.training.checkpointer - loading best weights
2021-05-12 00:41:16,991 - INFO - allennlp.commands.train - The model will be evaluated using the best epoch weights.
2021-05-12 00:41:16,994 - INFO - allennlp.training.util - Iterating over dataset
0it [00:00, ?it/s]
2021-05-12 00:41:16,995 - INFO - allennlp.data.samplers.bucket_batch_sampler - No sorting keys given; trying to guess a good one
2021-05-12 00:41:16,999 - INFO - allennlp.data.samplers.bucket_batch_sampler - Using ['tokens'] as the sorting keys
.run/deps/UAS: 0.88, .run/deps/LAS: 0.84, .run/deps/UEM: 0.62, .run/deps/LEM: 0.51, .run/.sum: 1.72, loss: 0.54 ||: : 22it [00:02, 10.92it/s]
.run/deps/UAS: 0.88, .run/deps/LAS: 0.84, .run/deps/UEM: 0.57, .run/deps/LEM: 0.45, .run/.sum: 1.72, loss: 0.56 ||: : 44it [00:04, 10.11it/s]
.run/deps/UAS: 0.89, .run/deps/LAS: 0.85, .run/deps/UEM: 0.58, .run/deps/LEM: 0.47, .run/.sum: 1.74, loss: 0.53 ||: : 67it [00:06, 10.48it/s]
.run/deps/UAS: 0.89, .run/deps/LAS: 0.85, .run/deps/UEM: 0.58, .run/deps/LEM: 0.46, .run/.sum: 1.74, loss: 0.54 ||: : 94it [00:08, 11.20it/s]
.run/deps/UAS: 0.89, .run/deps/LAS: 0.85, .run/deps/UEM: 0.59, .run/deps/LEM: 0.47, .run/.sum: 1.74, loss: 0.56 ||: : 119it [00:10, 11.63it/s]
.run/deps/UAS: 0.89, .run/deps/LAS: 0.85, .run/deps/UEM: 0.58, .run/deps/LEM: 0.47, .run/.sum: 1.74, loss: 0.56 ||: : 130it [00:12, 10.45it/s]
2021-05-12 00:41:29,439 - INFO - allennlp.common.util - Metrics: {
  "best_epoch": 4,
  "peak_worker_0_memory_MB": 4224.8046875,
  "peak_gpu_0_memory_MB": 5612.32373046875,
  "training_duration": "0:18:04.226312",
  "training_start_epoch": 0,
  "training_epochs": 4,
  "epoch": 4,
  "training_.run/deps/UAS": 0.7583938216389275,
  "training_.run/deps/LAS": 0.6778942737737371,
  "training_.run/deps/UEM": 0.27840229610141115,
  "training_.run/deps/LEM": 0.1994738100932791,
  "training_.run/.sum": 1.4362880954126647,
  "training_loss": 1.1326451982908556,
  "training_worker_0_memory_MB": 4224.8046875,
  "training_gpu_0_memory_MB": 5612.32373046875,
  "validation_.run/deps/UAS": 0.8884603149355813,
  "validation_.run/deps/LAS": 0.851956418005408,
  "validation_.run/deps/UEM": 0.5724275724275725,
  "validation_.run/deps/LEM": 0.46353646353646355,
  "validation_.run/.sum": 1.7404167329409894,
  "validation_loss": 0.5788169523614106,
  "best_validation_.run/deps/UAS": 0.8884603149355813,
  "best_validation_.run/deps/LAS": 0.851956418005408,
  "best_validation_.run/deps/UEM": 0.5724275724275725,
  "best_validation_.run/deps/LEM": 0.46353646353646355,
  "best_validation_.run/.sum": 1.7404167329409894,
  "best_validation_loss": 0.5788169523614106,
  "test_.run/deps/UAS": 0.8867150143449155,
  "test_.run/deps/LAS": 0.8498167038571884,
  "test_.run/deps/UEM": 0.5840154068367838,
  "test_.run/deps/LEM": 0.470871449205585,
  "test_.run/.sum": 1.7365317182021038,
  "test_loss": 0.5640935740269085
}
2021-05-12 00:41:29,459 - INFO - allennlp.models.archival - archiving weights and vocabulary to logs/bert_finetune_en/2021.05.12_00.22.24/model.tar.gz
2021-05-12 00:42:52,805 - INFO - allennlp.models.archival - loading archive file logs/bert_finetune_en/2021.05.12_00.22.24/model.tar.gz
2021-05-12 00:42:52,806 - INFO - allennlp.models.archival - extracting archive file logs/bert_finetune_en/2021.05.12_00.22.24/model.tar.gz to temp dir /scratch/tmp0theyu4w
2021-05-12 00:43:03,111 - INFO - allennlp.common.params - dataset_reader.type = udify_universal_dependencies
2021-05-12 00:43:03,112 - INFO - allennlp.common.params - dataset_reader.token_indexers.bert.type = udify-bert-pretrained
2021-05-12 00:43:03,112 - INFO - allennlp.common.params - dataset_reader.token_indexers.bert.pretrained_model = config/archive/bert-base-multilingual-cased/vocab.txt
2021-05-12 00:43:03,112 - INFO - allennlp.common.params - dataset_reader.token_indexers.bert.use_starting_offsets = True
2021-05-12 00:43:03,112 - INFO - allennlp.common.params - dataset_reader.token_indexers.bert.do_lowercase = False
2021-05-12 00:43:03,112 - INFO - allennlp.common.params - dataset_reader.token_indexers.bert.never_lowercase = None
2021-05-12 00:43:03,112 - INFO - allennlp.common.params - dataset_reader.token_indexers.bert.max_pieces = 512
2021-05-12 00:43:03,113 - INFO - allennlp.common.params - dataset_reader.token_indexers.bert.truncate_long_sequences = False
Calling BertTokenizer.from_pretrained() with the path to a single file or url is deprecated
2021-05-12 00:43:03,331 - INFO - allennlp.common.params - dataset_reader.token_indexers.tokens.type = single_id
2021-05-12 00:43:03,332 - INFO - allennlp.common.params - dataset_reader.token_indexers.tokens.namespace = tokens
2021-05-12 00:43:03,332 - INFO - allennlp.common.params - dataset_reader.token_indexers.tokens.lowercase_tokens = True
2021-05-12 00:43:03,332 - INFO - allennlp.common.params - dataset_reader.token_indexers.tokens.start_tokens = None
2021-05-12 00:43:03,332 - INFO - allennlp.common.params - dataset_reader.token_indexers.tokens.end_tokens = None
2021-05-12 00:43:03,332 - INFO - allennlp.common.params - dataset_reader.token_indexers.tokens.feature_name = text
2021-05-12 00:43:03,332 - INFO - allennlp.common.params - dataset_reader.token_indexers.tokens.default_value = THIS IS A REALLY UNLIKELY VALUE THAT HAS TO BE A STRING
2021-05-12 00:43:03,332 - INFO - allennlp.common.params - dataset_reader.token_indexers.tokens.token_min_padding_length = 0
2021-05-12 00:43:03,332 - INFO - allennlp.common.params - dataset_reader.lazy = False
2021-05-12 00:43:03,332 - INFO - allennlp.common.params - dataset_reader.type = udify_universal_dependencies
2021-05-12 00:43:03,333 - INFO - allennlp.common.params - dataset_reader.token_indexers.bert.type = udify-bert-pretrained
2021-05-12 00:43:03,333 - INFO - allennlp.common.params - dataset_reader.token_indexers.bert.pretrained_model = config/archive/bert-base-multilingual-cased/vocab.txt
2021-05-12 00:43:03,333 - INFO - allennlp.common.params - dataset_reader.token_indexers.bert.use_starting_offsets = True
2021-05-12 00:43:03,333 - INFO - allennlp.common.params - dataset_reader.token_indexers.bert.do_lowercase = False
2021-05-12 00:43:03,333 - INFO - allennlp.common.params - dataset_reader.token_indexers.bert.never_lowercase = None
2021-05-12 00:43:03,333 - INFO - allennlp.common.params - dataset_reader.token_indexers.bert.max_pieces = 512
2021-05-12 00:43:03,333 - INFO - allennlp.common.params - dataset_reader.token_indexers.bert.truncate_long_sequences = False
Calling BertTokenizer.from_pretrained() with the path to a single file or url is deprecated
2021-05-12 00:43:03,549 - INFO - allennlp.common.params - dataset_reader.token_indexers.tokens.type = single_id
2021-05-12 00:43:03,550 - INFO - allennlp.common.params - dataset_reader.token_indexers.tokens.namespace = tokens
2021-05-12 00:43:03,550 - INFO - allennlp.common.params - dataset_reader.token_indexers.tokens.lowercase_tokens = True
2021-05-12 00:43:03,550 - INFO - allennlp.common.params - dataset_reader.token_indexers.tokens.start_tokens = None
2021-05-12 00:43:03,550 - INFO - allennlp.common.params - dataset_reader.token_indexers.tokens.end_tokens = None
2021-05-12 00:43:03,550 - INFO - allennlp.common.params - dataset_reader.token_indexers.tokens.feature_name = text
2021-05-12 00:43:03,550 - INFO - allennlp.common.params - dataset_reader.token_indexers.tokens.default_value = THIS IS A REALLY UNLIKELY VALUE THAT HAS TO BE A STRING
2021-05-12 00:43:03,550 - INFO - allennlp.common.params - dataset_reader.token_indexers.tokens.token_min_padding_length = 0
2021-05-12 00:43:03,550 - INFO - allennlp.common.params - dataset_reader.lazy = False
2021-05-12 00:43:03,551 - INFO - allennlp.common.params - vocabulary.type = from_files
2021-05-12 00:43:03,551 - INFO - allennlp.data.vocabulary - Loading token dictionary from /scratch/tmp0theyu4w/vocabulary.
2021-05-12 00:43:03,551 - INFO - filelock - Lock 22396695406336 acquired on /scratch/tmp0theyu4w/vocabulary/.lock
2021-05-12 00:43:04,936 - INFO - filelock - Lock 22396695406336 released on /scratch/tmp0theyu4w/vocabulary/.lock
2021-05-12 00:43:04,937 - INFO - allennlp.common.params - model.type = udify_model
2021-05-12 00:43:04,937 - INFO - allennlp.common.params - model.tasks = ['deps']
2021-05-12 00:43:04,938 - INFO - allennlp.common.params - model.text_field_embedder.type = udify_embedder
2021-05-12 00:43:04,938 - INFO - allennlp.common.params - model.text_field_embedder.allow_unmatched_keys = True
2021-05-12 00:43:04,938 - INFO - allennlp.common.params - model.text_field_embedder.dropout = 0.5
2021-05-12 00:43:04,938 - INFO - allennlp.common.params - model.text_field_embedder.output_dim = None
2021-05-12 00:43:04,938 - INFO - allennlp.common.params - model.text_field_embedder.sum_embeddings = None
2021-05-12 00:43:04,938 - INFO - allennlp.common.params - model.text_field_embedder.token_embedders.bert.type = udify-bert-pretrained
2021-05-12 00:43:04,938 - INFO - allennlp.common.params - model.text_field_embedder.token_embedders.bert.pretrained_model = bert-base-multilingual-cased
2021-05-12 00:43:04,938 - INFO - allennlp.common.params - model.text_field_embedder.token_embedders.bert.requires_grad = True
2021-05-12 00:43:04,938 - INFO - allennlp.common.params - model.text_field_embedder.token_embedders.bert.dropout = 0.15
2021-05-12 00:43:04,939 - INFO - allennlp.common.params - model.text_field_embedder.token_embedders.bert.layer_dropout = 0.1
2021-05-12 00:43:04,939 - INFO - allennlp.common.params - model.text_field_embedder.token_embedders.bert.combine_layers = all
2021-05-12 00:43:11,891 - INFO - allennlp.common.params - model.encoder.type = pass_through
2021-05-12 00:43:11,892 - INFO - allennlp.common.params - model.encoder.input_dim = 768
2021-05-12 00:43:11,892 - INFO - allennlp.common.params - model.decoders.deps.type = udify_dependency_decoder
2021-05-12 00:43:11,892 - INFO - allennlp.common.params - model.decoders.deps.encoder.type = pass_through
2021-05-12 00:43:11,893 - INFO - allennlp.common.params - model.decoders.deps.encoder.input_dim = 768
2021-05-12 00:43:11,893 - INFO - allennlp.common.params - model.decoders.deps.tag_representation_dim = 256
2021-05-12 00:43:11,893 - INFO - allennlp.common.params - model.decoders.deps.arc_representation_dim = 768
2021-05-12 00:43:11,893 - INFO - allennlp.common.params - model.decoders.deps.pos_embed_dim = None
2021-05-12 00:43:11,893 - INFO - allennlp.common.params - model.decoders.deps.tag_feedforward = None
2021-05-12 00:43:11,893 - INFO - allennlp.common.params - model.decoders.deps.arc_feedforward = None
2021-05-12 00:43:11,893 - INFO - allennlp.common.params - model.decoders.deps.use_mst_decoding_for_validation = True
2021-05-12 00:43:11,893 - INFO - allennlp.common.params - model.decoders.deps.dropout = 0.5
2021-05-12 00:43:11,893 - INFO - allennlp.common.params - model.decoders.deps.initializer = <allennlp.nn.initializers.InitializerApplicator object at 0x145ec1431850>
2021-05-12 00:43:11,893 - INFO - allennlp.common.params - model.decoders.deps.regularizer = None
2021-05-12 00:43:12,009 - INFO - udify.models.dependency_decoder - Found POS tags corresponding to the following punctuation : {}. Ignoring words with these POS tags for evaluation.
2021-05-12 00:43:12,009 - INFO - allennlp.nn.initializers - Initializing parameters
2021-05-12 00:43:12,009 - INFO - allennlp.nn.initializers - Done initializing parameters; the following parameters are using their default initialization from their code
2021-05-12 00:43:12,009 - INFO - allennlp.nn.initializers -    _head_sentinel
2021-05-12 00:43:12,009 - INFO - allennlp.nn.initializers -    arc_attention._bias
2021-05-12 00:43:12,010 - INFO - allennlp.nn.initializers -    arc_attention._weight_matrix
2021-05-12 00:43:12,010 - INFO - allennlp.nn.initializers -    child_arc_feedforward._linear_layers.0.bias
2021-05-12 00:43:12,010 - INFO - allennlp.nn.initializers -    child_arc_feedforward._linear_layers.0.weight
2021-05-12 00:43:12,010 - INFO - allennlp.nn.initializers -    child_tag_feedforward._linear_layers.0.bias
2021-05-12 00:43:12,010 - INFO - allennlp.nn.initializers -    child_tag_feedforward._linear_layers.0.weight
2021-05-12 00:43:12,010 - INFO - allennlp.nn.initializers -    head_arc_feedforward._linear_layers.0.bias
2021-05-12 00:43:12,010 - INFO - allennlp.nn.initializers -    head_arc_feedforward._linear_layers.0.weight
2021-05-12 00:43:12,010 - INFO - allennlp.nn.initializers -    head_tag_feedforward._linear_layers.0.bias
2021-05-12 00:43:12,010 - INFO - allennlp.nn.initializers -    head_tag_feedforward._linear_layers.0.weight
2021-05-12 00:43:12,010 - INFO - allennlp.nn.initializers -    tag_bilinear.bias
2021-05-12 00:43:12,010 - INFO - allennlp.nn.initializers -    tag_bilinear.weight
2021-05-12 00:43:12,010 - INFO - allennlp.common.params - model.decoders.feats.type = udify_tag_decoder
2021-05-12 00:43:12,011 - INFO - allennlp.common.params - model.decoders.feats.task = feats
2021-05-12 00:43:12,011 - INFO - allennlp.common.params - model.decoders.feats.encoder.type = pass_through
2021-05-12 00:43:12,011 - INFO - allennlp.common.params - model.decoders.feats.encoder.input_dim = 768
2021-05-12 00:43:12,011 - INFO - allennlp.common.params - model.decoders.feats.label_smoothing = 0.03
2021-05-12 00:43:12,011 - INFO - allennlp.common.params - model.decoders.feats.dropout = 0.5
2021-05-12 00:43:12,011 - INFO - allennlp.common.params - model.decoders.feats.adaptive = True
2021-05-12 00:43:12,012 - INFO - allennlp.common.params - model.decoders.feats.features = None
2021-05-12 00:43:12,012 - INFO - allennlp.common.params - model.decoders.feats.initializer = <allennlp.nn.initializers.InitializerApplicator object at 0x145ec1431df0>
2021-05-12 00:43:12,012 - INFO - allennlp.common.params - model.decoders.feats.regularizer = None
2021-05-12 00:43:12,025 - INFO - allennlp.nn.initializers - Initializing parameters
2021-05-12 00:43:12,025 - INFO - allennlp.nn.initializers - Done initializing parameters; the following parameters are using their default initialization from their code
2021-05-12 00:43:12,026 - INFO - allennlp.nn.initializers -    task_output.head.weight
2021-05-12 00:43:12,026 - INFO - allennlp.nn.initializers -    task_output.tail.0.0.weight
2021-05-12 00:43:12,026 - INFO - allennlp.nn.initializers -    task_output.tail.0.1.weight
2021-05-12 00:43:12,026 - INFO - allennlp.nn.initializers -    task_output.tail.1.0.weight
2021-05-12 00:43:12,026 - INFO - allennlp.nn.initializers -    task_output.tail.1.1.weight
2021-05-12 00:43:12,026 - INFO - allennlp.common.params - model.decoders.lemmas.type = udify_tag_decoder
2021-05-12 00:43:12,026 - INFO - allennlp.common.params - model.decoders.lemmas.task = lemmas
2021-05-12 00:43:12,027 - INFO - allennlp.common.params - model.decoders.lemmas.encoder.type = pass_through
2021-05-12 00:43:12,027 - INFO - allennlp.common.params - model.decoders.lemmas.encoder.input_dim = 768
2021-05-12 00:43:12,027 - INFO - allennlp.common.params - model.decoders.lemmas.label_smoothing = 0.03
2021-05-12 00:43:12,027 - INFO - allennlp.common.params - model.decoders.lemmas.dropout = 0.5
2021-05-12 00:43:12,027 - INFO - allennlp.common.params - model.decoders.lemmas.adaptive = True
2021-05-12 00:43:12,027 - INFO - allennlp.common.params - model.decoders.lemmas.features = None
2021-05-12 00:43:12,027 - INFO - allennlp.common.params - model.decoders.lemmas.initializer = <allennlp.nn.initializers.InitializerApplicator object at 0x145ec1431df0>
2021-05-12 00:43:12,027 - INFO - allennlp.common.params - model.decoders.lemmas.regularizer = None
2021-05-12 00:43:12,122 - INFO - allennlp.nn.initializers - Initializing parameters
2021-05-12 00:43:12,122 - INFO - allennlp.nn.initializers - Done initializing parameters; the following parameters are using their default initialization from their code
2021-05-12 00:43:12,123 - INFO - allennlp.nn.initializers -    task_output.head.weight
2021-05-12 00:43:12,123 - INFO - allennlp.nn.initializers -    task_output.tail.0.0.weight
2021-05-12 00:43:12,123 - INFO - allennlp.nn.initializers -    task_output.tail.0.1.weight
2021-05-12 00:43:12,123 - INFO - allennlp.nn.initializers -    task_output.tail.1.0.weight
2021-05-12 00:43:12,123 - INFO - allennlp.nn.initializers -    task_output.tail.1.1.weight
2021-05-12 00:43:12,123 - INFO - allennlp.common.params - model.decoders.upos.type = udify_tag_decoder
2021-05-12 00:43:12,123 - INFO - allennlp.common.params - model.decoders.upos.task = upos
2021-05-12 00:43:12,124 - INFO - allennlp.common.params - model.decoders.upos.encoder.type = pass_through
2021-05-12 00:43:12,124 - INFO - allennlp.common.params - model.decoders.upos.encoder.input_dim = 768
2021-05-12 00:43:12,124 - INFO - allennlp.common.params - model.decoders.upos.label_smoothing = 0.03
2021-05-12 00:43:12,124 - INFO - allennlp.common.params - model.decoders.upos.dropout = 0.5
2021-05-12 00:43:12,124 - INFO - allennlp.common.params - model.decoders.upos.adaptive = False
2021-05-12 00:43:12,124 - INFO - allennlp.common.params - model.decoders.upos.features = None
2021-05-12 00:43:12,124 - INFO - allennlp.common.params - model.decoders.upos.initializer = <allennlp.nn.initializers.InitializerApplicator object at 0x145ec1431df0>
2021-05-12 00:43:12,124 - INFO - allennlp.common.params - model.decoders.upos.regularizer = None
2021-05-12 00:43:12,125 - INFO - allennlp.nn.initializers - Initializing parameters
2021-05-12 00:43:12,125 - INFO - allennlp.nn.initializers - Done initializing parameters; the following parameters are using their default initialization from their code
2021-05-12 00:43:12,125 - INFO - allennlp.nn.initializers -    task_output._module.bias
2021-05-12 00:43:12,125 - INFO - allennlp.nn.initializers -    task_output._module.weight
2021-05-12 00:43:12,125 - INFO - allennlp.common.params - model.pretrained_model = bert-base-multilingual-cased
2021-05-12 00:43:12,125 - INFO - allennlp.common.params - model.post_encoder_embedder = None
2021-05-12 00:43:12,125 - INFO - allennlp.common.params - model.dropout = 0.5
2021-05-12 00:43:12,125 - INFO - allennlp.common.params - model.word_dropout = 0.2
2021-05-12 00:43:12,125 - INFO - allennlp.common.params - model.mix_embedding = 12
2021-05-12 00:43:12,126 - INFO - allennlp.common.params - model.layer_dropout = 0.1
2021-05-12 00:43:12,126 - INFO - allennlp.common.params - model.initializer = <allennlp.nn.initializers.InitializerApplicator object at 0x145ec14394f0>
2021-05-12 00:43:12,126 - INFO - allennlp.common.params - model.regularizer = None
2021-05-12 00:43:12,647 - INFO - allennlp.nn.initializers - Initializing parameters
2021-05-12 00:43:12,650 - INFO - allennlp.nn.initializers - Done initializing parameters; the following parameters are using their default initialization from their code
2021-05-12 00:43:12,650 - INFO - allennlp.nn.initializers -    decoders.deps._head_sentinel
2021-05-12 00:43:12,650 - INFO - allennlp.nn.initializers -    decoders.deps.arc_attention._bias
2021-05-12 00:43:12,650 - INFO - allennlp.nn.initializers -    decoders.deps.arc_attention._weight_matrix
2021-05-12 00:43:12,650 - INFO - allennlp.nn.initializers -    decoders.deps.child_arc_feedforward._linear_layers.0.bias
2021-05-12 00:43:12,650 - INFO - allennlp.nn.initializers -    decoders.deps.child_arc_feedforward._linear_layers.0.weight
2021-05-12 00:43:12,651 - INFO - allennlp.nn.initializers -    decoders.deps.child_tag_feedforward._linear_layers.0.bias
2021-05-12 00:43:12,651 - INFO - allennlp.nn.initializers -    decoders.deps.child_tag_feedforward._linear_layers.0.weight
2021-05-12 00:43:12,651 - INFO - allennlp.nn.initializers -    decoders.deps.head_arc_feedforward._linear_layers.0.bias
2021-05-12 00:43:12,651 - INFO - allennlp.nn.initializers -    decoders.deps.head_arc_feedforward._linear_layers.0.weight
2021-05-12 00:43:12,651 - INFO - allennlp.nn.initializers -    decoders.deps.head_tag_feedforward._linear_layers.0.bias
2021-05-12 00:43:12,651 - INFO - allennlp.nn.initializers -    decoders.deps.head_tag_feedforward._linear_layers.0.weight
2021-05-12 00:43:12,651 - INFO - allennlp.nn.initializers -    decoders.deps.tag_bilinear.bias
2021-05-12 00:43:12,651 - INFO - allennlp.nn.initializers -    decoders.deps.tag_bilinear.weight
2021-05-12 00:43:12,651 - INFO - allennlp.nn.initializers -    decoders.feats.task_output.head.weight
2021-05-12 00:43:12,651 - INFO - allennlp.nn.initializers -    decoders.feats.task_output.tail.0.0.weight
2021-05-12 00:43:12,651 - INFO - allennlp.nn.initializers -    decoders.feats.task_output.tail.0.1.weight
2021-05-12 00:43:12,651 - INFO - allennlp.nn.initializers -    decoders.feats.task_output.tail.1.0.weight
2021-05-12 00:43:12,651 - INFO - allennlp.nn.initializers -    decoders.feats.task_output.tail.1.1.weight
2021-05-12 00:43:12,651 - INFO - allennlp.nn.initializers -    decoders.lemmas.task_output.head.weight
2021-05-12 00:43:12,651 - INFO - allennlp.nn.initializers -    decoders.lemmas.task_output.tail.0.0.weight
2021-05-12 00:43:12,651 - INFO - allennlp.nn.initializers -    decoders.lemmas.task_output.tail.0.1.weight
2021-05-12 00:43:12,651 - INFO - allennlp.nn.initializers -    decoders.lemmas.task_output.tail.1.0.weight
2021-05-12 00:43:12,651 - INFO - allennlp.nn.initializers -    decoders.lemmas.task_output.tail.1.1.weight
2021-05-12 00:43:12,652 - INFO - allennlp.nn.initializers -    decoders.upos.task_output._module.bias
2021-05-12 00:43:12,652 - INFO - allennlp.nn.initializers -    decoders.upos.task_output._module.weight
2021-05-12 00:43:12,652 - INFO - allennlp.nn.initializers -    scalar_mix.deps.gamma
2021-05-12 00:43:12,652 - INFO - allennlp.nn.initializers -    scalar_mix.deps.scalar_parameters.0
2021-05-12 00:43:12,652 - INFO - allennlp.nn.initializers -    scalar_mix.deps.scalar_parameters.1
2021-05-12 00:43:12,652 - INFO - allennlp.nn.initializers -    scalar_mix.deps.scalar_parameters.10
2021-05-12 00:43:12,652 - INFO - allennlp.nn.initializers -    scalar_mix.deps.scalar_parameters.11
2021-05-12 00:43:12,652 - INFO - allennlp.nn.initializers -    scalar_mix.deps.scalar_parameters.2
2021-05-12 00:43:12,652 - INFO - allennlp.nn.initializers -    scalar_mix.deps.scalar_parameters.3
2021-05-12 00:43:12,652 - INFO - allennlp.nn.initializers -    scalar_mix.deps.scalar_parameters.4
2021-05-12 00:43:12,652 - INFO - allennlp.nn.initializers -    scalar_mix.deps.scalar_parameters.5
2021-05-12 00:43:12,652 - INFO - allennlp.nn.initializers -    scalar_mix.deps.scalar_parameters.6
2021-05-12 00:43:12,652 - INFO - allennlp.nn.initializers -    scalar_mix.deps.scalar_parameters.7
2021-05-12 00:43:12,652 - INFO - allennlp.nn.initializers -    scalar_mix.deps.scalar_parameters.8
2021-05-12 00:43:12,652 - INFO - allennlp.nn.initializers -    scalar_mix.deps.scalar_parameters.9
2021-05-12 00:43:12,652 - INFO - allennlp.nn.initializers -    scalar_mix.feats.gamma
2021-05-12 00:43:12,652 - INFO - allennlp.nn.initializers -    scalar_mix.feats.scalar_parameters.0
2021-05-12 00:43:12,652 - INFO - allennlp.nn.initializers -    scalar_mix.feats.scalar_parameters.1
2021-05-12 00:43:12,653 - INFO - allennlp.nn.initializers -    scalar_mix.feats.scalar_parameters.10
2021-05-12 00:43:12,653 - INFO - allennlp.nn.initializers -    scalar_mix.feats.scalar_parameters.11
2021-05-12 00:43:12,653 - INFO - allennlp.nn.initializers -    scalar_mix.feats.scalar_parameters.2
2021-05-12 00:43:12,653 - INFO - allennlp.nn.initializers -    scalar_mix.feats.scalar_parameters.3
2021-05-12 00:43:12,653 - INFO - allennlp.nn.initializers -    scalar_mix.feats.scalar_parameters.4
2021-05-12 00:43:12,653 - INFO - allennlp.nn.initializers -    scalar_mix.feats.scalar_parameters.5
2021-05-12 00:43:12,653 - INFO - allennlp.nn.initializers -    scalar_mix.feats.scalar_parameters.6
2021-05-12 00:43:12,653 - INFO - allennlp.nn.initializers -    scalar_mix.feats.scalar_parameters.7
2021-05-12 00:43:12,653 - INFO - allennlp.nn.initializers -    scalar_mix.feats.scalar_parameters.8
2021-05-12 00:43:12,653 - INFO - allennlp.nn.initializers -    scalar_mix.feats.scalar_parameters.9
2021-05-12 00:43:12,653 - INFO - allennlp.nn.initializers -    scalar_mix.lemmas.gamma
2021-05-12 00:43:12,653 - INFO - allennlp.nn.initializers -    scalar_mix.lemmas.scalar_parameters.0
2021-05-12 00:43:12,653 - INFO - allennlp.nn.initializers -    scalar_mix.lemmas.scalar_parameters.1
2021-05-12 00:43:12,653 - INFO - allennlp.nn.initializers -    scalar_mix.lemmas.scalar_parameters.10
2021-05-12 00:43:12,653 - INFO - allennlp.nn.initializers -    scalar_mix.lemmas.scalar_parameters.11
2021-05-12 00:43:12,653 - INFO - allennlp.nn.initializers -    scalar_mix.lemmas.scalar_parameters.2
2021-05-12 00:43:12,653 - INFO - allennlp.nn.initializers -    scalar_mix.lemmas.scalar_parameters.3
2021-05-12 00:43:12,653 - INFO - allennlp.nn.initializers -    scalar_mix.lemmas.scalar_parameters.4
2021-05-12 00:43:12,654 - INFO - allennlp.nn.initializers -    scalar_mix.lemmas.scalar_parameters.5
2021-05-12 00:43:12,654 - INFO - allennlp.nn.initializers -    scalar_mix.lemmas.scalar_parameters.6
2021-05-12 00:43:12,654 - INFO - allennlp.nn.initializers -    scalar_mix.lemmas.scalar_parameters.7
2021-05-12 00:43:12,654 - INFO - allennlp.nn.initializers -    scalar_mix.lemmas.scalar_parameters.8
2021-05-12 00:43:12,654 - INFO - allennlp.nn.initializers -    scalar_mix.lemmas.scalar_parameters.9
2021-05-12 00:43:12,654 - INFO - allennlp.nn.initializers -    scalar_mix.upos.gamma
2021-05-12 00:43:12,654 - INFO - allennlp.nn.initializers -    scalar_mix.upos.scalar_parameters.0
2021-05-12 00:43:12,654 - INFO - allennlp.nn.initializers -    scalar_mix.upos.scalar_parameters.1
2021-05-12 00:43:12,654 - INFO - allennlp.nn.initializers -    scalar_mix.upos.scalar_parameters.10
2021-05-12 00:43:12,654 - INFO - allennlp.nn.initializers -    scalar_mix.upos.scalar_parameters.11
2021-05-12 00:43:12,654 - INFO - allennlp.nn.initializers -    scalar_mix.upos.scalar_parameters.2
2021-05-12 00:43:12,654 - INFO - allennlp.nn.initializers -    scalar_mix.upos.scalar_parameters.3
2021-05-12 00:43:12,654 - INFO - allennlp.nn.initializers -    scalar_mix.upos.scalar_parameters.4
2021-05-12 00:43:12,654 - INFO - allennlp.nn.initializers -    scalar_mix.upos.scalar_parameters.5
2021-05-12 00:43:12,654 - INFO - allennlp.nn.initializers -    scalar_mix.upos.scalar_parameters.6
2021-05-12 00:43:12,654 - INFO - allennlp.nn.initializers -    scalar_mix.upos.scalar_parameters.7
2021-05-12 00:43:12,654 - INFO - allennlp.nn.initializers -    scalar_mix.upos.scalar_parameters.8
2021-05-12 00:43:12,654 - INFO - allennlp.nn.initializers -    scalar_mix.upos.scalar_parameters.9
2021-05-12 00:43:12,655 - INFO - allennlp.nn.initializers -    text_field_embedder.token_embedder_bert.bert_model.embeddings.LayerNorm.bias
2021-05-12 00:43:12,655 - INFO - allennlp.nn.initializers -    text_field_embedder.token_embedder_bert.bert_model.embeddings.LayerNorm.weight
2021-05-12 00:43:12,655 - INFO - allennlp.nn.initializers -    text_field_embedder.token_embedder_bert.bert_model.embeddings.position_embeddings.weight
2021-05-12 00:43:12,655 - INFO - allennlp.nn.initializers -    text_field_embedder.token_embedder_bert.bert_model.embeddings.token_type_embeddings.weight
2021-05-12 00:43:12,655 - INFO - allennlp.nn.initializers -    text_field_embedder.token_embedder_bert.bert_model.embeddings.word_embeddings.weight
2021-05-12 00:43:12,655 - INFO - allennlp.nn.initializers -    text_field_embedder.token_embedder_bert.bert_model.encoder.layer.0.attention.output.LayerNorm.bias
2021-05-12 00:43:12,655 - INFO - allennlp.nn.initializers -    text_field_embedder.token_embedder_bert.bert_model.encoder.layer.0.attention.output.LayerNorm.weight
2021-05-12 00:43:12,655 - INFO - allennlp.nn.initializers -    text_field_embedder.token_embedder_bert.bert_model.encoder.layer.0.attention.output.dense.bias
2021-05-12 00:43:12,655 - INFO - allennlp.nn.initializers -    text_field_embedder.token_embedder_bert.bert_model.encoder.layer.0.attention.output.dense.weight
2021-05-12 00:43:12,655 - INFO - allennlp.nn.initializers -    text_field_embedder.token_embedder_bert.bert_model.encoder.layer.0.attention.self.key.bias
2021-05-12 00:43:12,655 - INFO - allennlp.nn.initializers -    text_field_embedder.token_embedder_bert.bert_model.encoder.layer.0.attention.self.key.weight
2021-05-12 00:43:12,655 - INFO - allennlp.nn.initializers -    text_field_embedder.token_embedder_bert.bert_model.encoder.layer.0.attention.self.query.bias
2021-05-12 00:43:12,655 - INFO - allennlp.nn.initializers -    text_field_embedder.token_embedder_bert.bert_model.encoder.layer.0.attention.self.query.weight
2021-05-12 00:43:12,655 - INFO - allennlp.nn.initializers -    text_field_embedder.token_embedder_bert.bert_model.encoder.layer.0.attention.self.value.bias
2021-05-12 00:43:12,655 - INFO - allennlp.nn.initializers -    text_field_embedder.token_embedder_bert.bert_model.encoder.layer.0.attention.self.value.weight
2021-05-12 00:43:12,655 - INFO - allennlp.nn.initializers -    text_field_embedder.token_embedder_bert.bert_model.encoder.layer.0.intermediate.dense.bias
2021-05-12 00:43:12,655 - INFO - allennlp.nn.initializers -    text_field_embedder.token_embedder_bert.bert_model.encoder.layer.0.intermediate.dense.weight
2021-05-12 00:43:12,655 - INFO - allennlp.nn.initializers -    text_field_embedder.token_embedder_bert.bert_model.encoder.layer.0.output.LayerNorm.bias
2021-05-12 00:43:12,655 - INFO - allennlp.nn.initializers -    text_field_embedder.token_embedder_bert.bert_model.encoder.layer.0.output.LayerNorm.weight
2021-05-12 00:43:12,656 - INFO - allennlp.nn.initializers -    text_field_embedder.token_embedder_bert.bert_model.encoder.layer.0.output.dense.bias
2021-05-12 00:43:12,656 - INFO - allennlp.nn.initializers -    text_field_embedder.token_embedder_bert.bert_model.encoder.layer.0.output.dense.weight
2021-05-12 00:43:12,656 - INFO - allennlp.nn.initializers -    text_field_embedder.token_embedder_bert.bert_model.encoder.layer.1.attention.output.LayerNorm.bias
2021-05-12 00:43:12,656 - INFO - allennlp.nn.initializers -    text_field_embedder.token_embedder_bert.bert_model.encoder.layer.1.attention.output.LayerNorm.weight
2021-05-12 00:43:12,656 - INFO - allennlp.nn.initializers -    text_field_embedder.token_embedder_bert.bert_model.encoder.layer.1.attention.output.dense.bias
2021-05-12 00:43:12,656 - INFO - allennlp.nn.initializers -    text_field_embedder.token_embedder_bert.bert_model.encoder.layer.1.attention.output.dense.weight
2021-05-12 00:43:12,656 - INFO - allennlp.nn.initializers -    text_field_embedder.token_embedder_bert.bert_model.encoder.layer.1.attention.self.key.bias
2021-05-12 00:43:12,656 - INFO - allennlp.nn.initializers -    text_field_embedder.token_embedder_bert.bert_model.encoder.layer.1.attention.self.key.weight
2021-05-12 00:43:12,656 - INFO - allennlp.nn.initializers -    text_field_embedder.token_embedder_bert.bert_model.encoder.layer.1.attention.self.query.bias
2021-05-12 00:43:12,656 - INFO - allennlp.nn.initializers -    text_field_embedder.token_embedder_bert.bert_model.encoder.layer.1.attention.self.query.weight
2021-05-12 00:43:12,656 - INFO - allennlp.nn.initializers -    text_field_embedder.token_embedder_bert.bert_model.encoder.layer.1.attention.self.value.bias
2021-05-12 00:43:12,656 - INFO - allennlp.nn.initializers -    text_field_embedder.token_embedder_bert.bert_model.encoder.layer.1.attention.self.value.weight
2021-05-12 00:43:12,656 - INFO - allennlp.nn.initializers -    text_field_embedder.token_embedder_bert.bert_model.encoder.layer.1.intermediate.dense.bias
2021-05-12 00:43:12,656 - INFO - allennlp.nn.initializers -    text_field_embedder.token_embedder_bert.bert_model.encoder.layer.1.intermediate.dense.weight
2021-05-12 00:43:12,656 - INFO - allennlp.nn.initializers -    text_field_embedder.token_embedder_bert.bert_model.encoder.layer.1.output.LayerNorm.bias
2021-05-12 00:43:12,656 - INFO - allennlp.nn.initializers -    text_field_embedder.token_embedder_bert.bert_model.encoder.layer.1.output.LayerNorm.weight
2021-05-12 00:43:12,656 - INFO - allennlp.nn.initializers -    text_field_embedder.token_embedder_bert.bert_model.encoder.layer.1.output.dense.bias
2021-05-12 00:43:12,656 - INFO - allennlp.nn.initializers -    text_field_embedder.token_embedder_bert.bert_model.encoder.layer.1.output.dense.weight
2021-05-12 00:43:12,656 - INFO - allennlp.nn.initializers -    text_field_embedder.token_embedder_bert.bert_model.encoder.layer.10.attention.output.LayerNorm.bias
2021-05-12 00:43:12,657 - INFO - allennlp.nn.initializers -    text_field_embedder.token_embedder_bert.bert_model.encoder.layer.10.attention.output.LayerNorm.weight
2021-05-12 00:43:12,657 - INFO - allennlp.nn.initializers -    text_field_embedder.token_embedder_bert.bert_model.encoder.layer.10.attention.output.dense.bias
2021-05-12 00:43:12,657 - INFO - allennlp.nn.initializers -    text_field_embedder.token_embedder_bert.bert_model.encoder.layer.10.attention.output.dense.weight
2021-05-12 00:43:12,657 - INFO - allennlp.nn.initializers -    text_field_embedder.token_embedder_bert.bert_model.encoder.layer.10.attention.self.key.bias
2021-05-12 00:43:12,657 - INFO - allennlp.nn.initializers -    text_field_embedder.token_embedder_bert.bert_model.encoder.layer.10.attention.self.key.weight
2021-05-12 00:43:12,657 - INFO - allennlp.nn.initializers -    text_field_embedder.token_embedder_bert.bert_model.encoder.layer.10.attention.self.query.bias
2021-05-12 00:43:12,657 - INFO - allennlp.nn.initializers -    text_field_embedder.token_embedder_bert.bert_model.encoder.layer.10.attention.self.query.weight
2021-05-12 00:43:12,657 - INFO - allennlp.nn.initializers -    text_field_embedder.token_embedder_bert.bert_model.encoder.layer.10.attention.self.value.bias
2021-05-12 00:43:12,657 - INFO - allennlp.nn.initializers -    text_field_embedder.token_embedder_bert.bert_model.encoder.layer.10.attention.self.value.weight
2021-05-12 00:43:12,657 - INFO - allennlp.nn.initializers -    text_field_embedder.token_embedder_bert.bert_model.encoder.layer.10.intermediate.dense.bias
2021-05-12 00:43:12,657 - INFO - allennlp.nn.initializers -    text_field_embedder.token_embedder_bert.bert_model.encoder.layer.10.intermediate.dense.weight
2021-05-12 00:43:12,657 - INFO - allennlp.nn.initializers -    text_field_embedder.token_embedder_bert.bert_model.encoder.layer.10.output.LayerNorm.bias
2021-05-12 00:43:12,657 - INFO - allennlp.nn.initializers -    text_field_embedder.token_embedder_bert.bert_model.encoder.layer.10.output.LayerNorm.weight
2021-05-12 00:43:12,657 - INFO - allennlp.nn.initializers -    text_field_embedder.token_embedder_bert.bert_model.encoder.layer.10.output.dense.bias
2021-05-12 00:43:12,657 - INFO - allennlp.nn.initializers -    text_field_embedder.token_embedder_bert.bert_model.encoder.layer.10.output.dense.weight
2021-05-12 00:43:12,657 - INFO - allennlp.nn.initializers -    text_field_embedder.token_embedder_bert.bert_model.encoder.layer.11.attention.output.LayerNorm.bias
2021-05-12 00:43:12,657 - INFO - allennlp.nn.initializers -    text_field_embedder.token_embedder_bert.bert_model.encoder.layer.11.attention.output.LayerNorm.weight
2021-05-12 00:43:12,657 - INFO - allennlp.nn.initializers -    text_field_embedder.token_embedder_bert.bert_model.encoder.layer.11.attention.output.dense.bias
2021-05-12 00:43:12,658 - INFO - allennlp.nn.initializers -    text_field_embedder.token_embedder_bert.bert_model.encoder.layer.11.attention.output.dense.weight
2021-05-12 00:43:12,658 - INFO - allennlp.nn.initializers -    text_field_embedder.token_embedder_bert.bert_model.encoder.layer.11.attention.self.key.bias
2021-05-12 00:43:12,658 - INFO - allennlp.nn.initializers -    text_field_embedder.token_embedder_bert.bert_model.encoder.layer.11.attention.self.key.weight
2021-05-12 00:43:12,658 - INFO - allennlp.nn.initializers -    text_field_embedder.token_embedder_bert.bert_model.encoder.layer.11.attention.self.query.bias
2021-05-12 00:43:12,658 - INFO - allennlp.nn.initializers -    text_field_embedder.token_embedder_bert.bert_model.encoder.layer.11.attention.self.query.weight
2021-05-12 00:43:12,658 - INFO - allennlp.nn.initializers -    text_field_embedder.token_embedder_bert.bert_model.encoder.layer.11.attention.self.value.bias
2021-05-12 00:43:12,658 - INFO - allennlp.nn.initializers -    text_field_embedder.token_embedder_bert.bert_model.encoder.layer.11.attention.self.value.weight
2021-05-12 00:43:12,658 - INFO - allennlp.nn.initializers -    text_field_embedder.token_embedder_bert.bert_model.encoder.layer.11.intermediate.dense.bias
2021-05-12 00:43:12,658 - INFO - allennlp.nn.initializers -    text_field_embedder.token_embedder_bert.bert_model.encoder.layer.11.intermediate.dense.weight
2021-05-12 00:43:12,658 - INFO - allennlp.nn.initializers -    text_field_embedder.token_embedder_bert.bert_model.encoder.layer.11.output.LayerNorm.bias
2021-05-12 00:43:12,658 - INFO - allennlp.nn.initializers -    text_field_embedder.token_embedder_bert.bert_model.encoder.layer.11.output.LayerNorm.weight
2021-05-12 00:43:12,658 - INFO - allennlp.nn.initializers -    text_field_embedder.token_embedder_bert.bert_model.encoder.layer.11.output.dense.bias
2021-05-12 00:43:12,658 - INFO - allennlp.nn.initializers -    text_field_embedder.token_embedder_bert.bert_model.encoder.layer.11.output.dense.weight
2021-05-12 00:43:12,658 - INFO - allennlp.nn.initializers -    text_field_embedder.token_embedder_bert.bert_model.encoder.layer.2.attention.output.LayerNorm.bias
2021-05-12 00:43:12,658 - INFO - allennlp.nn.initializers -    text_field_embedder.token_embedder_bert.bert_model.encoder.layer.2.attention.output.LayerNorm.weight
2021-05-12 00:43:12,658 - INFO - allennlp.nn.initializers -    text_field_embedder.token_embedder_bert.bert_model.encoder.layer.2.attention.output.dense.bias
2021-05-12 00:43:12,658 - INFO - allennlp.nn.initializers -    text_field_embedder.token_embedder_bert.bert_model.encoder.layer.2.attention.output.dense.weight
2021-05-12 00:43:12,658 - INFO - allennlp.nn.initializers -    text_field_embedder.token_embedder_bert.bert_model.encoder.layer.2.attention.self.key.bias
2021-05-12 00:43:12,659 - INFO - allennlp.nn.initializers -    text_field_embedder.token_embedder_bert.bert_model.encoder.layer.2.attention.self.key.weight
2021-05-12 00:43:12,659 - INFO - allennlp.nn.initializers -    text_field_embedder.token_embedder_bert.bert_model.encoder.layer.2.attention.self.query.bias
2021-05-12 00:43:12,659 - INFO - allennlp.nn.initializers -    text_field_embedder.token_embedder_bert.bert_model.encoder.layer.2.attention.self.query.weight
2021-05-12 00:43:12,659 - INFO - allennlp.nn.initializers -    text_field_embedder.token_embedder_bert.bert_model.encoder.layer.2.attention.self.value.bias
2021-05-12 00:43:12,659 - INFO - allennlp.nn.initializers -    text_field_embedder.token_embedder_bert.bert_model.encoder.layer.2.attention.self.value.weight
2021-05-12 00:43:12,659 - INFO - allennlp.nn.initializers -    text_field_embedder.token_embedder_bert.bert_model.encoder.layer.2.intermediate.dense.bias
2021-05-12 00:43:12,659 - INFO - allennlp.nn.initializers -    text_field_embedder.token_embedder_bert.bert_model.encoder.layer.2.intermediate.dense.weight
2021-05-12 00:43:12,659 - INFO - allennlp.nn.initializers -    text_field_embedder.token_embedder_bert.bert_model.encoder.layer.2.output.LayerNorm.bias
2021-05-12 00:43:12,659 - INFO - allennlp.nn.initializers -    text_field_embedder.token_embedder_bert.bert_model.encoder.layer.2.output.LayerNorm.weight
2021-05-12 00:43:12,659 - INFO - allennlp.nn.initializers -    text_field_embedder.token_embedder_bert.bert_model.encoder.layer.2.output.dense.bias
2021-05-12 00:43:12,659 - INFO - allennlp.nn.initializers -    text_field_embedder.token_embedder_bert.bert_model.encoder.layer.2.output.dense.weight
2021-05-12 00:43:12,659 - INFO - allennlp.nn.initializers -    text_field_embedder.token_embedder_bert.bert_model.encoder.layer.3.attention.output.LayerNorm.bias
2021-05-12 00:43:12,659 - INFO - allennlp.nn.initializers -    text_field_embedder.token_embedder_bert.bert_model.encoder.layer.3.attention.output.LayerNorm.weight
2021-05-12 00:43:12,659 - INFO - allennlp.nn.initializers -    text_field_embedder.token_embedder_bert.bert_model.encoder.layer.3.attention.output.dense.bias
2021-05-12 00:43:12,659 - INFO - allennlp.nn.initializers -    text_field_embedder.token_embedder_bert.bert_model.encoder.layer.3.attention.output.dense.weight
2021-05-12 00:43:12,659 - INFO - allennlp.nn.initializers -    text_field_embedder.token_embedder_bert.bert_model.encoder.layer.3.attention.self.key.bias
2021-05-12 00:43:12,659 - INFO - allennlp.nn.initializers -    text_field_embedder.token_embedder_bert.bert_model.encoder.layer.3.attention.self.key.weight
2021-05-12 00:43:12,659 - INFO - allennlp.nn.initializers -    text_field_embedder.token_embedder_bert.bert_model.encoder.layer.3.attention.self.query.bias
2021-05-12 00:43:12,659 - INFO - allennlp.nn.initializers -    text_field_embedder.token_embedder_bert.bert_model.encoder.layer.3.attention.self.query.weight
2021-05-12 00:43:12,660 - INFO - allennlp.nn.initializers -    text_field_embedder.token_embedder_bert.bert_model.encoder.layer.3.attention.self.value.bias
2021-05-12 00:43:12,660 - INFO - allennlp.nn.initializers -    text_field_embedder.token_embedder_bert.bert_model.encoder.layer.3.attention.self.value.weight
2021-05-12 00:43:12,660 - INFO - allennlp.nn.initializers -    text_field_embedder.token_embedder_bert.bert_model.encoder.layer.3.intermediate.dense.bias
2021-05-12 00:43:12,660 - INFO - allennlp.nn.initializers -    text_field_embedder.token_embedder_bert.bert_model.encoder.layer.3.intermediate.dense.weight
2021-05-12 00:43:12,660 - INFO - allennlp.nn.initializers -    text_field_embedder.token_embedder_bert.bert_model.encoder.layer.3.output.LayerNorm.bias
2021-05-12 00:43:12,660 - INFO - allennlp.nn.initializers -    text_field_embedder.token_embedder_bert.bert_model.encoder.layer.3.output.LayerNorm.weight
2021-05-12 00:43:12,660 - INFO - allennlp.nn.initializers -    text_field_embedder.token_embedder_bert.bert_model.encoder.layer.3.output.dense.bias
2021-05-12 00:43:12,660 - INFO - allennlp.nn.initializers -    text_field_embedder.token_embedder_bert.bert_model.encoder.layer.3.output.dense.weight
2021-05-12 00:43:12,660 - INFO - allennlp.nn.initializers -    text_field_embedder.token_embedder_bert.bert_model.encoder.layer.4.attention.output.LayerNorm.bias
2021-05-12 00:43:12,660 - INFO - allennlp.nn.initializers -    text_field_embedder.token_embedder_bert.bert_model.encoder.layer.4.attention.output.LayerNorm.weight
2021-05-12 00:43:12,660 - INFO - allennlp.nn.initializers -    text_field_embedder.token_embedder_bert.bert_model.encoder.layer.4.attention.output.dense.bias
2021-05-12 00:43:12,660 - INFO - allennlp.nn.initializers -    text_field_embedder.token_embedder_bert.bert_model.encoder.layer.4.attention.output.dense.weight
2021-05-12 00:43:12,660 - INFO - allennlp.nn.initializers -    text_field_embedder.token_embedder_bert.bert_model.encoder.layer.4.attention.self.key.bias
2021-05-12 00:43:12,660 - INFO - allennlp.nn.initializers -    text_field_embedder.token_embedder_bert.bert_model.encoder.layer.4.attention.self.key.weight
2021-05-12 00:43:12,660 - INFO - allennlp.nn.initializers -    text_field_embedder.token_embedder_bert.bert_model.encoder.layer.4.attention.self.query.bias
2021-05-12 00:43:12,660 - INFO - allennlp.nn.initializers -    text_field_embedder.token_embedder_bert.bert_model.encoder.layer.4.attention.self.query.weight
2021-05-12 00:43:12,660 - INFO - allennlp.nn.initializers -    text_field_embedder.token_embedder_bert.bert_model.encoder.layer.4.attention.self.value.bias
2021-05-12 00:43:12,660 - INFO - allennlp.nn.initializers -    text_field_embedder.token_embedder_bert.bert_model.encoder.layer.4.attention.self.value.weight
2021-05-12 00:43:12,661 - INFO - allennlp.nn.initializers -    text_field_embedder.token_embedder_bert.bert_model.encoder.layer.4.intermediate.dense.bias
2021-05-12 00:43:12,661 - INFO - allennlp.nn.initializers -    text_field_embedder.token_embedder_bert.bert_model.encoder.layer.4.intermediate.dense.weight
2021-05-12 00:43:12,661 - INFO - allennlp.nn.initializers -    text_field_embedder.token_embedder_bert.bert_model.encoder.layer.4.output.LayerNorm.bias
2021-05-12 00:43:12,661 - INFO - allennlp.nn.initializers -    text_field_embedder.token_embedder_bert.bert_model.encoder.layer.4.output.LayerNorm.weight
2021-05-12 00:43:12,661 - INFO - allennlp.nn.initializers -    text_field_embedder.token_embedder_bert.bert_model.encoder.layer.4.output.dense.bias
2021-05-12 00:43:12,661 - INFO - allennlp.nn.initializers -    text_field_embedder.token_embedder_bert.bert_model.encoder.layer.4.output.dense.weight
2021-05-12 00:43:12,661 - INFO - allennlp.nn.initializers -    text_field_embedder.token_embedder_bert.bert_model.encoder.layer.5.attention.output.LayerNorm.bias
2021-05-12 00:43:12,661 - INFO - allennlp.nn.initializers -    text_field_embedder.token_embedder_bert.bert_model.encoder.layer.5.attention.output.LayerNorm.weight
2021-05-12 00:43:12,661 - INFO - allennlp.nn.initializers -    text_field_embedder.token_embedder_bert.bert_model.encoder.layer.5.attention.output.dense.bias
2021-05-12 00:43:12,661 - INFO - allennlp.nn.initializers -    text_field_embedder.token_embedder_bert.bert_model.encoder.layer.5.attention.output.dense.weight
2021-05-12 00:43:12,661 - INFO - allennlp.nn.initializers -    text_field_embedder.token_embedder_bert.bert_model.encoder.layer.5.attention.self.key.bias
2021-05-12 00:43:12,661 - INFO - allennlp.nn.initializers -    text_field_embedder.token_embedder_bert.bert_model.encoder.layer.5.attention.self.key.weight
2021-05-12 00:43:12,661 - INFO - allennlp.nn.initializers -    text_field_embedder.token_embedder_bert.bert_model.encoder.layer.5.attention.self.query.bias
2021-05-12 00:43:12,661 - INFO - allennlp.nn.initializers -    text_field_embedder.token_embedder_bert.bert_model.encoder.layer.5.attention.self.query.weight
2021-05-12 00:43:12,661 - INFO - allennlp.nn.initializers -    text_field_embedder.token_embedder_bert.bert_model.encoder.layer.5.attention.self.value.bias
2021-05-12 00:43:12,661 - INFO - allennlp.nn.initializers -    text_field_embedder.token_embedder_bert.bert_model.encoder.layer.5.attention.self.value.weight
2021-05-12 00:43:12,661 - INFO - allennlp.nn.initializers -    text_field_embedder.token_embedder_bert.bert_model.encoder.layer.5.intermediate.dense.bias
2021-05-12 00:43:12,661 - INFO - allennlp.nn.initializers -    text_field_embedder.token_embedder_bert.bert_model.encoder.layer.5.intermediate.dense.weight
2021-05-12 00:43:12,661 - INFO - allennlp.nn.initializers -    text_field_embedder.token_embedder_bert.bert_model.encoder.layer.5.output.LayerNorm.bias
2021-05-12 00:43:12,662 - INFO - allennlp.nn.initializers -    text_field_embedder.token_embedder_bert.bert_model.encoder.layer.5.output.LayerNorm.weight
2021-05-12 00:43:12,662 - INFO - allennlp.nn.initializers -    text_field_embedder.token_embedder_bert.bert_model.encoder.layer.5.output.dense.bias
2021-05-12 00:43:12,662 - INFO - allennlp.nn.initializers -    text_field_embedder.token_embedder_bert.bert_model.encoder.layer.5.output.dense.weight
2021-05-12 00:43:12,662 - INFO - allennlp.nn.initializers -    text_field_embedder.token_embedder_bert.bert_model.encoder.layer.6.attention.output.LayerNorm.bias
2021-05-12 00:43:12,662 - INFO - allennlp.nn.initializers -    text_field_embedder.token_embedder_bert.bert_model.encoder.layer.6.attention.output.LayerNorm.weight
2021-05-12 00:43:12,662 - INFO - allennlp.nn.initializers -    text_field_embedder.token_embedder_bert.bert_model.encoder.layer.6.attention.output.dense.bias
2021-05-12 00:43:12,662 - INFO - allennlp.nn.initializers -    text_field_embedder.token_embedder_bert.bert_model.encoder.layer.6.attention.output.dense.weight
2021-05-12 00:43:12,662 - INFO - allennlp.nn.initializers -    text_field_embedder.token_embedder_bert.bert_model.encoder.layer.6.attention.self.key.bias
2021-05-12 00:43:12,662 - INFO - allennlp.nn.initializers -    text_field_embedder.token_embedder_bert.bert_model.encoder.layer.6.attention.self.key.weight
2021-05-12 00:43:12,662 - INFO - allennlp.nn.initializers -    text_field_embedder.token_embedder_bert.bert_model.encoder.layer.6.attention.self.query.bias
2021-05-12 00:43:12,662 - INFO - allennlp.nn.initializers -    text_field_embedder.token_embedder_bert.bert_model.encoder.layer.6.attention.self.query.weight
2021-05-12 00:43:12,662 - INFO - allennlp.nn.initializers -    text_field_embedder.token_embedder_bert.bert_model.encoder.layer.6.attention.self.value.bias
2021-05-12 00:43:12,662 - INFO - allennlp.nn.initializers -    text_field_embedder.token_embedder_bert.bert_model.encoder.layer.6.attention.self.value.weight
2021-05-12 00:43:12,662 - INFO - allennlp.nn.initializers -    text_field_embedder.token_embedder_bert.bert_model.encoder.layer.6.intermediate.dense.bias
2021-05-12 00:43:12,662 - INFO - allennlp.nn.initializers -    text_field_embedder.token_embedder_bert.bert_model.encoder.layer.6.intermediate.dense.weight
2021-05-12 00:43:12,662 - INFO - allennlp.nn.initializers -    text_field_embedder.token_embedder_bert.bert_model.encoder.layer.6.output.LayerNorm.bias
2021-05-12 00:43:12,662 - INFO - allennlp.nn.initializers -    text_field_embedder.token_embedder_bert.bert_model.encoder.layer.6.output.LayerNorm.weight
2021-05-12 00:43:12,662 - INFO - allennlp.nn.initializers -    text_field_embedder.token_embedder_bert.bert_model.encoder.layer.6.output.dense.bias
2021-05-12 00:43:12,663 - INFO - allennlp.nn.initializers -    text_field_embedder.token_embedder_bert.bert_model.encoder.layer.6.output.dense.weight
2021-05-12 00:43:12,663 - INFO - allennlp.nn.initializers -    text_field_embedder.token_embedder_bert.bert_model.encoder.layer.7.attention.output.LayerNorm.bias
2021-05-12 00:43:12,663 - INFO - allennlp.nn.initializers -    text_field_embedder.token_embedder_bert.bert_model.encoder.layer.7.attention.output.LayerNorm.weight
2021-05-12 00:43:12,663 - INFO - allennlp.nn.initializers -    text_field_embedder.token_embedder_bert.bert_model.encoder.layer.7.attention.output.dense.bias
2021-05-12 00:43:12,663 - INFO - allennlp.nn.initializers -    text_field_embedder.token_embedder_bert.bert_model.encoder.layer.7.attention.output.dense.weight
2021-05-12 00:43:12,663 - INFO - allennlp.nn.initializers -    text_field_embedder.token_embedder_bert.bert_model.encoder.layer.7.attention.self.key.bias
2021-05-12 00:43:12,663 - INFO - allennlp.nn.initializers -    text_field_embedder.token_embedder_bert.bert_model.encoder.layer.7.attention.self.key.weight
2021-05-12 00:43:12,663 - INFO - allennlp.nn.initializers -    text_field_embedder.token_embedder_bert.bert_model.encoder.layer.7.attention.self.query.bias
2021-05-12 00:43:12,663 - INFO - allennlp.nn.initializers -    text_field_embedder.token_embedder_bert.bert_model.encoder.layer.7.attention.self.query.weight
2021-05-12 00:43:12,663 - INFO - allennlp.nn.initializers -    text_field_embedder.token_embedder_bert.bert_model.encoder.layer.7.attention.self.value.bias
2021-05-12 00:43:12,663 - INFO - allennlp.nn.initializers -    text_field_embedder.token_embedder_bert.bert_model.encoder.layer.7.attention.self.value.weight
2021-05-12 00:43:12,663 - INFO - allennlp.nn.initializers -    text_field_embedder.token_embedder_bert.bert_model.encoder.layer.7.intermediate.dense.bias
2021-05-12 00:43:12,663 - INFO - allennlp.nn.initializers -    text_field_embedder.token_embedder_bert.bert_model.encoder.layer.7.intermediate.dense.weight
2021-05-12 00:43:12,663 - INFO - allennlp.nn.initializers -    text_field_embedder.token_embedder_bert.bert_model.encoder.layer.7.output.LayerNorm.bias
2021-05-12 00:43:12,663 - INFO - allennlp.nn.initializers -    text_field_embedder.token_embedder_bert.bert_model.encoder.layer.7.output.LayerNorm.weight
2021-05-12 00:43:12,663 - INFO - allennlp.nn.initializers -    text_field_embedder.token_embedder_bert.bert_model.encoder.layer.7.output.dense.bias
2021-05-12 00:43:12,663 - INFO - allennlp.nn.initializers -    text_field_embedder.token_embedder_bert.bert_model.encoder.layer.7.output.dense.weight
2021-05-12 00:43:12,663 - INFO - allennlp.nn.initializers -    text_field_embedder.token_embedder_bert.bert_model.encoder.layer.8.attention.output.LayerNorm.bias
2021-05-12 00:43:12,663 - INFO - allennlp.nn.initializers -    text_field_embedder.token_embedder_bert.bert_model.encoder.layer.8.attention.output.LayerNorm.weight
2021-05-12 00:43:12,664 - INFO - allennlp.nn.initializers -    text_field_embedder.token_embedder_bert.bert_model.encoder.layer.8.attention.output.dense.bias
2021-05-12 00:43:12,664 - INFO - allennlp.nn.initializers -    text_field_embedder.token_embedder_bert.bert_model.encoder.layer.8.attention.output.dense.weight
2021-05-12 00:43:12,664 - INFO - allennlp.nn.initializers -    text_field_embedder.token_embedder_bert.bert_model.encoder.layer.8.attention.self.key.bias
2021-05-12 00:43:12,664 - INFO - allennlp.nn.initializers -    text_field_embedder.token_embedder_bert.bert_model.encoder.layer.8.attention.self.key.weight
2021-05-12 00:43:12,664 - INFO - allennlp.nn.initializers -    text_field_embedder.token_embedder_bert.bert_model.encoder.layer.8.attention.self.query.bias
2021-05-12 00:43:12,664 - INFO - allennlp.nn.initializers -    text_field_embedder.token_embedder_bert.bert_model.encoder.layer.8.attention.self.query.weight
2021-05-12 00:43:12,664 - INFO - allennlp.nn.initializers -    text_field_embedder.token_embedder_bert.bert_model.encoder.layer.8.attention.self.value.bias
2021-05-12 00:43:12,664 - INFO - allennlp.nn.initializers -    text_field_embedder.token_embedder_bert.bert_model.encoder.layer.8.attention.self.value.weight
2021-05-12 00:43:12,664 - INFO - allennlp.nn.initializers -    text_field_embedder.token_embedder_bert.bert_model.encoder.layer.8.intermediate.dense.bias
2021-05-12 00:43:12,664 - INFO - allennlp.nn.initializers -    text_field_embedder.token_embedder_bert.bert_model.encoder.layer.8.intermediate.dense.weight
2021-05-12 00:43:12,664 - INFO - allennlp.nn.initializers -    text_field_embedder.token_embedder_bert.bert_model.encoder.layer.8.output.LayerNorm.bias
2021-05-12 00:43:12,664 - INFO - allennlp.nn.initializers -    text_field_embedder.token_embedder_bert.bert_model.encoder.layer.8.output.LayerNorm.weight
2021-05-12 00:43:12,664 - INFO - allennlp.nn.initializers -    text_field_embedder.token_embedder_bert.bert_model.encoder.layer.8.output.dense.bias
2021-05-12 00:43:12,664 - INFO - allennlp.nn.initializers -    text_field_embedder.token_embedder_bert.bert_model.encoder.layer.8.output.dense.weight
2021-05-12 00:43:12,664 - INFO - allennlp.nn.initializers -    text_field_embedder.token_embedder_bert.bert_model.encoder.layer.9.attention.output.LayerNorm.bias
2021-05-12 00:43:12,664 - INFO - allennlp.nn.initializers -    text_field_embedder.token_embedder_bert.bert_model.encoder.layer.9.attention.output.LayerNorm.weight
2021-05-12 00:43:12,664 - INFO - allennlp.nn.initializers -    text_field_embedder.token_embedder_bert.bert_model.encoder.layer.9.attention.output.dense.bias
2021-05-12 00:43:12,664 - INFO - allennlp.nn.initializers -    text_field_embedder.token_embedder_bert.bert_model.encoder.layer.9.attention.output.dense.weight
2021-05-12 00:43:12,665 - INFO - allennlp.nn.initializers -    text_field_embedder.token_embedder_bert.bert_model.encoder.layer.9.attention.self.key.bias
2021-05-12 00:43:12,665 - INFO - allennlp.nn.initializers -    text_field_embedder.token_embedder_bert.bert_model.encoder.layer.9.attention.self.key.weight
2021-05-12 00:43:12,665 - INFO - allennlp.nn.initializers -    text_field_embedder.token_embedder_bert.bert_model.encoder.layer.9.attention.self.query.bias
2021-05-12 00:43:12,665 - INFO - allennlp.nn.initializers -    text_field_embedder.token_embedder_bert.bert_model.encoder.layer.9.attention.self.query.weight
2021-05-12 00:43:12,665 - INFO - allennlp.nn.initializers -    text_field_embedder.token_embedder_bert.bert_model.encoder.layer.9.attention.self.value.bias
2021-05-12 00:43:12,665 - INFO - allennlp.nn.initializers -    text_field_embedder.token_embedder_bert.bert_model.encoder.layer.9.attention.self.value.weight
2021-05-12 00:43:12,665 - INFO - allennlp.nn.initializers -    text_field_embedder.token_embedder_bert.bert_model.encoder.layer.9.intermediate.dense.bias
2021-05-12 00:43:12,665 - INFO - allennlp.nn.initializers -    text_field_embedder.token_embedder_bert.bert_model.encoder.layer.9.intermediate.dense.weight
2021-05-12 00:43:12,665 - INFO - allennlp.nn.initializers -    text_field_embedder.token_embedder_bert.bert_model.encoder.layer.9.output.LayerNorm.bias
2021-05-12 00:43:12,665 - INFO - allennlp.nn.initializers -    text_field_embedder.token_embedder_bert.bert_model.encoder.layer.9.output.LayerNorm.weight
2021-05-12 00:43:12,665 - INFO - allennlp.nn.initializers -    text_field_embedder.token_embedder_bert.bert_model.encoder.layer.9.output.dense.bias
2021-05-12 00:43:12,665 - INFO - allennlp.nn.initializers -    text_field_embedder.token_embedder_bert.bert_model.encoder.layer.9.output.dense.weight
2021-05-12 00:43:12,665 - INFO - allennlp.nn.initializers -    text_field_embedder.token_embedder_bert.bert_model.pooler.dense.bias
2021-05-12 00:43:12,665 - INFO - allennlp.nn.initializers -    text_field_embedder.token_embedder_bert.bert_model.pooler.dense.weight
2021-05-12 00:43:12,671 - INFO - udify.models.udify_model - Total number of parameters: 198563643
2021-05-12 00:43:12,671 - INFO - udify.models.udify_model - Total number of trainable parameters: 198563643
2021-05-12 00:43:13,520 - INFO - allennlp.models.archival - removing temporary unarchived model dir at /scratch/tmp0theyu4w
reading instances: 0it [00:00, ?it/s]
2021-05-12 00:43:13,612 - INFO - udify.dataset_readers.universal_dependencies - Reading UD instances from conllu dataset at: data/ud-treebanks-v2.3/UD_English-EWT/en_ewt-ud-dev.conllu
reading instances: 1743it [00:02, 870.84it/s]
reading instances: 2002it [00:02, 899.66it/s]
2021-05-12 00:43:15,973 - WARNING - allennlp.models.model - Encountered the logits key in the model's return dictionary which couldn't be split by the batch size. Key will be ignored.
2021-05-12 00:43:15,973 - WARNING - allennlp.models.model - Encountered the class_probabilities key in the model's return dictionary which couldn't be split by the batch size. Key will be ignored.
2021-05-12 00:44:43,809 - INFO - udify.util - Metric     | Correct   |      Gold | Predicted | Aligned
2021-05-12 00:44:43,810 - INFO - udify.util - -----------+-----------+-----------+-----------+-----------
2021-05-12 00:44:43,810 - INFO - udify.util - Tokens     |    100.00 |    100.00 |    100.00 |
2021-05-12 00:44:43,810 - INFO - udify.util - Sentences  |    100.00 |    100.00 |    100.00 |
2021-05-12 00:44:43,810 - INFO - udify.util - Words      |    100.00 |    100.00 |    100.00 |
2021-05-12 00:44:43,810 - INFO - udify.util - UPOS       |      0.00 |      0.00 |      0.00 |      0.00
2021-05-12 00:44:43,810 - INFO - udify.util - XPOS       |      0.00 |      0.00 |      0.00 |      0.00
2021-05-12 00:44:43,810 - INFO - udify.util - UFeats     |     33.80 |     33.80 |     33.80 |     33.80
2021-05-12 00:44:43,810 - INFO - udify.util - AllTags    |      0.00 |      0.00 |      0.00 |      0.00
2021-05-12 00:44:43,810 - INFO - udify.util - Lemmas     |      0.00 |      0.00 |      0.00 |      0.00
2021-05-12 00:44:43,811 - INFO - udify.util - UAS        |     88.82 |     88.82 |     88.82 |     88.82
2021-05-12 00:44:43,811 - INFO - udify.util - LAS        |     85.33 |     85.33 |     85.33 |     85.33
2021-05-12 00:44:43,811 - INFO - udify.util - CLAS       |     82.29 |     81.68 |     81.98 |     81.68
2021-05-12 00:44:43,811 - INFO - udify.util - MLAS       |      0.00 |      0.00 |      0.00 |      0.00
2021-05-12 00:44:43,811 - INFO - udify.util - BLEX       |      0.00 |      0.00 |      0.00 |      0.00
2021-05-12 00:44:43,812 - INFO - allennlp.models.archival - loading archive file logs/bert_finetune_en/2021.05.12_00.22.24/model.tar.gz
2021-05-12 00:44:43,812 - INFO - allennlp.models.archival - extracting archive file logs/bert_finetune_en/2021.05.12_00.22.24/model.tar.gz to temp dir /scratch/tmp6fq8e6ui
2021-05-12 00:44:54,128 - INFO - allennlp.common.params - dataset_reader.type = udify_universal_dependencies
2021-05-12 00:44:54,128 - INFO - allennlp.common.params - dataset_reader.token_indexers.bert.type = udify-bert-pretrained
2021-05-12 00:44:54,128 - INFO - allennlp.common.params - dataset_reader.token_indexers.bert.pretrained_model = config/archive/bert-base-multilingual-cased/vocab.txt
2021-05-12 00:44:54,129 - INFO - allennlp.common.params - dataset_reader.token_indexers.bert.use_starting_offsets = True
2021-05-12 00:44:54,129 - INFO - allennlp.common.params - dataset_reader.token_indexers.bert.do_lowercase = False
2021-05-12 00:44:54,129 - INFO - allennlp.common.params - dataset_reader.token_indexers.bert.never_lowercase = None
2021-05-12 00:44:54,129 - INFO - allennlp.common.params - dataset_reader.token_indexers.bert.max_pieces = 512
2021-05-12 00:44:54,129 - INFO - allennlp.common.params - dataset_reader.token_indexers.bert.truncate_long_sequences = False
Calling BertTokenizer.from_pretrained() with the path to a single file or url is deprecated
2021-05-12 00:44:54,360 - INFO - allennlp.common.params - dataset_reader.token_indexers.tokens.type = single_id
2021-05-12 00:44:54,360 - INFO - allennlp.common.params - dataset_reader.token_indexers.tokens.namespace = tokens
2021-05-12 00:44:54,361 - INFO - allennlp.common.params - dataset_reader.token_indexers.tokens.lowercase_tokens = True
2021-05-12 00:44:54,361 - INFO - allennlp.common.params - dataset_reader.token_indexers.tokens.start_tokens = None
2021-05-12 00:44:54,361 - INFO - allennlp.common.params - dataset_reader.token_indexers.tokens.end_tokens = None
2021-05-12 00:44:54,361 - INFO - allennlp.common.params - dataset_reader.token_indexers.tokens.feature_name = text
2021-05-12 00:44:54,361 - INFO - allennlp.common.params - dataset_reader.token_indexers.tokens.default_value = THIS IS A REALLY UNLIKELY VALUE THAT HAS TO BE A STRING
2021-05-12 00:44:54,361 - INFO - allennlp.common.params - dataset_reader.token_indexers.tokens.token_min_padding_length = 0
2021-05-12 00:44:54,361 - INFO - allennlp.common.params - dataset_reader.lazy = False
2021-05-12 00:44:54,361 - INFO - allennlp.common.params - dataset_reader.type = udify_universal_dependencies
2021-05-12 00:44:54,362 - INFO - allennlp.common.params - dataset_reader.token_indexers.bert.type = udify-bert-pretrained
2021-05-12 00:44:54,362 - INFO - allennlp.common.params - dataset_reader.token_indexers.bert.pretrained_model = config/archive/bert-base-multilingual-cased/vocab.txt
2021-05-12 00:44:54,362 - INFO - allennlp.common.params - dataset_reader.token_indexers.bert.use_starting_offsets = True
2021-05-12 00:44:54,362 - INFO - allennlp.common.params - dataset_reader.token_indexers.bert.do_lowercase = False
2021-05-12 00:44:54,362 - INFO - allennlp.common.params - dataset_reader.token_indexers.bert.never_lowercase = None
2021-05-12 00:44:54,362 - INFO - allennlp.common.params - dataset_reader.token_indexers.bert.max_pieces = 512
2021-05-12 00:44:54,362 - INFO - allennlp.common.params - dataset_reader.token_indexers.bert.truncate_long_sequences = False
Calling BertTokenizer.from_pretrained() with the path to a single file or url is deprecated
2021-05-12 00:44:54,580 - INFO - allennlp.common.params - dataset_reader.token_indexers.tokens.type = single_id
2021-05-12 00:44:54,580 - INFO - allennlp.common.params - dataset_reader.token_indexers.tokens.namespace = tokens
2021-05-12 00:44:54,580 - INFO - allennlp.common.params - dataset_reader.token_indexers.tokens.lowercase_tokens = True
2021-05-12 00:44:54,580 - INFO - allennlp.common.params - dataset_reader.token_indexers.tokens.start_tokens = None
2021-05-12 00:44:54,580 - INFO - allennlp.common.params - dataset_reader.token_indexers.tokens.end_tokens = None
2021-05-12 00:44:54,581 - INFO - allennlp.common.params - dataset_reader.token_indexers.tokens.feature_name = text
2021-05-12 00:44:54,581 - INFO - allennlp.common.params - dataset_reader.token_indexers.tokens.default_value = THIS IS A REALLY UNLIKELY VALUE THAT HAS TO BE A STRING
2021-05-12 00:44:54,581 - INFO - allennlp.common.params - dataset_reader.token_indexers.tokens.token_min_padding_length = 0
2021-05-12 00:44:54,581 - INFO - allennlp.common.params - dataset_reader.lazy = False
2021-05-12 00:44:54,581 - INFO - allennlp.common.params - vocabulary.type = from_files
2021-05-12 00:44:54,581 - INFO - allennlp.data.vocabulary - Loading token dictionary from /scratch/tmp6fq8e6ui/vocabulary.
2021-05-12 00:44:54,582 - INFO - filelock - Lock 22387740382016 acquired on /scratch/tmp6fq8e6ui/vocabulary/.lock
2021-05-12 00:44:55,958 - INFO - filelock - Lock 22387740382016 released on /scratch/tmp6fq8e6ui/vocabulary/.lock
2021-05-12 00:44:55,959 - INFO - allennlp.common.params - model.type = udify_model
2021-05-12 00:44:55,959 - INFO - allennlp.common.params - model.tasks = ['deps']
2021-05-12 00:44:55,960 - INFO - allennlp.common.params - model.text_field_embedder.type = udify_embedder
2021-05-12 00:44:55,960 - INFO - allennlp.common.params - model.text_field_embedder.allow_unmatched_keys = True
2021-05-12 00:44:55,960 - INFO - allennlp.common.params - model.text_field_embedder.dropout = 0.5
2021-05-12 00:44:55,960 - INFO - allennlp.common.params - model.text_field_embedder.output_dim = None
2021-05-12 00:44:55,960 - INFO - allennlp.common.params - model.text_field_embedder.sum_embeddings = None
2021-05-12 00:44:55,960 - INFO - allennlp.common.params - model.text_field_embedder.token_embedders.bert.type = udify-bert-pretrained
2021-05-12 00:44:55,960 - INFO - allennlp.common.params - model.text_field_embedder.token_embedders.bert.pretrained_model = bert-base-multilingual-cased
2021-05-12 00:44:55,961 - INFO - allennlp.common.params - model.text_field_embedder.token_embedders.bert.requires_grad = True
2021-05-12 00:44:55,961 - INFO - allennlp.common.params - model.text_field_embedder.token_embedders.bert.dropout = 0.15
2021-05-12 00:44:55,961 - INFO - allennlp.common.params - model.text_field_embedder.token_embedders.bert.layer_dropout = 0.1
2021-05-12 00:44:55,961 - INFO - allennlp.common.params - model.text_field_embedder.token_embedders.bert.combine_layers = all
2021-05-12 00:45:02,867 - INFO - allennlp.common.params - model.encoder.type = pass_through
2021-05-12 00:45:02,867 - INFO - allennlp.common.params - model.encoder.input_dim = 768
2021-05-12 00:45:02,868 - INFO - allennlp.common.params - model.decoders.deps.type = udify_dependency_decoder
2021-05-12 00:45:02,868 - INFO - allennlp.common.params - model.decoders.deps.encoder.type = pass_through
2021-05-12 00:45:02,868 - INFO - allennlp.common.params - model.decoders.deps.encoder.input_dim = 768
2021-05-12 00:45:02,868 - INFO - allennlp.common.params - model.decoders.deps.tag_representation_dim = 256
2021-05-12 00:45:02,869 - INFO - allennlp.common.params - model.decoders.deps.arc_representation_dim = 768
2021-05-12 00:45:02,869 - INFO - allennlp.common.params - model.decoders.deps.pos_embed_dim = None
2021-05-12 00:45:02,869 - INFO - allennlp.common.params - model.decoders.deps.tag_feedforward = None
2021-05-12 00:45:02,869 - INFO - allennlp.common.params - model.decoders.deps.arc_feedforward = None
2021-05-12 00:45:02,869 - INFO - allennlp.common.params - model.decoders.deps.use_mst_decoding_for_validation = True
2021-05-12 00:45:02,869 - INFO - allennlp.common.params - model.decoders.deps.dropout = 0.5
2021-05-12 00:45:02,869 - INFO - allennlp.common.params - model.decoders.deps.initializer = <allennlp.nn.initializers.InitializerApplicator object at 0x145ec1431850>
2021-05-12 00:45:02,869 - INFO - allennlp.common.params - model.decoders.deps.regularizer = None
2021-05-12 00:45:02,982 - INFO - udify.models.dependency_decoder - Found POS tags corresponding to the following punctuation : {}. Ignoring words with these POS tags for evaluation.
2021-05-12 00:45:02,982 - INFO - allennlp.nn.initializers - Initializing parameters
2021-05-12 00:45:02,983 - INFO - allennlp.nn.initializers - Done initializing parameters; the following parameters are using their default initialization from their code
2021-05-12 00:45:02,983 - INFO - allennlp.nn.initializers -    _head_sentinel
2021-05-12 00:45:02,983 - INFO - allennlp.nn.initializers -    arc_attention._bias
2021-05-12 00:45:02,983 - INFO - allennlp.nn.initializers -    arc_attention._weight_matrix
2021-05-12 00:45:02,983 - INFO - allennlp.nn.initializers -    child_arc_feedforward._linear_layers.0.bias
2021-05-12 00:45:02,983 - INFO - allennlp.nn.initializers -    child_arc_feedforward._linear_layers.0.weight
2021-05-12 00:45:02,983 - INFO - allennlp.nn.initializers -    child_tag_feedforward._linear_layers.0.bias
2021-05-12 00:45:02,983 - INFO - allennlp.nn.initializers -    child_tag_feedforward._linear_layers.0.weight
2021-05-12 00:45:02,983 - INFO - allennlp.nn.initializers -    head_arc_feedforward._linear_layers.0.bias
2021-05-12 00:45:02,983 - INFO - allennlp.nn.initializers -    head_arc_feedforward._linear_layers.0.weight
2021-05-12 00:45:02,983 - INFO - allennlp.nn.initializers -    head_tag_feedforward._linear_layers.0.bias
2021-05-12 00:45:02,983 - INFO - allennlp.nn.initializers -    head_tag_feedforward._linear_layers.0.weight
2021-05-12 00:45:02,983 - INFO - allennlp.nn.initializers -    tag_bilinear.bias
2021-05-12 00:45:02,984 - INFO - allennlp.nn.initializers -    tag_bilinear.weight
2021-05-12 00:45:02,984 - INFO - allennlp.common.params - model.decoders.feats.type = udify_tag_decoder
2021-05-12 00:45:02,984 - INFO - allennlp.common.params - model.decoders.feats.task = feats
2021-05-12 00:45:02,984 - INFO - allennlp.common.params - model.decoders.feats.encoder.type = pass_through
2021-05-12 00:45:02,985 - INFO - allennlp.common.params - model.decoders.feats.encoder.input_dim = 768
2021-05-12 00:45:02,985 - INFO - allennlp.common.params - model.decoders.feats.label_smoothing = 0.03
2021-05-12 00:45:02,985 - INFO - allennlp.common.params - model.decoders.feats.dropout = 0.5
2021-05-12 00:45:02,985 - INFO - allennlp.common.params - model.decoders.feats.adaptive = True
2021-05-12 00:45:02,985 - INFO - allennlp.common.params - model.decoders.feats.features = None
2021-05-12 00:45:02,985 - INFO - allennlp.common.params - model.decoders.feats.initializer = <allennlp.nn.initializers.InitializerApplicator object at 0x145ec1431df0>
2021-05-12 00:45:02,985 - INFO - allennlp.common.params - model.decoders.feats.regularizer = None
2021-05-12 00:45:02,999 - INFO - allennlp.nn.initializers - Initializing parameters
2021-05-12 00:45:02,999 - INFO - allennlp.nn.initializers - Done initializing parameters; the following parameters are using their default initialization from their code
2021-05-12 00:45:02,999 - INFO - allennlp.nn.initializers -    task_output.head.weight
2021-05-12 00:45:02,999 - INFO - allennlp.nn.initializers -    task_output.tail.0.0.weight
2021-05-12 00:45:02,999 - INFO - allennlp.nn.initializers -    task_output.tail.0.1.weight
2021-05-12 00:45:02,999 - INFO - allennlp.nn.initializers -    task_output.tail.1.0.weight
2021-05-12 00:45:02,999 - INFO - allennlp.nn.initializers -    task_output.tail.1.1.weight
2021-05-12 00:45:02,999 - INFO - allennlp.common.params - model.decoders.lemmas.type = udify_tag_decoder
2021-05-12 00:45:03,000 - INFO - allennlp.common.params - model.decoders.lemmas.task = lemmas
2021-05-12 00:45:03,000 - INFO - allennlp.common.params - model.decoders.lemmas.encoder.type = pass_through
2021-05-12 00:45:03,000 - INFO - allennlp.common.params - model.decoders.lemmas.encoder.input_dim = 768
2021-05-12 00:45:03,000 - INFO - allennlp.common.params - model.decoders.lemmas.label_smoothing = 0.03
2021-05-12 00:45:03,000 - INFO - allennlp.common.params - model.decoders.lemmas.dropout = 0.5
2021-05-12 00:45:03,001 - INFO - allennlp.common.params - model.decoders.lemmas.adaptive = True
2021-05-12 00:45:03,001 - INFO - allennlp.common.params - model.decoders.lemmas.features = None
2021-05-12 00:45:03,001 - INFO - allennlp.common.params - model.decoders.lemmas.initializer = <allennlp.nn.initializers.InitializerApplicator object at 0x145ec1431df0>
2021-05-12 00:45:03,001 - INFO - allennlp.common.params - model.decoders.lemmas.regularizer = None
2021-05-12 00:45:03,098 - INFO - allennlp.nn.initializers - Initializing parameters
2021-05-12 00:45:03,098 - INFO - allennlp.nn.initializers - Done initializing parameters; the following parameters are using their default initialization from their code
2021-05-12 00:45:03,098 - INFO - allennlp.nn.initializers -    task_output.head.weight
2021-05-12 00:45:03,098 - INFO - allennlp.nn.initializers -    task_output.tail.0.0.weight
2021-05-12 00:45:03,098 - INFO - allennlp.nn.initializers -    task_output.tail.0.1.weight
2021-05-12 00:45:03,098 - INFO - allennlp.nn.initializers -    task_output.tail.1.0.weight
2021-05-12 00:45:03,098 - INFO - allennlp.nn.initializers -    task_output.tail.1.1.weight
2021-05-12 00:45:03,098 - INFO - allennlp.common.params - model.decoders.upos.type = udify_tag_decoder
2021-05-12 00:45:03,099 - INFO - allennlp.common.params - model.decoders.upos.task = upos
2021-05-12 00:45:03,099 - INFO - allennlp.common.params - model.decoders.upos.encoder.type = pass_through
2021-05-12 00:45:03,099 - INFO - allennlp.common.params - model.decoders.upos.encoder.input_dim = 768
2021-05-12 00:45:03,099 - INFO - allennlp.common.params - model.decoders.upos.label_smoothing = 0.03
2021-05-12 00:45:03,099 - INFO - allennlp.common.params - model.decoders.upos.dropout = 0.5
2021-05-12 00:45:03,099 - INFO - allennlp.common.params - model.decoders.upos.adaptive = False
2021-05-12 00:45:03,100 - INFO - allennlp.common.params - model.decoders.upos.features = None
2021-05-12 00:45:03,100 - INFO - allennlp.common.params - model.decoders.upos.initializer = <allennlp.nn.initializers.InitializerApplicator object at 0x145ec1431df0>
2021-05-12 00:45:03,100 - INFO - allennlp.common.params - model.decoders.upos.regularizer = None
2021-05-12 00:45:03,100 - INFO - allennlp.nn.initializers - Initializing parameters
2021-05-12 00:45:03,100 - INFO - allennlp.nn.initializers - Done initializing parameters; the following parameters are using their default initialization from their code
2021-05-12 00:45:03,100 - INFO - allennlp.nn.initializers -    task_output._module.bias
2021-05-12 00:45:03,100 - INFO - allennlp.nn.initializers -    task_output._module.weight
2021-05-12 00:45:03,101 - INFO - allennlp.common.params - model.pretrained_model = bert-base-multilingual-cased
2021-05-12 00:45:03,101 - INFO - allennlp.common.params - model.post_encoder_embedder = None
2021-05-12 00:45:03,101 - INFO - allennlp.common.params - model.dropout = 0.5
2021-05-12 00:45:03,101 - INFO - allennlp.common.params - model.word_dropout = 0.2
2021-05-12 00:45:03,101 - INFO - allennlp.common.params - model.mix_embedding = 12
2021-05-12 00:45:03,101 - INFO - allennlp.common.params - model.layer_dropout = 0.1
2021-05-12 00:45:03,101 - INFO - allennlp.common.params - model.initializer = <allennlp.nn.initializers.InitializerApplicator object at 0x145ec14394f0>
2021-05-12 00:45:03,101 - INFO - allennlp.common.params - model.regularizer = None
2021-05-12 00:45:03,636 - INFO - allennlp.nn.initializers - Initializing parameters
2021-05-12 00:45:03,639 - INFO - allennlp.nn.initializers - Done initializing parameters; the following parameters are using their default initialization from their code
2021-05-12 00:45:03,639 - INFO - allennlp.nn.initializers -    decoders.deps._head_sentinel
2021-05-12 00:45:03,640 - INFO - allennlp.nn.initializers -    decoders.deps.arc_attention._bias
2021-05-12 00:45:03,640 - INFO - allennlp.nn.initializers -    decoders.deps.arc_attention._weight_matrix
2021-05-12 00:45:03,640 - INFO - allennlp.nn.initializers -    decoders.deps.child_arc_feedforward._linear_layers.0.bias
2021-05-12 00:45:03,640 - INFO - allennlp.nn.initializers -    decoders.deps.child_arc_feedforward._linear_layers.0.weight
2021-05-12 00:45:03,640 - INFO - allennlp.nn.initializers -    decoders.deps.child_tag_feedforward._linear_layers.0.bias
2021-05-12 00:45:03,640 - INFO - allennlp.nn.initializers -    decoders.deps.child_tag_feedforward._linear_layers.0.weight
2021-05-12 00:45:03,640 - INFO - allennlp.nn.initializers -    decoders.deps.head_arc_feedforward._linear_layers.0.bias
2021-05-12 00:45:03,640 - INFO - allennlp.nn.initializers -    decoders.deps.head_arc_feedforward._linear_layers.0.weight
2021-05-12 00:45:03,640 - INFO - allennlp.nn.initializers -    decoders.deps.head_tag_feedforward._linear_layers.0.bias
2021-05-12 00:45:03,640 - INFO - allennlp.nn.initializers -    decoders.deps.head_tag_feedforward._linear_layers.0.weight
2021-05-12 00:45:03,640 - INFO - allennlp.nn.initializers -    decoders.deps.tag_bilinear.bias
2021-05-12 00:45:03,640 - INFO - allennlp.nn.initializers -    decoders.deps.tag_bilinear.weight
2021-05-12 00:45:03,640 - INFO - allennlp.nn.initializers -    decoders.feats.task_output.head.weight
2021-05-12 00:45:03,640 - INFO - allennlp.nn.initializers -    decoders.feats.task_output.tail.0.0.weight
2021-05-12 00:45:03,640 - INFO - allennlp.nn.initializers -    decoders.feats.task_output.tail.0.1.weight
2021-05-12 00:45:03,640 - INFO - allennlp.nn.initializers -    decoders.feats.task_output.tail.1.0.weight
2021-05-12 00:45:03,640 - INFO - allennlp.nn.initializers -    decoders.feats.task_output.tail.1.1.weight
2021-05-12 00:45:03,640 - INFO - allennlp.nn.initializers -    decoders.lemmas.task_output.head.weight
2021-05-12 00:45:03,641 - INFO - allennlp.nn.initializers -    decoders.lemmas.task_output.tail.0.0.weight
2021-05-12 00:45:03,641 - INFO - allennlp.nn.initializers -    decoders.lemmas.task_output.tail.0.1.weight
2021-05-12 00:45:03,641 - INFO - allennlp.nn.initializers -    decoders.lemmas.task_output.tail.1.0.weight
2021-05-12 00:45:03,641 - INFO - allennlp.nn.initializers -    decoders.lemmas.task_output.tail.1.1.weight
2021-05-12 00:45:03,641 - INFO - allennlp.nn.initializers -    decoders.upos.task_output._module.bias
2021-05-12 00:45:03,641 - INFO - allennlp.nn.initializers -    decoders.upos.task_output._module.weight
2021-05-12 00:45:03,641 - INFO - allennlp.nn.initializers -    scalar_mix.deps.gamma
2021-05-12 00:45:03,641 - INFO - allennlp.nn.initializers -    scalar_mix.deps.scalar_parameters.0
2021-05-12 00:45:03,641 - INFO - allennlp.nn.initializers -    scalar_mix.deps.scalar_parameters.1
2021-05-12 00:45:03,641 - INFO - allennlp.nn.initializers -    scalar_mix.deps.scalar_parameters.10
2021-05-12 00:45:03,641 - INFO - allennlp.nn.initializers -    scalar_mix.deps.scalar_parameters.11
2021-05-12 00:45:03,641 - INFO - allennlp.nn.initializers -    scalar_mix.deps.scalar_parameters.2
2021-05-12 00:45:03,641 - INFO - allennlp.nn.initializers -    scalar_mix.deps.scalar_parameters.3
2021-05-12 00:45:03,641 - INFO - allennlp.nn.initializers -    scalar_mix.deps.scalar_parameters.4
2021-05-12 00:45:03,641 - INFO - allennlp.nn.initializers -    scalar_mix.deps.scalar_parameters.5
2021-05-12 00:45:03,641 - INFO - allennlp.nn.initializers -    scalar_mix.deps.scalar_parameters.6
2021-05-12 00:45:03,641 - INFO - allennlp.nn.initializers -    scalar_mix.deps.scalar_parameters.7
2021-05-12 00:45:03,641 - INFO - allennlp.nn.initializers -    scalar_mix.deps.scalar_parameters.8
2021-05-12 00:45:03,642 - INFO - allennlp.nn.initializers -    scalar_mix.deps.scalar_parameters.9
2021-05-12 00:45:03,642 - INFO - allennlp.nn.initializers -    scalar_mix.feats.gamma
2021-05-12 00:45:03,642 - INFO - allennlp.nn.initializers -    scalar_mix.feats.scalar_parameters.0
2021-05-12 00:45:03,642 - INFO - allennlp.nn.initializers -    scalar_mix.feats.scalar_parameters.1
2021-05-12 00:45:03,642 - INFO - allennlp.nn.initializers -    scalar_mix.feats.scalar_parameters.10
2021-05-12 00:45:03,642 - INFO - allennlp.nn.initializers -    scalar_mix.feats.scalar_parameters.11
2021-05-12 00:45:03,642 - INFO - allennlp.nn.initializers -    scalar_mix.feats.scalar_parameters.2
2021-05-12 00:45:03,642 - INFO - allennlp.nn.initializers -    scalar_mix.feats.scalar_parameters.3
2021-05-12 00:45:03,642 - INFO - allennlp.nn.initializers -    scalar_mix.feats.scalar_parameters.4
2021-05-12 00:45:03,642 - INFO - allennlp.nn.initializers -    scalar_mix.feats.scalar_parameters.5
2021-05-12 00:45:03,642 - INFO - allennlp.nn.initializers -    scalar_mix.feats.scalar_parameters.6
2021-05-12 00:45:03,642 - INFO - allennlp.nn.initializers -    scalar_mix.feats.scalar_parameters.7
2021-05-12 00:45:03,642 - INFO - allennlp.nn.initializers -    scalar_mix.feats.scalar_parameters.8
2021-05-12 00:45:03,642 - INFO - allennlp.nn.initializers -    scalar_mix.feats.scalar_parameters.9
2021-05-12 00:45:03,642 - INFO - allennlp.nn.initializers -    scalar_mix.lemmas.gamma
2021-05-12 00:45:03,642 - INFO - allennlp.nn.initializers -    scalar_mix.lemmas.scalar_parameters.0
2021-05-12 00:45:03,642 - INFO - allennlp.nn.initializers -    scalar_mix.lemmas.scalar_parameters.1
2021-05-12 00:45:03,642 - INFO - allennlp.nn.initializers -    scalar_mix.lemmas.scalar_parameters.10
2021-05-12 00:45:03,642 - INFO - allennlp.nn.initializers -    scalar_mix.lemmas.scalar_parameters.11
2021-05-12 00:45:03,643 - INFO - allennlp.nn.initializers -    scalar_mix.lemmas.scalar_parameters.2
2021-05-12 00:45:03,643 - INFO - allennlp.nn.initializers -    scalar_mix.lemmas.scalar_parameters.3
2021-05-12 00:45:03,643 - INFO - allennlp.nn.initializers -    scalar_mix.lemmas.scalar_parameters.4
2021-05-12 00:45:03,643 - INFO - allennlp.nn.initializers -    scalar_mix.lemmas.scalar_parameters.5
2021-05-12 00:45:03,643 - INFO - allennlp.nn.initializers -    scalar_mix.lemmas.scalar_parameters.6
2021-05-12 00:45:03,643 - INFO - allennlp.nn.initializers -    scalar_mix.lemmas.scalar_parameters.7
2021-05-12 00:45:03,643 - INFO - allennlp.nn.initializers -    scalar_mix.lemmas.scalar_parameters.8
2021-05-12 00:45:03,643 - INFO - allennlp.nn.initializers -    scalar_mix.lemmas.scalar_parameters.9
2021-05-12 00:45:03,643 - INFO - allennlp.nn.initializers -    scalar_mix.upos.gamma
2021-05-12 00:45:03,643 - INFO - allennlp.nn.initializers -    scalar_mix.upos.scalar_parameters.0
2021-05-12 00:45:03,643 - INFO - allennlp.nn.initializers -    scalar_mix.upos.scalar_parameters.1
2021-05-12 00:45:03,643 - INFO - allennlp.nn.initializers -    scalar_mix.upos.scalar_parameters.10
2021-05-12 00:45:03,643 - INFO - allennlp.nn.initializers -    scalar_mix.upos.scalar_parameters.11
2021-05-12 00:45:03,643 - INFO - allennlp.nn.initializers -    scalar_mix.upos.scalar_parameters.2
2021-05-12 00:45:03,643 - INFO - allennlp.nn.initializers -    scalar_mix.upos.scalar_parameters.3
2021-05-12 00:45:03,643 - INFO - allennlp.nn.initializers -    scalar_mix.upos.scalar_parameters.4
2021-05-12 00:45:03,643 - INFO - allennlp.nn.initializers -    scalar_mix.upos.scalar_parameters.5
2021-05-12 00:45:03,643 - INFO - allennlp.nn.initializers -    scalar_mix.upos.scalar_parameters.6
2021-05-12 00:45:03,644 - INFO - allennlp.nn.initializers -    scalar_mix.upos.scalar_parameters.7
2021-05-12 00:45:03,644 - INFO - allennlp.nn.initializers -    scalar_mix.upos.scalar_parameters.8
2021-05-12 00:45:03,644 - INFO - allennlp.nn.initializers -    scalar_mix.upos.scalar_parameters.9
2021-05-12 00:45:03,644 - INFO - allennlp.nn.initializers -    text_field_embedder.token_embedder_bert.bert_model.embeddings.LayerNorm.bias
2021-05-12 00:45:03,644 - INFO - allennlp.nn.initializers -    text_field_embedder.token_embedder_bert.bert_model.embeddings.LayerNorm.weight
2021-05-12 00:45:03,644 - INFO - allennlp.nn.initializers -    text_field_embedder.token_embedder_bert.bert_model.embeddings.position_embeddings.weight
2021-05-12 00:45:03,644 - INFO - allennlp.nn.initializers -    text_field_embedder.token_embedder_bert.bert_model.embeddings.token_type_embeddings.weight
2021-05-12 00:45:03,644 - INFO - allennlp.nn.initializers -    text_field_embedder.token_embedder_bert.bert_model.embeddings.word_embeddings.weight
2021-05-12 00:45:03,644 - INFO - allennlp.nn.initializers -    text_field_embedder.token_embedder_bert.bert_model.encoder.layer.0.attention.output.LayerNorm.bias
2021-05-12 00:45:03,644 - INFO - allennlp.nn.initializers -    text_field_embedder.token_embedder_bert.bert_model.encoder.layer.0.attention.output.LayerNorm.weight
2021-05-12 00:45:03,644 - INFO - allennlp.nn.initializers -    text_field_embedder.token_embedder_bert.bert_model.encoder.layer.0.attention.output.dense.bias
2021-05-12 00:45:03,644 - INFO - allennlp.nn.initializers -    text_field_embedder.token_embedder_bert.bert_model.encoder.layer.0.attention.output.dense.weight
2021-05-12 00:45:03,644 - INFO - allennlp.nn.initializers -    text_field_embedder.token_embedder_bert.bert_model.encoder.layer.0.attention.self.key.bias
2021-05-12 00:45:03,644 - INFO - allennlp.nn.initializers -    text_field_embedder.token_embedder_bert.bert_model.encoder.layer.0.attention.self.key.weight
2021-05-12 00:45:03,644 - INFO - allennlp.nn.initializers -    text_field_embedder.token_embedder_bert.bert_model.encoder.layer.0.attention.self.query.bias
2021-05-12 00:45:03,644 - INFO - allennlp.nn.initializers -    text_field_embedder.token_embedder_bert.bert_model.encoder.layer.0.attention.self.query.weight
2021-05-12 00:45:03,644 - INFO - allennlp.nn.initializers -    text_field_embedder.token_embedder_bert.bert_model.encoder.layer.0.attention.self.value.bias
2021-05-12 00:45:03,644 - INFO - allennlp.nn.initializers -    text_field_embedder.token_embedder_bert.bert_model.encoder.layer.0.attention.self.value.weight
2021-05-12 00:45:03,644 - INFO - allennlp.nn.initializers -    text_field_embedder.token_embedder_bert.bert_model.encoder.layer.0.intermediate.dense.bias
2021-05-12 00:45:03,645 - INFO - allennlp.nn.initializers -    text_field_embedder.token_embedder_bert.bert_model.encoder.layer.0.intermediate.dense.weight
2021-05-12 00:45:03,645 - INFO - allennlp.nn.initializers -    text_field_embedder.token_embedder_bert.bert_model.encoder.layer.0.output.LayerNorm.bias
2021-05-12 00:45:03,645 - INFO - allennlp.nn.initializers -    text_field_embedder.token_embedder_bert.bert_model.encoder.layer.0.output.LayerNorm.weight
2021-05-12 00:45:03,645 - INFO - allennlp.nn.initializers -    text_field_embedder.token_embedder_bert.bert_model.encoder.layer.0.output.dense.bias
2021-05-12 00:45:03,645 - INFO - allennlp.nn.initializers -    text_field_embedder.token_embedder_bert.bert_model.encoder.layer.0.output.dense.weight
2021-05-12 00:45:03,645 - INFO - allennlp.nn.initializers -    text_field_embedder.token_embedder_bert.bert_model.encoder.layer.1.attention.output.LayerNorm.bias
2021-05-12 00:45:03,645 - INFO - allennlp.nn.initializers -    text_field_embedder.token_embedder_bert.bert_model.encoder.layer.1.attention.output.LayerNorm.weight
2021-05-12 00:45:03,645 - INFO - allennlp.nn.initializers -    text_field_embedder.token_embedder_bert.bert_model.encoder.layer.1.attention.output.dense.bias
2021-05-12 00:45:03,645 - INFO - allennlp.nn.initializers -    text_field_embedder.token_embedder_bert.bert_model.encoder.layer.1.attention.output.dense.weight
2021-05-12 00:45:03,645 - INFO - allennlp.nn.initializers -    text_field_embedder.token_embedder_bert.bert_model.encoder.layer.1.attention.self.key.bias
2021-05-12 00:45:03,645 - INFO - allennlp.nn.initializers -    text_field_embedder.token_embedder_bert.bert_model.encoder.layer.1.attention.self.key.weight
2021-05-12 00:45:03,645 - INFO - allennlp.nn.initializers -    text_field_embedder.token_embedder_bert.bert_model.encoder.layer.1.attention.self.query.bias
2021-05-12 00:45:03,645 - INFO - allennlp.nn.initializers -    text_field_embedder.token_embedder_bert.bert_model.encoder.layer.1.attention.self.query.weight
2021-05-12 00:45:03,645 - INFO - allennlp.nn.initializers -    text_field_embedder.token_embedder_bert.bert_model.encoder.layer.1.attention.self.value.bias
2021-05-12 00:45:03,645 - INFO - allennlp.nn.initializers -    text_field_embedder.token_embedder_bert.bert_model.encoder.layer.1.attention.self.value.weight
2021-05-12 00:45:03,645 - INFO - allennlp.nn.initializers -    text_field_embedder.token_embedder_bert.bert_model.encoder.layer.1.intermediate.dense.bias
2021-05-12 00:45:03,645 - INFO - allennlp.nn.initializers -    text_field_embedder.token_embedder_bert.bert_model.encoder.layer.1.intermediate.dense.weight
2021-05-12 00:45:03,645 - INFO - allennlp.nn.initializers -    text_field_embedder.token_embedder_bert.bert_model.encoder.layer.1.output.LayerNorm.bias
2021-05-12 00:45:03,646 - INFO - allennlp.nn.initializers -    text_field_embedder.token_embedder_bert.bert_model.encoder.layer.1.output.LayerNorm.weight
2021-05-12 00:45:03,646 - INFO - allennlp.nn.initializers -    text_field_embedder.token_embedder_bert.bert_model.encoder.layer.1.output.dense.bias
2021-05-12 00:45:03,646 - INFO - allennlp.nn.initializers -    text_field_embedder.token_embedder_bert.bert_model.encoder.layer.1.output.dense.weight
2021-05-12 00:45:03,646 - INFO - allennlp.nn.initializers -    text_field_embedder.token_embedder_bert.bert_model.encoder.layer.10.attention.output.LayerNorm.bias
2021-05-12 00:45:03,646 - INFO - allennlp.nn.initializers -    text_field_embedder.token_embedder_bert.bert_model.encoder.layer.10.attention.output.LayerNorm.weight
2021-05-12 00:45:03,646 - INFO - allennlp.nn.initializers -    text_field_embedder.token_embedder_bert.bert_model.encoder.layer.10.attention.output.dense.bias
2021-05-12 00:45:03,646 - INFO - allennlp.nn.initializers -    text_field_embedder.token_embedder_bert.bert_model.encoder.layer.10.attention.output.dense.weight
2021-05-12 00:45:03,646 - INFO - allennlp.nn.initializers -    text_field_embedder.token_embedder_bert.bert_model.encoder.layer.10.attention.self.key.bias
2021-05-12 00:45:03,646 - INFO - allennlp.nn.initializers -    text_field_embedder.token_embedder_bert.bert_model.encoder.layer.10.attention.self.key.weight
2021-05-12 00:45:03,646 - INFO - allennlp.nn.initializers -    text_field_embedder.token_embedder_bert.bert_model.encoder.layer.10.attention.self.query.bias
2021-05-12 00:45:03,646 - INFO - allennlp.nn.initializers -    text_field_embedder.token_embedder_bert.bert_model.encoder.layer.10.attention.self.query.weight
2021-05-12 00:45:03,646 - INFO - allennlp.nn.initializers -    text_field_embedder.token_embedder_bert.bert_model.encoder.layer.10.attention.self.value.bias
2021-05-12 00:45:03,646 - INFO - allennlp.nn.initializers -    text_field_embedder.token_embedder_bert.bert_model.encoder.layer.10.attention.self.value.weight
2021-05-12 00:45:03,646 - INFO - allennlp.nn.initializers -    text_field_embedder.token_embedder_bert.bert_model.encoder.layer.10.intermediate.dense.bias
2021-05-12 00:45:03,646 - INFO - allennlp.nn.initializers -    text_field_embedder.token_embedder_bert.bert_model.encoder.layer.10.intermediate.dense.weight
2021-05-12 00:45:03,646 - INFO - allennlp.nn.initializers -    text_field_embedder.token_embedder_bert.bert_model.encoder.layer.10.output.LayerNorm.bias
2021-05-12 00:45:03,646 - INFO - allennlp.nn.initializers -    text_field_embedder.token_embedder_bert.bert_model.encoder.layer.10.output.LayerNorm.weight
2021-05-12 00:45:03,646 - INFO - allennlp.nn.initializers -    text_field_embedder.token_embedder_bert.bert_model.encoder.layer.10.output.dense.bias
2021-05-12 00:45:03,646 - INFO - allennlp.nn.initializers -    text_field_embedder.token_embedder_bert.bert_model.encoder.layer.10.output.dense.weight
2021-05-12 00:45:03,647 - INFO - allennlp.nn.initializers -    text_field_embedder.token_embedder_bert.bert_model.encoder.layer.11.attention.output.LayerNorm.bias
2021-05-12 00:45:03,647 - INFO - allennlp.nn.initializers -    text_field_embedder.token_embedder_bert.bert_model.encoder.layer.11.attention.output.LayerNorm.weight
2021-05-12 00:45:03,647 - INFO - allennlp.nn.initializers -    text_field_embedder.token_embedder_bert.bert_model.encoder.layer.11.attention.output.dense.bias
2021-05-12 00:45:03,647 - INFO - allennlp.nn.initializers -    text_field_embedder.token_embedder_bert.bert_model.encoder.layer.11.attention.output.dense.weight
2021-05-12 00:45:03,647 - INFO - allennlp.nn.initializers -    text_field_embedder.token_embedder_bert.bert_model.encoder.layer.11.attention.self.key.bias
2021-05-12 00:45:03,647 - INFO - allennlp.nn.initializers -    text_field_embedder.token_embedder_bert.bert_model.encoder.layer.11.attention.self.key.weight
2021-05-12 00:45:03,647 - INFO - allennlp.nn.initializers -    text_field_embedder.token_embedder_bert.bert_model.encoder.layer.11.attention.self.query.bias
2021-05-12 00:45:03,647 - INFO - allennlp.nn.initializers -    text_field_embedder.token_embedder_bert.bert_model.encoder.layer.11.attention.self.query.weight
2021-05-12 00:45:03,647 - INFO - allennlp.nn.initializers -    text_field_embedder.token_embedder_bert.bert_model.encoder.layer.11.attention.self.value.bias
2021-05-12 00:45:03,647 - INFO - allennlp.nn.initializers -    text_field_embedder.token_embedder_bert.bert_model.encoder.layer.11.attention.self.value.weight
2021-05-12 00:45:03,647 - INFO - allennlp.nn.initializers -    text_field_embedder.token_embedder_bert.bert_model.encoder.layer.11.intermediate.dense.bias
2021-05-12 00:45:03,647 - INFO - allennlp.nn.initializers -    text_field_embedder.token_embedder_bert.bert_model.encoder.layer.11.intermediate.dense.weight
2021-05-12 00:45:03,647 - INFO - allennlp.nn.initializers -    text_field_embedder.token_embedder_bert.bert_model.encoder.layer.11.output.LayerNorm.bias
2021-05-12 00:45:03,647 - INFO - allennlp.nn.initializers -    text_field_embedder.token_embedder_bert.bert_model.encoder.layer.11.output.LayerNorm.weight
2021-05-12 00:45:03,647 - INFO - allennlp.nn.initializers -    text_field_embedder.token_embedder_bert.bert_model.encoder.layer.11.output.dense.bias
2021-05-12 00:45:03,647 - INFO - allennlp.nn.initializers -    text_field_embedder.token_embedder_bert.bert_model.encoder.layer.11.output.dense.weight
2021-05-12 00:45:03,647 - INFO - allennlp.nn.initializers -    text_field_embedder.token_embedder_bert.bert_model.encoder.layer.2.attention.output.LayerNorm.bias
2021-05-12 00:45:03,647 - INFO - allennlp.nn.initializers -    text_field_embedder.token_embedder_bert.bert_model.encoder.layer.2.attention.output.LayerNorm.weight
2021-05-12 00:45:03,648 - INFO - allennlp.nn.initializers -    text_field_embedder.token_embedder_bert.bert_model.encoder.layer.2.attention.output.dense.bias
2021-05-12 00:45:03,648 - INFO - allennlp.nn.initializers -    text_field_embedder.token_embedder_bert.bert_model.encoder.layer.2.attention.output.dense.weight
2021-05-12 00:45:03,648 - INFO - allennlp.nn.initializers -    text_field_embedder.token_embedder_bert.bert_model.encoder.layer.2.attention.self.key.bias
2021-05-12 00:45:03,648 - INFO - allennlp.nn.initializers -    text_field_embedder.token_embedder_bert.bert_model.encoder.layer.2.attention.self.key.weight
2021-05-12 00:45:03,648 - INFO - allennlp.nn.initializers -    text_field_embedder.token_embedder_bert.bert_model.encoder.layer.2.attention.self.query.bias
2021-05-12 00:45:03,648 - INFO - allennlp.nn.initializers -    text_field_embedder.token_embedder_bert.bert_model.encoder.layer.2.attention.self.query.weight
2021-05-12 00:45:03,648 - INFO - allennlp.nn.initializers -    text_field_embedder.token_embedder_bert.bert_model.encoder.layer.2.attention.self.value.bias
2021-05-12 00:45:03,648 - INFO - allennlp.nn.initializers -    text_field_embedder.token_embedder_bert.bert_model.encoder.layer.2.attention.self.value.weight
2021-05-12 00:45:03,648 - INFO - allennlp.nn.initializers -    text_field_embedder.token_embedder_bert.bert_model.encoder.layer.2.intermediate.dense.bias
2021-05-12 00:45:03,648 - INFO - allennlp.nn.initializers -    text_field_embedder.token_embedder_bert.bert_model.encoder.layer.2.intermediate.dense.weight
2021-05-12 00:45:03,648 - INFO - allennlp.nn.initializers -    text_field_embedder.token_embedder_bert.bert_model.encoder.layer.2.output.LayerNorm.bias
2021-05-12 00:45:03,648 - INFO - allennlp.nn.initializers -    text_field_embedder.token_embedder_bert.bert_model.encoder.layer.2.output.LayerNorm.weight
2021-05-12 00:45:03,648 - INFO - allennlp.nn.initializers -    text_field_embedder.token_embedder_bert.bert_model.encoder.layer.2.output.dense.bias
2021-05-12 00:45:03,648 - INFO - allennlp.nn.initializers -    text_field_embedder.token_embedder_bert.bert_model.encoder.layer.2.output.dense.weight
2021-05-12 00:45:03,648 - INFO - allennlp.nn.initializers -    text_field_embedder.token_embedder_bert.bert_model.encoder.layer.3.attention.output.LayerNorm.bias
2021-05-12 00:45:03,648 - INFO - allennlp.nn.initializers -    text_field_embedder.token_embedder_bert.bert_model.encoder.layer.3.attention.output.LayerNorm.weight
2021-05-12 00:45:03,648 - INFO - allennlp.nn.initializers -    text_field_embedder.token_embedder_bert.bert_model.encoder.layer.3.attention.output.dense.bias
2021-05-12 00:45:03,648 - INFO - allennlp.nn.initializers -    text_field_embedder.token_embedder_bert.bert_model.encoder.layer.3.attention.output.dense.weight
2021-05-12 00:45:03,648 - INFO - allennlp.nn.initializers -    text_field_embedder.token_embedder_bert.bert_model.encoder.layer.3.attention.self.key.bias
2021-05-12 00:45:03,649 - INFO - allennlp.nn.initializers -    text_field_embedder.token_embedder_bert.bert_model.encoder.layer.3.attention.self.key.weight
2021-05-12 00:45:03,649 - INFO - allennlp.nn.initializers -    text_field_embedder.token_embedder_bert.bert_model.encoder.layer.3.attention.self.query.bias
2021-05-12 00:45:03,649 - INFO - allennlp.nn.initializers -    text_field_embedder.token_embedder_bert.bert_model.encoder.layer.3.attention.self.query.weight
2021-05-12 00:45:03,649 - INFO - allennlp.nn.initializers -    text_field_embedder.token_embedder_bert.bert_model.encoder.layer.3.attention.self.value.bias
2021-05-12 00:45:03,649 - INFO - allennlp.nn.initializers -    text_field_embedder.token_embedder_bert.bert_model.encoder.layer.3.attention.self.value.weight
2021-05-12 00:45:03,649 - INFO - allennlp.nn.initializers -    text_field_embedder.token_embedder_bert.bert_model.encoder.layer.3.intermediate.dense.bias
2021-05-12 00:45:03,649 - INFO - allennlp.nn.initializers -    text_field_embedder.token_embedder_bert.bert_model.encoder.layer.3.intermediate.dense.weight
2021-05-12 00:45:03,649 - INFO - allennlp.nn.initializers -    text_field_embedder.token_embedder_bert.bert_model.encoder.layer.3.output.LayerNorm.bias
2021-05-12 00:45:03,649 - INFO - allennlp.nn.initializers -    text_field_embedder.token_embedder_bert.bert_model.encoder.layer.3.output.LayerNorm.weight
2021-05-12 00:45:03,649 - INFO - allennlp.nn.initializers -    text_field_embedder.token_embedder_bert.bert_model.encoder.layer.3.output.dense.bias
2021-05-12 00:45:03,649 - INFO - allennlp.nn.initializers -    text_field_embedder.token_embedder_bert.bert_model.encoder.layer.3.output.dense.weight
2021-05-12 00:45:03,649 - INFO - allennlp.nn.initializers -    text_field_embedder.token_embedder_bert.bert_model.encoder.layer.4.attention.output.LayerNorm.bias
2021-05-12 00:45:03,649 - INFO - allennlp.nn.initializers -    text_field_embedder.token_embedder_bert.bert_model.encoder.layer.4.attention.output.LayerNorm.weight
2021-05-12 00:45:03,649 - INFO - allennlp.nn.initializers -    text_field_embedder.token_embedder_bert.bert_model.encoder.layer.4.attention.output.dense.bias
2021-05-12 00:45:03,649 - INFO - allennlp.nn.initializers -    text_field_embedder.token_embedder_bert.bert_model.encoder.layer.4.attention.output.dense.weight
2021-05-12 00:45:03,649 - INFO - allennlp.nn.initializers -    text_field_embedder.token_embedder_bert.bert_model.encoder.layer.4.attention.self.key.bias
2021-05-12 00:45:03,649 - INFO - allennlp.nn.initializers -    text_field_embedder.token_embedder_bert.bert_model.encoder.layer.4.attention.self.key.weight
2021-05-12 00:45:03,649 - INFO - allennlp.nn.initializers -    text_field_embedder.token_embedder_bert.bert_model.encoder.layer.4.attention.self.query.bias
2021-05-12 00:45:03,650 - INFO - allennlp.nn.initializers -    text_field_embedder.token_embedder_bert.bert_model.encoder.layer.4.attention.self.query.weight
2021-05-12 00:45:03,650 - INFO - allennlp.nn.initializers -    text_field_embedder.token_embedder_bert.bert_model.encoder.layer.4.attention.self.value.bias
2021-05-12 00:45:03,650 - INFO - allennlp.nn.initializers -    text_field_embedder.token_embedder_bert.bert_model.encoder.layer.4.attention.self.value.weight
2021-05-12 00:45:03,650 - INFO - allennlp.nn.initializers -    text_field_embedder.token_embedder_bert.bert_model.encoder.layer.4.intermediate.dense.bias
2021-05-12 00:45:03,650 - INFO - allennlp.nn.initializers -    text_field_embedder.token_embedder_bert.bert_model.encoder.layer.4.intermediate.dense.weight
2021-05-12 00:45:03,650 - INFO - allennlp.nn.initializers -    text_field_embedder.token_embedder_bert.bert_model.encoder.layer.4.output.LayerNorm.bias
2021-05-12 00:45:03,650 - INFO - allennlp.nn.initializers -    text_field_embedder.token_embedder_bert.bert_model.encoder.layer.4.output.LayerNorm.weight
2021-05-12 00:45:03,650 - INFO - allennlp.nn.initializers -    text_field_embedder.token_embedder_bert.bert_model.encoder.layer.4.output.dense.bias
2021-05-12 00:45:03,650 - INFO - allennlp.nn.initializers -    text_field_embedder.token_embedder_bert.bert_model.encoder.layer.4.output.dense.weight
2021-05-12 00:45:03,650 - INFO - allennlp.nn.initializers -    text_field_embedder.token_embedder_bert.bert_model.encoder.layer.5.attention.output.LayerNorm.bias
2021-05-12 00:45:03,650 - INFO - allennlp.nn.initializers -    text_field_embedder.token_embedder_bert.bert_model.encoder.layer.5.attention.output.LayerNorm.weight
2021-05-12 00:45:03,650 - INFO - allennlp.nn.initializers -    text_field_embedder.token_embedder_bert.bert_model.encoder.layer.5.attention.output.dense.bias
2021-05-12 00:45:03,650 - INFO - allennlp.nn.initializers -    text_field_embedder.token_embedder_bert.bert_model.encoder.layer.5.attention.output.dense.weight
2021-05-12 00:45:03,650 - INFO - allennlp.nn.initializers -    text_field_embedder.token_embedder_bert.bert_model.encoder.layer.5.attention.self.key.bias
2021-05-12 00:45:03,650 - INFO - allennlp.nn.initializers -    text_field_embedder.token_embedder_bert.bert_model.encoder.layer.5.attention.self.key.weight
2021-05-12 00:45:03,650 - INFO - allennlp.nn.initializers -    text_field_embedder.token_embedder_bert.bert_model.encoder.layer.5.attention.self.query.bias
2021-05-12 00:45:03,650 - INFO - allennlp.nn.initializers -    text_field_embedder.token_embedder_bert.bert_model.encoder.layer.5.attention.self.query.weight
2021-05-12 00:45:03,650 - INFO - allennlp.nn.initializers -    text_field_embedder.token_embedder_bert.bert_model.encoder.layer.5.attention.self.value.bias
2021-05-12 00:45:03,650 - INFO - allennlp.nn.initializers -    text_field_embedder.token_embedder_bert.bert_model.encoder.layer.5.attention.self.value.weight
2021-05-12 00:45:03,651 - INFO - allennlp.nn.initializers -    text_field_embedder.token_embedder_bert.bert_model.encoder.layer.5.intermediate.dense.bias
2021-05-12 00:45:03,651 - INFO - allennlp.nn.initializers -    text_field_embedder.token_embedder_bert.bert_model.encoder.layer.5.intermediate.dense.weight
2021-05-12 00:45:03,651 - INFO - allennlp.nn.initializers -    text_field_embedder.token_embedder_bert.bert_model.encoder.layer.5.output.LayerNorm.bias
2021-05-12 00:45:03,651 - INFO - allennlp.nn.initializers -    text_field_embedder.token_embedder_bert.bert_model.encoder.layer.5.output.LayerNorm.weight
2021-05-12 00:45:03,651 - INFO - allennlp.nn.initializers -    text_field_embedder.token_embedder_bert.bert_model.encoder.layer.5.output.dense.bias
2021-05-12 00:45:03,651 - INFO - allennlp.nn.initializers -    text_field_embedder.token_embedder_bert.bert_model.encoder.layer.5.output.dense.weight
2021-05-12 00:45:03,651 - INFO - allennlp.nn.initializers -    text_field_embedder.token_embedder_bert.bert_model.encoder.layer.6.attention.output.LayerNorm.bias
2021-05-12 00:45:03,651 - INFO - allennlp.nn.initializers -    text_field_embedder.token_embedder_bert.bert_model.encoder.layer.6.attention.output.LayerNorm.weight
2021-05-12 00:45:03,651 - INFO - allennlp.nn.initializers -    text_field_embedder.token_embedder_bert.bert_model.encoder.layer.6.attention.output.dense.bias
2021-05-12 00:45:03,651 - INFO - allennlp.nn.initializers -    text_field_embedder.token_embedder_bert.bert_model.encoder.layer.6.attention.output.dense.weight
2021-05-12 00:45:03,651 - INFO - allennlp.nn.initializers -    text_field_embedder.token_embedder_bert.bert_model.encoder.layer.6.attention.self.key.bias
2021-05-12 00:45:03,651 - INFO - allennlp.nn.initializers -    text_field_embedder.token_embedder_bert.bert_model.encoder.layer.6.attention.self.key.weight
2021-05-12 00:45:03,651 - INFO - allennlp.nn.initializers -    text_field_embedder.token_embedder_bert.bert_model.encoder.layer.6.attention.self.query.bias
2021-05-12 00:45:03,651 - INFO - allennlp.nn.initializers -    text_field_embedder.token_embedder_bert.bert_model.encoder.layer.6.attention.self.query.weight
2021-05-12 00:45:03,651 - INFO - allennlp.nn.initializers -    text_field_embedder.token_embedder_bert.bert_model.encoder.layer.6.attention.self.value.bias
2021-05-12 00:45:03,651 - INFO - allennlp.nn.initializers -    text_field_embedder.token_embedder_bert.bert_model.encoder.layer.6.attention.self.value.weight
2021-05-12 00:45:03,651 - INFO - allennlp.nn.initializers -    text_field_embedder.token_embedder_bert.bert_model.encoder.layer.6.intermediate.dense.bias
2021-05-12 00:45:03,651 - INFO - allennlp.nn.initializers -    text_field_embedder.token_embedder_bert.bert_model.encoder.layer.6.intermediate.dense.weight
2021-05-12 00:45:03,652 - INFO - allennlp.nn.initializers -    text_field_embedder.token_embedder_bert.bert_model.encoder.layer.6.output.LayerNorm.bias
2021-05-12 00:45:03,652 - INFO - allennlp.nn.initializers -    text_field_embedder.token_embedder_bert.bert_model.encoder.layer.6.output.LayerNorm.weight
2021-05-12 00:45:03,652 - INFO - allennlp.nn.initializers -    text_field_embedder.token_embedder_bert.bert_model.encoder.layer.6.output.dense.bias
2021-05-12 00:45:03,652 - INFO - allennlp.nn.initializers -    text_field_embedder.token_embedder_bert.bert_model.encoder.layer.6.output.dense.weight
2021-05-12 00:45:03,652 - INFO - allennlp.nn.initializers -    text_field_embedder.token_embedder_bert.bert_model.encoder.layer.7.attention.output.LayerNorm.bias
2021-05-12 00:45:03,652 - INFO - allennlp.nn.initializers -    text_field_embedder.token_embedder_bert.bert_model.encoder.layer.7.attention.output.LayerNorm.weight
2021-05-12 00:45:03,652 - INFO - allennlp.nn.initializers -    text_field_embedder.token_embedder_bert.bert_model.encoder.layer.7.attention.output.dense.bias
2021-05-12 00:45:03,652 - INFO - allennlp.nn.initializers -    text_field_embedder.token_embedder_bert.bert_model.encoder.layer.7.attention.output.dense.weight
2021-05-12 00:45:03,652 - INFO - allennlp.nn.initializers -    text_field_embedder.token_embedder_bert.bert_model.encoder.layer.7.attention.self.key.bias
2021-05-12 00:45:03,652 - INFO - allennlp.nn.initializers -    text_field_embedder.token_embedder_bert.bert_model.encoder.layer.7.attention.self.key.weight
2021-05-12 00:45:03,652 - INFO - allennlp.nn.initializers -    text_field_embedder.token_embedder_bert.bert_model.encoder.layer.7.attention.self.query.bias
2021-05-12 00:45:03,652 - INFO - allennlp.nn.initializers -    text_field_embedder.token_embedder_bert.bert_model.encoder.layer.7.attention.self.query.weight
2021-05-12 00:45:03,652 - INFO - allennlp.nn.initializers -    text_field_embedder.token_embedder_bert.bert_model.encoder.layer.7.attention.self.value.bias
2021-05-12 00:45:03,652 - INFO - allennlp.nn.initializers -    text_field_embedder.token_embedder_bert.bert_model.encoder.layer.7.attention.self.value.weight
2021-05-12 00:45:03,652 - INFO - allennlp.nn.initializers -    text_field_embedder.token_embedder_bert.bert_model.encoder.layer.7.intermediate.dense.bias
2021-05-12 00:45:03,652 - INFO - allennlp.nn.initializers -    text_field_embedder.token_embedder_bert.bert_model.encoder.layer.7.intermediate.dense.weight
2021-05-12 00:45:03,652 - INFO - allennlp.nn.initializers -    text_field_embedder.token_embedder_bert.bert_model.encoder.layer.7.output.LayerNorm.bias
2021-05-12 00:45:03,652 - INFO - allennlp.nn.initializers -    text_field_embedder.token_embedder_bert.bert_model.encoder.layer.7.output.LayerNorm.weight
2021-05-12 00:45:03,652 - INFO - allennlp.nn.initializers -    text_field_embedder.token_embedder_bert.bert_model.encoder.layer.7.output.dense.bias
2021-05-12 00:45:03,653 - INFO - allennlp.nn.initializers -    text_field_embedder.token_embedder_bert.bert_model.encoder.layer.7.output.dense.weight
2021-05-12 00:45:03,653 - INFO - allennlp.nn.initializers -    text_field_embedder.token_embedder_bert.bert_model.encoder.layer.8.attention.output.LayerNorm.bias
2021-05-12 00:45:03,653 - INFO - allennlp.nn.initializers -    text_field_embedder.token_embedder_bert.bert_model.encoder.layer.8.attention.output.LayerNorm.weight
2021-05-12 00:45:03,653 - INFO - allennlp.nn.initializers -    text_field_embedder.token_embedder_bert.bert_model.encoder.layer.8.attention.output.dense.bias
2021-05-12 00:45:03,653 - INFO - allennlp.nn.initializers -    text_field_embedder.token_embedder_bert.bert_model.encoder.layer.8.attention.output.dense.weight
2021-05-12 00:45:03,653 - INFO - allennlp.nn.initializers -    text_field_embedder.token_embedder_bert.bert_model.encoder.layer.8.attention.self.key.bias
2021-05-12 00:45:03,653 - INFO - allennlp.nn.initializers -    text_field_embedder.token_embedder_bert.bert_model.encoder.layer.8.attention.self.key.weight
2021-05-12 00:45:03,653 - INFO - allennlp.nn.initializers -    text_field_embedder.token_embedder_bert.bert_model.encoder.layer.8.attention.self.query.bias
2021-05-12 00:45:03,653 - INFO - allennlp.nn.initializers -    text_field_embedder.token_embedder_bert.bert_model.encoder.layer.8.attention.self.query.weight
2021-05-12 00:45:03,653 - INFO - allennlp.nn.initializers -    text_field_embedder.token_embedder_bert.bert_model.encoder.layer.8.attention.self.value.bias
2021-05-12 00:45:03,653 - INFO - allennlp.nn.initializers -    text_field_embedder.token_embedder_bert.bert_model.encoder.layer.8.attention.self.value.weight
2021-05-12 00:45:03,653 - INFO - allennlp.nn.initializers -    text_field_embedder.token_embedder_bert.bert_model.encoder.layer.8.intermediate.dense.bias
2021-05-12 00:45:03,653 - INFO - allennlp.nn.initializers -    text_field_embedder.token_embedder_bert.bert_model.encoder.layer.8.intermediate.dense.weight
2021-05-12 00:45:03,653 - INFO - allennlp.nn.initializers -    text_field_embedder.token_embedder_bert.bert_model.encoder.layer.8.output.LayerNorm.bias
2021-05-12 00:45:03,653 - INFO - allennlp.nn.initializers -    text_field_embedder.token_embedder_bert.bert_model.encoder.layer.8.output.LayerNorm.weight
2021-05-12 00:45:03,653 - INFO - allennlp.nn.initializers -    text_field_embedder.token_embedder_bert.bert_model.encoder.layer.8.output.dense.bias
2021-05-12 00:45:03,653 - INFO - allennlp.nn.initializers -    text_field_embedder.token_embedder_bert.bert_model.encoder.layer.8.output.dense.weight
2021-05-12 00:45:03,653 - INFO - allennlp.nn.initializers -    text_field_embedder.token_embedder_bert.bert_model.encoder.layer.9.attention.output.LayerNorm.bias
2021-05-12 00:45:03,654 - INFO - allennlp.nn.initializers -    text_field_embedder.token_embedder_bert.bert_model.encoder.layer.9.attention.output.LayerNorm.weight
2021-05-12 00:45:03,654 - INFO - allennlp.nn.initializers -    text_field_embedder.token_embedder_bert.bert_model.encoder.layer.9.attention.output.dense.bias
2021-05-12 00:45:03,654 - INFO - allennlp.nn.initializers -    text_field_embedder.token_embedder_bert.bert_model.encoder.layer.9.attention.output.dense.weight
2021-05-12 00:45:03,654 - INFO - allennlp.nn.initializers -    text_field_embedder.token_embedder_bert.bert_model.encoder.layer.9.attention.self.key.bias
2021-05-12 00:45:03,654 - INFO - allennlp.nn.initializers -    text_field_embedder.token_embedder_bert.bert_model.encoder.layer.9.attention.self.key.weight
2021-05-12 00:45:03,654 - INFO - allennlp.nn.initializers -    text_field_embedder.token_embedder_bert.bert_model.encoder.layer.9.attention.self.query.bias
2021-05-12 00:45:03,654 - INFO - allennlp.nn.initializers -    text_field_embedder.token_embedder_bert.bert_model.encoder.layer.9.attention.self.query.weight
2021-05-12 00:45:03,654 - INFO - allennlp.nn.initializers -    text_field_embedder.token_embedder_bert.bert_model.encoder.layer.9.attention.self.value.bias
2021-05-12 00:45:03,654 - INFO - allennlp.nn.initializers -    text_field_embedder.token_embedder_bert.bert_model.encoder.layer.9.attention.self.value.weight
2021-05-12 00:45:03,654 - INFO - allennlp.nn.initializers -    text_field_embedder.token_embedder_bert.bert_model.encoder.layer.9.intermediate.dense.bias
2021-05-12 00:45:03,654 - INFO - allennlp.nn.initializers -    text_field_embedder.token_embedder_bert.bert_model.encoder.layer.9.intermediate.dense.weight
2021-05-12 00:45:03,654 - INFO - allennlp.nn.initializers -    text_field_embedder.token_embedder_bert.bert_model.encoder.layer.9.output.LayerNorm.bias
2021-05-12 00:45:03,654 - INFO - allennlp.nn.initializers -    text_field_embedder.token_embedder_bert.bert_model.encoder.layer.9.output.LayerNorm.weight
2021-05-12 00:45:03,654 - INFO - allennlp.nn.initializers -    text_field_embedder.token_embedder_bert.bert_model.encoder.layer.9.output.dense.bias
2021-05-12 00:45:03,654 - INFO - allennlp.nn.initializers -    text_field_embedder.token_embedder_bert.bert_model.encoder.layer.9.output.dense.weight
2021-05-12 00:45:03,654 - INFO - allennlp.nn.initializers -    text_field_embedder.token_embedder_bert.bert_model.pooler.dense.bias
2021-05-12 00:45:03,654 - INFO - allennlp.nn.initializers -    text_field_embedder.token_embedder_bert.bert_model.pooler.dense.weight
2021-05-12 00:45:03,660 - INFO - udify.models.udify_model - Total number of parameters: 198563643
2021-05-12 00:45:03,660 - INFO - udify.models.udify_model - Total number of trainable parameters: 198563643
2021-05-12 00:45:04,497 - INFO - allennlp.models.archival - removing temporary unarchived model dir at /scratch/tmp6fq8e6ui
reading instances: 0it [00:00, ?it/s]
2021-05-12 00:45:04,578 - INFO - udify.dataset_readers.universal_dependencies - Reading UD instances from conllu dataset at: data/ud-treebanks-v2.3/UD_English-EWT/en_ewt-ud-test.conllu
reading instances: 1792it [00:02, 895.74it/s]
reading instances: 2077it [00:02, 924.04it/s]
2021-05-12 00:46:37,157 - INFO - udify.util - Metric     | Correct   |      Gold | Predicted | Aligned
2021-05-12 00:46:37,158 - INFO - udify.util - -----------+-----------+-----------+-----------+-----------
2021-05-12 00:46:37,158 - INFO - udify.util - Tokens     |    100.00 |    100.00 |    100.00 |
2021-05-12 00:46:37,158 - INFO - udify.util - Sentences  |    100.00 |    100.00 |    100.00 |
2021-05-12 00:46:37,158 - INFO - udify.util - Words      |    100.00 |    100.00 |    100.00 |
2021-05-12 00:46:37,158 - INFO - udify.util - UPOS       |      0.00 |      0.00 |      0.00 |      0.00
2021-05-12 00:46:37,158 - INFO - udify.util - XPOS       |      0.00 |      0.00 |      0.00 |      0.00
2021-05-12 00:46:37,159 - INFO - udify.util - UFeats     |     33.68 |     33.68 |     33.68 |     33.68
2021-05-12 00:46:37,159 - INFO - udify.util - AllTags    |      0.00 |      0.00 |      0.00 |      0.00
2021-05-12 00:46:37,159 - INFO - udify.util - Lemmas     |      0.00 |      0.00 |      0.00 |      0.00
2021-05-12 00:46:37,159 - INFO - udify.util - UAS        |     88.74 |     88.74 |     88.74 |     88.74
2021-05-12 00:46:37,159 - INFO - udify.util - LAS        |     85.23 |     85.23 |     85.23 |     85.23
2021-05-12 00:46:37,159 - INFO - udify.util - CLAS       |     82.14 |     81.76 |     81.95 |     81.76
2021-05-12 00:46:37,159 - INFO - udify.util - MLAS       |      0.00 |      0.00 |      0.00 |      0.00
2021-05-12 00:46:37,159 - INFO - udify.util - BLEX       |      0.00 |      0.00 |      0.00 |      0.00
